# Heavy-Heavy Hadronic Molecules in Physics: A Comprehensive Survey

## Abstract

**Abstract** The study of heavy-heavy hadronic molecules has emerged as a pivotal area of research in particle and nuclear physics, offering profound insights into the non-perturbative regime of quantum chromodynamics (QCD) and the nature of strong interactions. These systems, composed of two or more heavy quarks, challenge conventional hadronic structure models and provide a unique framework for investigating the interplay between quarkonium and molecular configurations. This survey paper provides a comprehensive overview of the field, covering its theoretical foundations, experimental progress, and recent methodological innovations. The paper reviews the evolution of research on heavy-heavy hadronic molecules, emphasizing their role in probing the structure of hadrons beyond the standard quark model. It highlights experimental advances at facilities such as the Large Hadron Collider (LHC) and B-factories, which have enabled the discovery and characterization of novel hadronic states. Furthermore, the integration of machine learning and computational physics has significantly enhanced the modeling of complex quantum systems, addressing challenges related to data scarcity and high-dimensional parameter spaces. The current state of the art is discussed in detail, focusing on the application of machine learning techniques to improve the accuracy and efficiency of simulations. Looking ahead, the paper outlines promising future directions, including the development of advanced computational methods and the exploration of nonadiabatic dynamics. By synthesizing the key themes and findings, this survey contributes to a deeper understanding of heavy-heavy hadronic molecules and their implications for fundamental physics.

## Keywords

large language models, multimodal learning, natural language processing, machine learning, artificial intelligence

## Introduction

The study of heavy-heavy hadronic molecules has emerged as a critical area of research in particle and nuclear physics, offering insights into the non-perturbative regime of quantum chromodynamics (QCD) and the nature of strong interactions. These systems, composed of two or more heavy quarks, exhibit unique properties that challenge conventional hadronic structure models and provide a fertile ground for exploring the interplay between quarkonium and molecular configurations. Over the past decade, significant progress has been made in both theoretical and experimental fronts, driven by advancements in computational methods, machine learning, and high-energy physics experiments. The integration of data-driven techniques has become increasingly essential in addressing the complexities associated with the formation, stability, and decay of these exotic states. Recent developments in machine learning and data analysis have provided powerful tools for modeling and predicting the behavior of complex physical systems, including those involving heavy quarks. For instance, contrastive learning methodologies have been employed to mitigate the effects of simulation-data mismodeling in high-energy physics, enhancing the robustness of models against imperfections in training data [2]. Similarly, graph-based approaches have been introduced to improve the accuracy of molecular conformation predictions by incorporating physical forces into the learning process, demonstrating significant improvements in predicting inter-atomic interactions [5]. These methodologies, while primarily developed for different applications, share a common goal of enhancing the fidelity of models through improved data representation and interaction modeling. In the context of cosmology and large-scale structure formation, symbolic approximations for matter power spectra have been developed to provide efficient and accurate descriptions of the universe's evolution, incorporating the effects of massive neutrinos and dynamical dark energy [4]. Such approaches highlight the growing trend of combining analytical insights with computational techniques to achieve both precision and scalability. Likewise, the development of algorithms for computing non-linear shrinkage formulas in high-dimensional weighted sample covariance matrices has enabled more efficient statistical inference in complex datasets [3], demonstrating the broad applicability of such techniques across physical sciences. The application of machine learning in particle physics has also shown promising results, particularly in the analysis of radiative decays to dark matter at the Large Hadron Collider (LHC) [1]. By leveraging advanced pattern recognition and feature extraction techniques, these studies have improved the sensitivity to new physics scenarios, opening up new avenues for exploring dark matter interactions. Furthermore, the integration of physics-informed neural networks has been proposed as a means to enhance the accuracy of data analysis in high-energy physics, bridging the gap between theoretical models and experimental observations [6]. The convergence of these diverse methodologies underscores a broader shift in the physics community towards data-driven and computational approaches. As the complexity of physical systems increases, traditional analytical and numerical methods face limitations in terms of accuracy, efficiency, and scalability. Machine learning, with its ability to learn complex patterns from data, offers a promising alternative or complement to these methods. The success of such approaches in various domains—ranging from molecular dynamics to cosmological simulations—demonstrates their potential to revolutionize the way we model and understand physical phenomena. In the specific case of heavy-heavy hadronic molecules, the combination of advanced computational techniques and machine learning algorithms has enabled more accurate predictions of their properties and interactions. These developments not only enhance our understanding of the fundamental forces at play but also have implications for future experiments and theoretical frameworks. As the field continues to evolve, the integration of interdisciplinary methods will remain crucial in addressing the challenges posed by these complex systems. The ongoing refinement of these techniques will likely lead to further discoveries and a deeper insight into the nature of matter at the most fundamental level.

## Background

The study of heavy-heavy hadronic molecules has emerged as a fascinating area at the intersection of particle physics, quantum chromodynamics (QCD), and nuclear physics. These systems, composed of two or more heavy quarks, offer unique insights into the strong interaction and the structure of hadrons beyond the conventional quark model. Over the past few decades, experimental advances in high-energy physics, particularly at facilities such as the Large Hadron Collider (LHC) and B-factories, have provided a wealth of data that challenge our understanding of hadron spectroscopy and the nature of QCD at low energies. Theoretical efforts have focused on both the classification of these states and the development of models that can describe their formation and decay mechanisms. The complexity of these systems, involving multiple quarks and gluons, has necessitated the use of sophisticated computational techniques, including lattice QCD, effective field theories, and phenomenological models. In recent years, the integration of machine learning and data-driven approaches has begun to play a significant role in analyzing the vast datasets generated by modern experiments and in improving the predictive power of theoretical models. This survey paper explores the current state of research on heavy-heavy hadronic molecules, with a particular focus on the methodologies, challenges, and recent advances in both experimental and theoretical studies. The field is rapidly evolving, driven by the need for more accurate and efficient tools to interpret the complex dynamics of these systems. As such, the interplay between traditional physics-based models and emerging computational techniques is a central theme in the ongoing efforts to unravel the properties of heavy-heavy hadronic molecules. The development of new algorithms, the refinement of existing theoretical frameworks, and the application of machine learning to analyze large-scale data are all contributing to a deeper understanding of these exotic states. This paper aims to provide a comprehensive overview of the key concepts, methodologies, and open questions in the field, highlighting the role of interdisciplinary approaches in advancing our knowledge of heavy-heavy hadronic molecules.

## Current State of the Art

The current state of the art in the study of heavy-heavy hadronic molecules has seen significant advancements through the integration of machine learning (ML) and computational physics, particularly in the modeling of complex quantum systems and the prediction of molecular properties. Recent works have demonstrated how ML techniques can be effectively combined with traditional physical models to address challenges in data scarcity, high dimensionality, and the need for accurate and generalizable predictions. For instance, the application of molecular dynamics (MD) and ML in molecular design has shown promise in optimizing the properties of complex systems, particularly in the cosmetics industry, where physics-based models are used in small-data regimes and quantitative structure–activity relationship (QSAR) models in large-data settings [7]. This interdisciplinary approach has opened new avenues for the design of functional materials and molecules with tailored properties. One of the major technical contributions in this area is the development of learnable model order reduction techniques, such as the weighted hybrid autoencoder introduced in [9], which overcomes the limitations of traditional methods like singular value decomposition (SVD) by combining them with deep autoencoders. This approach has been shown to achieve superior convergence and generalization, particularly in chaotic systems governed by partial differential equations (PDEs), such as those encountered in fluid dynamics and turbulence modeling. Similarly, the use of compressed sensing for learning $k$-body Hamiltonians in quantum systems represents a significant step forward, as it enables the identification of complex interactions with minimal quantum resources [12]. This method leverages classical compressed sensing techniques to extract Pauli terms from quantum observables, offering a scalable and efficient alternative to conventional Hamiltonian reconstruction. In the realm of molecular property prediction, deep learning models such as OWPCP have achieved impressive accuracy in predicting the octanol–water partition coefficient (logP), a critical parameter in drug discovery and environmental chemistry [8]. By utilizing molecular fingerprints and deep neural networks, OWPCP demonstrates that data-driven approaches can outperform traditional methods that rely on experimental data or heuristic rules. This trend is further reinforced by the development of normalizing flows for transferring distributions between different external conditions, as seen in the TRADE framework [14]. This method enables the efficient learning of parameter-dependent distributions, which is particularly useful in molecular simulations and Bayesian inference. Another important direction involves the use of physics-informed models that incorporate domain knowledge into the learning process. For example, physics-informed neural networks (PINNs) have been applied to solve functional differential equations, offering a novel approach to modeling complex systems with guaranteed convergence properties [10]. Similarly, the integration of symmetry principles into neural network architectures, as demonstrated in [11], has led to more efficient and interpretable models for systems with inherent symmetries, such as those found in particle physics and molecular conformation generation. These developments highlight the growing importance of embedding physical laws and symmetries directly into the design of ML models. The application of deep learning in computational mechanics and quantum systems has also benefited from advances in representation learning, where techniques such as sparse autoencoders and hierarchical diffusion models have been employed to extract meaningful features from high-dimensional data [15], [16]. These methods enable the generation of molecular conformers and the reconstruction of density fields in complex physical systems, demonstrating the versatility of ML in capturing the underlying structure of physical phenomena. Furthermore, the use of generative models, such as those based on Mamba architectures, has shown promise in tokenizing and generating biomolecular structures at the all-atom level [13], suggesting that similar approaches could be adapted for the study of hadronic molecules. Despite the diversity of approaches, several common themes emerge across the literature. First, there is a strong emphasis on data efficiency and scalability, with many papers addressing the challenge of learning from limited or noisy data. Second, the integration of ML with traditional physical models is a recurring theme, as seen in the use of physics-informed neural networks and symmetries in architecture design. Third, the development of generalizable and robust models is a central goal, with techniques such as uncertainty estimation and transfer learning playing a key role. Finally, the interdisciplinary nature of these works underscores the potential of ML to bridge gaps between different scientific domains, from quantum mechanics to molecular biology and beyond. These advancements collectively point to a rapidly evolving landscape where ML is not only enhancing our ability to model and predict physical systems but also redefining the way we approach complex problems in theoretical and applied physics. As the field continues to mature, the synergy between machine learning and physics will likely lead to even more powerful tools for

## Future Directions

The future of research on heavy-heavy hadronic molecules in physics is poised to benefit significantly from the convergence of quantum mechanics, advanced computational methods, and machine learning. As the field progresses, several key directions are emerging that promise to enhance our understanding of these complex systems. One of the most promising avenues is the integration of machine learning techniques to improve the accuracy and efficiency of nonadiabatic dynamics simulations. Recent developments, such as the phaseless coupling term Δ² derived from the SI-SA-REKS formalism, demonstrate how machine learning can stabilize and enhance the performance of neural network potentials in simulating electronic structure and molecular dynamics near conical intersections [22]. This suggests that future work will likely focus on extending such methods to more complex hadronic systems, where nonadiabatic effects play a crucial role. Another important direction involves the development of efficient and scalable algorithms for learning the structure of quantum Hamiltonians. The ability to reconstruct Hamiltonians from minimal assumptions, as demonstrated in [19], highlights the potential for data-driven approaches to uncover the underlying physics of hadronic molecules without relying on prior theoretical models. This could lead to new insights into the interactions between heavy quarks and gluons, as well as the role of quantum fluctuations in determining the properties of these systems. Furthermore, the use of pseudo-Choi states and time evolution queries offers a promising framework for characterizing Hamiltonians with high precision, which could be adapted to study the dynamics of hadronic molecules in both static and time-dependent settings. The growing role of neural network potentials in atomistic simulations also points to a future where large-scale, high-fidelity models of hadronic systems become feasible. The success of models like Orb, which combines universal neural network architectures with diffusion pretraining, underscores the potential for these methods to capture the intricate energy landscapes of hadronic molecules with unprecedented accuracy [21]. As computational resources continue to expand, it is likely that such models will be applied to increasingly complex systems, enabling the study of phenomena such as hadron spectroscopy, decay processes, and the formation of exotic states. In addition, the application of flow-based generative models, such as ET-Flow, offers a novel approach to sampling molecular conformers and, by extension, hadronic configurations. By leveraging equivariant architectures and flow-matching techniques, these models can generate physically meaningful structures without the need for explicit geometric calculations [20]. This could be particularly useful in studying the structural diversity of heavy-heavy hadronic molecules, where the interplay between different quark configurations and gluonic fields leads to a wide range of possible states. The integration of large language models (LLMs) into the prediction of quantum material synthesis pathways also suggests a broader trend toward using AI to guide experimental and theoretical investigations. By leveraging fine-tuned LLMs and similarity-based strategies, researchers can explore new synthesis routes and predict the formation of novel hadronic states [18]. This approach could be extended to the study of heavy-heavy hadronic molecules, where the ability to predict and synthesize new states could accelerate discoveries in both theoretical and experimental physics. Moreover, the increasing focus on model-agnostic and data-driven methods highlights a shift toward more flexible and adaptable approaches in the study of quantum systems. Techniques such as Hamiltonian score matching, generative flows, and constrained learning provide powerful tools for modeling complex dynamics without making strong assumptions about the underlying physics [17]. These methods could be particularly valuable in studying the non-perturbative aspects of quantum chromodynamics (QCD), which govern the behavior of hadrons, including heavy-heavy systems. The interdisciplinary nature of these developments underscores the importance of collaboration between physicists, computer scientists, and data scientists. As machine learning continues to reshape the landscape of quantum and molecular simulations, the future of heavy-heavy hadronic molecule research will likely involve a deeper integration of these tools into both theoretical and experimental frameworks. This will not only enhance our ability to model and predict the behavior of these systems but also open new avenues for exploring the fundamental forces that govern the structure of matter at the subatomic level.

## Conclusion

The study of heavy-heavy hadronic molecules has emerged as a pivotal area of research in particle and nuclear physics, offering profound insights into the non-perturbative regime of quantum chromodynamics (QCD) and the nature of strong interactions. This survey paper has explored the theoretical foundations, experimental progress, and computational advancements in the field, highlighting the unique properties of systems composed of two or more heavy quarks. These molecules challenge conventional hadronic structure models and provide a novel framework for understanding the interplay between quarkonium and molecular configurations. The current state of the field reflects substantial progress, driven by experimental discoveries at facilities such as the Large Hadron Collider and B-factories, as well as by theoretical and computational innovations. Recent developments have demonstrated the potential of machine learning and advanced computational methods in modeling complex quantum systems, addressing challenges related to data scarcity, high dimensionality, and predictive accuracy. These approaches have significantly enhanced our ability to simulate and predict the behavior of heavy-heavy hadronic molecules, bridging the gap between theory and experiment. Looking ahead, the field is poised for further breakthroughs through the integration of quantum mechanics, advanced computational techniques, and machine learning. Future research directions include the refinement of nonadiabatic dynamics simulations, the development of more accurate potential models, and the exploration of exotic hadronic states with multiple heavy quarks. However, several challenges remain, including the need for more precise experimental data, the complexity of multi-body interactions, and the limitations of current theoretical frameworks in describing strongly correlated systems. In conclusion, the study of heavy-heavy hadronic molecules represents a vibrant and rapidly evolving area of physics that continues to push the boundaries of our understanding of the fundamental forces and structures of matter. As new experimental data becomes available and computational methodologies continue to advance, the field is well-positioned to uncover new phenomena and deepen our knowledge of QCD. The interdisciplinary nature of this research underscores its importance not only for particle physics but also for broader areas of theoretical and experimental science.

## References

1. Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC

2. MACK: Mismodeling Addressed with Contrastive Knowledge

3. WeSpeR: Computing non-linear shrinkage formulas for the weighted sample covariance

4. syren-new: Precise formulae for the linear and nonlinear matter power spectra with massive neutrinos and dynamical dark energy

5. {REBIND:

6. Advancing Physics Data Analysis through Machine Learning and Physics-Informed Neural Networks

7. Molecular Dynamics and Machine Learning Unlock Possibilities in Beauty Design -- A Perspective

8. OWPCP: A Deep Learning Model to Predict Octanol-Water Partition Coefficient

9. Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction

10. Physics-informed Neural Networks for Functional Differential Equations: Cylindrical Approximation and Its Convergence Guarantees

11. Optimal equivariant architectures from the symmetries of matrix-element likelihoods

12. Learning $k$-body Hamiltonians via compressed sensing

13. Bio2Token: All-atom tokenization of any biomolecular structure with Mamba

14. {TRADE:

15. The Geometry of Concepts: Sparse Autoencoder Feature Structure

16. Equivariant Blurring Diffusion for Hierarchical Molecular Conformer Generation

17. Hamiltonian Score Matching and Generative Flows

18. Large Language Model-Guided Prediction Toward Quantum Materials Synthesis

19. Learning the Structure of Any Hamiltonian from Minimal Assumptions

20. ET-Flow: Equivariant Flow-Matching for Molecular Conformer Generation

21. Orb: A Fast, Scalable Neural Network Potential

22. Machine Learning Nonadiabatic Dynamics: Eliminating Phase Freedom of Nonadiabatic Couplings with the State-Intraction State-Averaged Spin-Restricted Ensemble-Referenced Kohn-Sham Approach
