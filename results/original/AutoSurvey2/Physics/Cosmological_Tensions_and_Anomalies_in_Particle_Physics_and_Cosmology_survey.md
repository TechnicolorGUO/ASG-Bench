# Cosmological Tensions and Anomalies in Particle Physics and Cosmology: A Comprehensive Survey

## Abstract

**Abstract** The standard cosmological model, ΛCDM, has been remarkably successful in explaining a wide range of observational data. However, recent cosmological tensions and anomalies—such as the Hubble constant (H₀) discrepancy, anomalies in the cosmic microwave background (CMB), and inconsistencies in large-scale structure observations—challenge its completeness. These discrepancies highlight potential limitations in our understanding of fundamental physics, including the nature of dark matter, dark energy, and the early universe. This survey paper provides a comprehensive overview of the current state of research on cosmological tensions and anomalies, emphasizing their implications for both particle physics and cosmology. The paper reviews key observational findings, theoretical interpretations, and the evolving landscape of model-building in light of these challenges. A particular focus is placed on the integration of artificial intelligence and machine learning techniques with traditional physical models, which has emerged as a promising approach to address unresolved issues. The survey also outlines future directions, emphasizing the need for more sophisticated modeling, improved data analysis, and interdisciplinary collaboration. By synthesizing current knowledge and identifying open questions, this paper aims to contribute to the ongoing dialogue on the next generation of cosmological theories and the potential for new physics beyond the standard model. The work underscores the importance of continued exploration in this dynamic field, where observational precision and theoretical innovation are increasingly intertwined.

## Keywords

large language models, multimodal learning, natural language processing, machine learning, artificial intelligence

## Introduction

The study of cosmological tensions and anomalies has become a focal point in both particle physics and cosmology, as discrepancies between theoretical predictions and observational data challenge the standard models of the universe. These tensions, ranging from the Hubble constant (H₀) discrepancy to anomalies in the cosmic microwave background (CMB), highlight the need for a deeper understanding of the underlying physics and the limitations of current models. In recent years, the integration of machine learning (ML) techniques has offered new tools to address these challenges, enabling more precise modeling, uncertainty quantification, and data-driven insights. This survey explores the evolving landscape of cosmological research, emphasizing the role of interdisciplinary approaches that bridge particle physics, cosmology, and data science. The increasing complexity of observational data, coupled with the need for robust statistical methods, has driven the development of advanced ML frameworks tailored to cosmological applications. For instance, the FAIR Universe HiggsML Uncertainty Dataset and Competition introduced a large-scale dataset for measuring Higgs boson properties with systematic uncertainties, demonstrating the effectiveness of ML techniques such as Contrastive Normalising Flows and Density Ratios in handling epistemic uncertainty [4]. This work underscores the importance of uncertainty quantification in high-energy physics and its relevance to cosmological studies where data quality and model reliability are paramount. Similarly, the application of score-based generative modeling in reconstructing galaxy cluster mass maps from Sunyaev-Zel’dovich (SZ) and X-ray data has shown the potential of diffusion models to infer complex physical structures from observational data [3]. These methods not only improve the accuracy of cosmological reconstructions but also highlight the growing role of generative models in astrophysical data analysis. Beyond reconstruction, the intersection of optimal transport and geometry has led to novel approaches for sampling from complex distributions. The work on Neural Sampling from Boltzmann Densities, which employs Fisher-Rao curves in Wasserstein geometry, addresses key challenges in sampling from unnormalized densities, offering analytical insights into the behavior of velocity fields and the stability of interpolation methods [2]. Such geometric perspectives are increasingly relevant in cosmology, where the need for efficient and reliable sampling techniques is critical for parameter estimation and model selection. Meanwhile, the development of foundation models, such as the SDO-FM for solar dynamics, illustrates the potential of multi-modal models to integrate diverse data sources and enable more comprehensive analysis in astrophysical contexts [1]. These models emphasize the importance of domain-specific knowledge in shaping the design and training of ML architectures, ensuring that they are both computationally efficient and physically meaningful. Despite the progress, several challenges remain, including the need for more interpretable models, the generalization of techniques across different data domains, and the integration of theoretical insights with empirical findings. Theoretical frameworks, such as those exploring the longevity of complex living systems, suggest broader perspectives on the behavior of complex systems, which may inform future approaches in cosmology and particle physics [2]. However, such theoretical work often lacks the technical depth required for direct application to cosmological problems, underscoring the need for closer collaboration between physicists, mathematicians, and data scientists. As the field continues to evolve, the focus on uncertainty quantification, generative modeling, and optimal transport will likely play a central role in resolving the tensions and anomalies that define contemporary cosmological research.

## Background

The study of cosmological tensions and anomalies has become a central theme in modern particle physics and cosmology, as observational data increasingly challenge the predictions of the standard cosmological model, ΛCDM. These tensions manifest in various forms, such as discrepancies in the Hubble constant measurements, anomalies in the cosmic microwave background (CMB) temperature fluctuations, and inconsistencies in the large-scale structure of the universe. Such issues suggest that our current understanding of the universe may be incomplete or that new physics beyond the standard model might be required to reconcile these observations with theory. In this context, the integration of advanced computational techniques, particularly those informed by physical laws, has gained significant traction. Physics-informed machine learning (PIML) approaches, such as physics-informed neural networks (PINNs), have emerged as powerful tools for modeling complex physical systems while respecting underlying theoretical constraints. Recent developments, including the introduction of PIKANs, which leverage the Kolmogorov-Arnold representation for improved performance, demonstrate the potential of these methods in addressing challenges in both particle physics and cosmology [19]. The ability of such models to incorporate domain-specific knowledge, such as conservation laws or symmetry principles, ensures that the solutions they generate remain physically meaningful. This is particularly important in cosmological modeling, where the accuracy of predictions depends critically on the fidelity of the underlying physical framework. Moreover, the application of PIML extends beyond traditional numerical simulations, as seen in the use of PINNs to solve inverse problems in holographic superconductivity, where data-driven approaches have successfully reconstructed physical parameters that align with experimental observations [6]. These advances highlight the growing synergy between machine learning and theoretical physics, enabling the exploration of new phenomena and the refinement of existing models. At the same time, the development of benchmarks for evaluating physical understanding, such as PhyGenBench, underscores the importance of ensuring that machine learning models not only fit data but also capture the essential principles governing physical systems [7]. In parallel, efforts to enforce logical and physical consistency in models, such as the integrity criteria proposed for hybrid physics-black-box systems, emphasize the need for rigorous constraints to prevent models from producing unphysical results [5]. These methodologies are not only relevant to cosmological studies but also to a wide range of physical systems, from quantum dynamics to fluid mechanics. As the field continues to evolve, the interplay between data-driven modeling and physical theory will play a crucial role in resolving the outstanding tensions and anomalies that challenge our understanding of the universe. The ongoing refinement of these techniques promises to provide deeper insights into the fundamental laws that govern both the smallest particles and the largest structures in the cosmos.

## Current State of the Art

The current state of the art in the field of cosmological tensions and anomalies in particle physics and cosmology is marked by a growing integration of artificial intelligence (AI) and machine learning (ML) techniques with traditional physical models. This convergence has enabled researchers to address long-standing challenges, such as the discrepancy between early and late universe measurements of the Hubble constant, the nature of dark matter and dark energy, and the anomalies observed in cosmic microwave background (CMB) data. The application of AI in these domains has not only enhanced the precision of theoretical predictions but also provided new insights into the underlying physical mechanisms governing the universe. Recent advancements in AI-driven data analysis have significantly improved the ability to extract meaningful information from complex and high-dimensional datasets. For instance, in the context of exoplanetary science, AI-based frameworks have been employed to identify atmospheric features and correlations that were previously difficult to discern. These techniques have revealed new trends, such as the "Clear Sky Corridor" in exoplanet atmospheres, where specific temperature ranges correlate with observable spectral features, suggesting that metallicity and aerosol formation play a crucial role in shaping planetary atmospheres [8]. Such findings have implications for understanding the formation and evolution of planetary systems, which in turn informs broader cosmological models. In particle physics, the development of lightweight deep learning models has demonstrated that high-performance results can be achieved with significantly reduced computational resources. These models, which employ novel architectures such as 3D convolutions and attention mechanisms, have shown superior performance in tasks like particle flow energy reconstruction, where accurate modeling of spatiotemporal correlations is essential [9]. This efficiency is particularly valuable in high-energy physics experiments, where data volumes are vast and computational constraints are tight. Moreover, the use of hybrid loss functions combining structural and statistical measures has improved the robustness of these models, making them more reliable in both interpolation and extrapolation scenarios. The application of equivariant representations in molecular systems has also influenced the broader field of physics, particularly in the context of symmetry-preserving models. By analyzing how different representations are utilized in predictive tasks, researchers have gained a better understanding of how to design models that respect the underlying physical symmetries [10]. This principle is directly applicable to cosmology and particle physics, where symmetries play a fundamental role in shaping the behavior of fundamental particles and the structure of the universe. In the realm of visual grounding and dynamic modeling, the integration of physical laws with learned corrections has opened new avenues for simulating complex systems. Techniques such as particle-GS, which enable back-propagation of image gradients to optimize physical simulators, have shown promise in capturing intrinsic dynamics with high accuracy [12]. These methods are particularly relevant to cosmology, where the simulation of large-scale structures and the behavior of dark matter require precise and efficient modeling approaches. The development of data-driven holographic models has further demonstrated the potential of AI in bridging the gap between theoretical physics and empirical observations. By training neural networks on experimental phase transition data, researchers have been able to reproduce phase diagrams that were previously only accessible through complex theoretical frameworks [7]. This approach not only validates existing models but also provides a flexible and scalable framework for exploring new physical regimes. Across these diverse applications, a common theme emerges: the increasing reliance on data-driven methodologies to enhance the accuracy, interpretability, and generalizability of physical models. This trend is supported by the growing availability of large-scale datasets and the development of efficient algorithms that can handle the complexity of modern scientific problems. Techniques from natural language processing, such as positional embeddings and transformer architectures, are being adapted to other domains, further expanding the toolkit available to researchers. Despite these advances, several challenges remain. The interpretation of AI models in scientific contexts is still an open issue, as many deep learning methods operate as "black boxes" that are difficult to analyze. Additionally, the generalization of these models to unseen data and the incorporation of physical constraints without sacrificing performance are ongoing areas of research. Addressing these challenges will be critical for ensuring that AI-based approaches continue to contribute meaningfully to our understanding of the universe. In summary, the current state of the art in cosmological tensions and anomalies in particle physics and cosmology is characterized by a dynamic interplay between AI and physics. The integration of machine learning techniques with domain-specific knowledge has led to significant improvements in modeling accuracy, computational efficiency, and interpretability. As the field continues to evolve, the development of more robust, interpretable, and generalizable models will be essential for addressing the remaining mysteries of the cosmos.

## Future Directions

The future of research on cosmological tensions and anomalies in particle physics and cosmology is poised to benefit significantly from the integration of advanced machine learning (ML) techniques with traditional physical modeling. As the field grapples with discrepancies between observational data and theoretical predictions—such as the Hubble tension, the matter density discrepancy, and anomalies in the cosmic microwave background—there is a growing need for robust, interpretable, and generalizable models that can navigate the complex interplay between theory and data. Recent advances in ML, particularly in areas like probabilistic modeling, data augmentation, and differentiable programming, offer promising avenues for addressing these challenges. One of the key directions for future research lies in the development of more sophisticated probabilistic frameworks that can handle the inherent uncertainties in cosmological data. Techniques such as kernel mean embeddings and variational inference, as demonstrated in [20], provide a means to approximate complex probability distributions in a computationally feasible manner. These methods could be extended to cosmological inference tasks, enabling more accurate parameter estimation and model selection in the presence of noisy or incomplete data. Moreover, the use of Fokker-Planck transport methods, which provide a gradient flow interpretation of KL divergence under the 2-Wasserstein distance, could lead to more efficient sampling strategies for Bayesian cosmological analysis. Another important area is the enhancement of data-driven approaches through the application of advanced ML architectures. For instance, the use of convolutional neural networks (CNNs) for real-time fault detection in spacecraft sensors, as explored in [13], suggests that similar techniques could be applied to anomaly detection in cosmological datasets. The success of CNNs in handling multivariate time series data highlights the potential for deep learning to uncover hidden patterns in large-scale cosmological surveys. Additionally, the concept of time series viewmakers, as introduced in [17], offers a novel approach to data augmentation that could improve the robustness of ML models trained on sparse or noisy cosmological data. The development of interpretable models remains a critical challenge, particularly in the context of high-dimensional data and complex physical systems. Techniques such as tensor network-based quantum-probabilistic learning, as described in [14], provide insights into the scaling behavior of models and their generalization capabilities. These findings could inform the design of more transparent ML models that are better suited for cosmological applications, where interpretability is essential for validating theoretical predictions. Furthermore, the discovery of universal scaling laws in quantum-probabilistic models suggests that similar principles may apply to cosmological ML frameworks, offering a theoretical foundation for model development. The integration of differentiable programming with physical simulations, as demonstrated in [18], presents a powerful paradigm for developing ML-driven models of cosmological phenomena. By enabling gradient-based optimization of physical systems, differentiable programming can facilitate the training of models that incorporate both observational data and physical laws. This approach could be particularly valuable in the context of cosmological simulations, where the accurate representation of physical processes is crucial. Additionally, the use of differentiable programming in plasma physics suggests that similar techniques could be applied to the modeling of cosmic plasmas and other astrophysical systems. The importance of robustness and generalizability in ML models cannot be overstated, especially when applied to cosmological data that often exhibit complex structures and non-stationarities. The findings from papers such as [11] and [15] highlight the value of data augmentation and historical data-based learning in improving model performance. These insights could be extended to cosmological applications, where the ability to predict critical transitions or detect anomalies in evolving systems is of paramount importance. Moreover, the use of neural quasiprobabilistic likelihood ratio estimation, as described in [16], offers a novel approach to handling negatively weighted data, which could be particularly useful in cosmological inference tasks involving rare events or complex likelihood surfaces. In summary, the future of cosmological tensions and anomalies research will likely be shaped by the continued convergence of machine learning and physics-based modeling. The development of more interpretable, robust, and generalizable models, combined with the integration of advanced probabilistic and differentiable programming techniques, will be essential for addressing the challenges posed by current observational data. As the field progresses, the insights gained from these interdisciplinary approaches will not only enhance our understanding of the universe but also open new avenues for theoretical and computational exploration.

## Conclusion

The conclusion of the survey paper on "Cosmological Tensions and Anomalies in Particle Physics and Cosmology" synthesizes the key findings and contributions that have emerged from the ongoing exploration of discrepancies between observational data and theoretical models. The paper has highlighted that cosmological tensions, such as the Hubble constant (H₀) discrepancy, anomalies in the cosmic microwave background (CMB), and inconsistencies in large-scale structure, pose significant challenges to the standard ΛCDM model. These issues suggest that our current understanding of the universe may be incomplete, necessitating a reevaluation of fundamental assumptions in both particle physics and cosmology. The current state of the field reflects a growing recognition of the need for more sophisticated analytical tools and theoretical frameworks. The integration of artificial intelligence (AI) and machine learning (ML) techniques with traditional physical models has shown promise in addressing these tensions, offering new avenues for data analysis, model fitting, and hypothesis testing. These computational advancements have enabled researchers to explore complex datasets with greater precision and to identify subtle patterns that may point toward new physics beyond the standard model. Looking ahead, future research should focus on developing more robust and interpretable machine learning models that can be seamlessly integrated with physical theories. There is also a pressing need for improved observational data, particularly from next-generation surveys and experiments, to resolve existing discrepancies and uncover new anomalies. Additionally, interdisciplinary collaboration between particle physicists, cosmologists, and data scientists will be essential in advancing our understanding of the universe's fundamental structure and evolution. Despite significant progress, many challenges remain, including the interpretation of anomalies, the validation of new models, and the development of a unified theoretical framework that can reconcile observational data with existing theories. As the field continues to evolve, it is clear that the study of cosmological tensions and anomalies will remain a critical area of research, driving innovation and deepening our comprehension of the cosmos. The journey to resolve these mysteries is not only a scientific endeavor but also a testament to the enduring quest for knowledge about the universe and our place within it.

## References

1. A Foundation Model for the Solar Dynamics Observatory

2. Modelling the longevity of complex living systems

3. Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling

4. FAIR Universe HiggsML Uncertainty Dataset and Competition

5. Structural Constraints for Physics-augmented Learning

6. Entanglement, ${T

7. Phase Diagram from Nonlinear Interaction between Superconducting Order and Density: Toward Data-Based Holographic Superconductor

8. The Clear Sky Corridor: Insights Towards Aerosol Formation in Exoplanets Using An AI-based Survey of Exoplanet Atmospheres

9. Lightweight Deep Learning Framework for Accurate Particle Flow Energy Reconstruction

10. Deconstructing equivariant representations in molecular systems

11. Interdependency Matters: Graph Alignment for Multivariate Time Series Anomaly Detection

12. Multi-modal Fusion Based Q-Distribution Prediction for Controlled Nuclear Fusion

13. Convolutional Neural Network Design and Evaluation for Real-Time Multivariate Time Series Fault Detection in Spacecraft Attitude Sensors

14. Universal scaling laws in quantum-probabilistic machine learning by tensor network towards interpreting representation and generalization powers

15. Learning from the past: predicting critical transitions with machine learning trained on surrogates of historical data

16. Neural quasiprobabilistic likelihood ratio estimation with negatively weighted data

17. Time Series Viewmakers for Robust Disruption Prediction

18. Differentiable Programming for Computational Plasma Physics

19. From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning

20. Deterministic Fokker-Planck Transport -- With Applications to Sampling, Variational Inference, Kernel Mean Embeddings & Sequential Monte Carlo
