# Artificial Intelligence in Psychological Research: A Comprehensive Survey

## Abstract

**Abstract** The integration of Artificial Intelligence (AI) into psychological research has emerged as a transformative force, offering innovative tools for understanding human cognition, behavior, and mental health. This survey paper provides a comprehensive overview of the current state of AI applications in psychology, tracing its evolution from early technical explorations to contemporary research focused on clinical and cognitive applications. The paper examines key areas such as mental health classification, personalized intervention, and cognitive modeling, highlighting the role of machine learning, natural language processing, and deep learning in advancing psychological assessment and treatment. While the current state of the art demonstrates significant progress in improving diagnostic accuracy and therapeutic personalization, challenges remain in ensuring interpretability, ethical compliance, and alignment with psychological theory. Future directions emphasize the need for more sophisticated AI models that better capture the nuances of human behavior, as well as interdisciplinary collaboration to address methodological and ethical concerns. This paper contributes to the growing discourse on AI in psychology by synthesizing existing research, identifying gaps, and outlining potential pathways for further development. By bridging technical advancements with psychological insights, this survey aims to guide future research and application in this rapidly evolving field.

## Keywords

large language models, multimodal learning, natural language processing, machine learning, artificial intelligence

## Introduction

Artificial Intelligence (AI) has increasingly become a transformative force across multiple domains, including psychology, where it is being leveraged to enhance understanding, assessment, and intervention in human behavior and mental health. The integration of AI into psychological research has opened new avenues for exploring complex cognitive processes, improving diagnostic accuracy, and developing personalized therapeutic strategies. Over the past decade, the application of AI in psychological contexts has expanded significantly, driven by advancements in machine learning, natural language processing, and multimodal data analysis. This survey paper aims to provide a comprehensive overview of the current state of AI in psychological research, highlighting key developments, challenges, and future directions. The use of AI in psychological research is not merely a technological enhancement but a paradigm shift that redefines how psychological phenomena are studied, modeled, and applied in real-world settings. One of the most prominent areas where AI has made an impact is in the development of virtual reality (VR) systems as psychological countermeasures, particularly in isolated and confined environments (ICEs) such as space missions or remote work settings. While VR has shown promise in promoting relaxation, improving mood, and supporting cognitive training, the application of AI in these contexts remains underexplored, as noted in a scoping review that found no eligible AI-based psychological countermeasure studies [6]. This gap underscores the need for further research into how AI can be integrated into VR-based interventions to enhance their effectiveness and adaptability. Concurrently, AI has been increasingly applied in educational settings, where it plays a role in data mining, assessment design, and personalized learning. Studies have compared symbolic, sub-symbolic, and neural-symbolic AI methods, emphasizing the importance of interpretability and generalizability in AI systems used for educational purposes [3]. These findings suggest that AI's role in psychology is not limited to clinical applications but extends to broader cognitive and developmental domains. The growing reliance on AI in psychological research also raises important questions about its limitations and ethical implications. For instance, while AI has been used in physics for over 30 years to analyze complex datasets, its application in psychology requires careful consideration of its societal impact and potential biases [8]. Similarly, the concept of Artificial General Intelligence (AGI) remains a topic of intense debate, with no consensus on its definition or feasibility [1]. This lack of clarity highlights the need for a more nuanced understanding of AI's capabilities and limitations, particularly when applied to human-centric domains like psychology. Furthermore, the use of AI in education has prompted concerns about academic integrity and the reliability of AI detection tools, leading to the development of AI-resilient assessment strategies that encourage critical thinking [2]. These issues reflect a broader trend in AI research, where the focus is shifting from mere performance metrics to the ethical, social, and interpretative dimensions of AI systems. Another significant development in AI-driven psychological research is the use of embedding techniques in multimodal machine learning for mental illness assessment. By combining textual, visual, and physiological data, researchers are able to develop more accurate and context-aware models of psychological states [7]. This approach not only enhances diagnostic precision but also supports the development of personalized interventions tailored to individual needs. In parallel, the application of AI in detecting conditions such as PTSD through clinical interviews has demonstrated the potential of natural language processing (NLP) and large language models (LLMs) to analyze complex linguistic patterns [4]. However, these advancements also raise concerns about data privacy, algorithmic bias, and the need for transparent and accountable AI systems. As AI continues to permeate psychological research, there is an increasing demand for frameworks that ensure responsible and trustworthy AI use, particularly in sensitive domains where human well-being is at stake. The evolving landscape of AI in psychological research is also shaped by the need for human-centered approaches that prioritize interpretability, collaboration, and ethical considerations. Studies have emphasized the importance of integrating cognitive, motivational, and metacognitive factors into AI models to improve their relevance and applicability in real-world settings [3]. This human-in-the-loop approach not only enhances the reliability of AI systems but also fosters trust among users and stakeholders. Moreover, the intersection of AI with other fields, such as law, democracy, and health, has highlighted the broader implications of AI deployment, calling for interdisciplinary collaboration and policy development [5]. As AI continues to reshape psychological research, it is essential to address these challenges and opportunities through a holistic and inclusive approach that balances innovation with responsibility.

## Background

Artificial Intelligence (AI) has increasingly become a transformative force across various domains, and its integration into psychological research is no exception. The evolution of AI, particularly in natural language processing and machine learning, has opened new avenues for understanding human cognition, emotion, and behavior. Early explorations in AI have been marked by a focus on technical capabilities, but recent studies have shifted toward examining the psychological and ethical dimensions of AI systems, particularly their interactions with humans. This shift is reflected in the growing body of literature that explores how AI can influence emotional well-being, trust, and even the perception of human nature. For instance, research has shown that AI chatbots can enhance happiness, especially when engaging in conversations about negative topics, due to their ability to mirror sentiment and exhibit a positivity bias [9]. Such findings suggest that AI is not merely a tool for data processing but also a medium through which emotional and psychological dynamics can be studied and potentially influenced. The increasing sophistication of large language models (LLMs) has further complicated the landscape, as these systems are now capable of simulating complex human-like interactions. However, this advancement raises important questions about the psychological implications of such interactions. For example, studies have revealed that LLMs may exhibit a systemic distrust in humans, with a negative correlation between model intelligence and trust in human nature [10]. This finding underscores the need for a deeper understanding of how AI systems perceive and interact with humans, and how these perceptions might shape user experiences and behaviors. Additionally, the use of AI in psychological research has led to the development of new methodologies, such as the creation of psychological scales to assess AIâ€™s attitudes toward human nature, as well as the application of computational models to analyze sentiment and emotional responses [10]. These innovations highlight the interdisciplinary nature of AI in psychology, where technical advancements are paired with psychological insights to create more nuanced and effective research tools. Beyond the emotional and cognitive aspects, AI is also being explored for its potential to enhance knowledge acquisition and reasoning. One notable contribution is the theoretical framework that distinguishes between "knowledge that" and "knowledge why," emphasizing the importance of causal understanding in AI systems [11]. This distinction has significant implications for psychological research, as it suggests that AI models must go beyond pattern recognition and probabilistic inference to achieve a deeper, more human-like understanding of the world. Furthermore, the application of AI in psychological studies has led to the development of new experimental designs, including randomized controlled trials and large-scale data analyses, which have provided valuable insights into the effects of AI on emotional well-being and user behavior [12]. These methodological advancements have not only improved the rigor of AI research but have also expanded the scope of psychological inquiry, enabling researchers to explore complex phenomena that were previously difficult to study. Despite these advancements, the integration of AI into psychological research is not without challenges. Ethical concerns, such as the potential for AI to influence human behavior in unintended ways, have sparked debates about the responsibility of developers and researchers. Additionally, the reliance on AI for psychological assessments and interventions raises questions about the validity and reliability of such tools. For example, while some studies suggest that AI can improve well-being through supportive conversations, others highlight the risk of dependency and the need for careful monitoring of user engagement [12]. These contrasting viewpoints underscore the complexity of AI's role in psychological research and the need for continued investigation into its long-term effects. As AI continues to evolve, it is clear that its impact on psychological research will be both profound and multifaceted, requiring a balanced approach that considers both its potential and its limitations.

## Current State of the Art

The integration of artificial intelligence (AI) into psychological research has advanced significantly in recent years, driven by improvements in machine learning, natural language processing, and data analytics. Current research demonstrates a growing emphasis on leveraging AI for tasks ranging from mental health classification and clinical decision support to personalized learning and cognitive modeling. One notable development is the application of deep learning techniques to mental health data, as seen in the LatentGLoss approach, which enhances text classification in mental health by employing a teacher-student architecture with a novel loss function [21]. This method underscores the importance of model design and the adaptation of loss functions to better capture the nuances of psychological data. Similarly, AI-based clinical decision support systems have gained traction, with studies highlighting the need for more realistic and ecologically valid evaluations that go beyond traditional metrics like trust and reliance [22]. These systems are increasingly being designed to support, rather than replace, human expertise, reflecting a broader trend toward human-AI collaboration in psychological research and practice. The evaluation of AI systems has also evolved, with a focus on both task-specific and general intelligence benchmarks. The AGITB benchmark, for instance, provides a rigorous framework for assessing artificial general intelligence through signal-level tasks that reflect fundamental computational invariants [13]. In contrast, the AI Index Report 2025 offers a comprehensive overview of AI trends, including hardware advancements, inference costs, and corporate AI ethics, serving as a valuable resource for policymakers and researchers [19]. These efforts highlight the need for standardized metrics and benchmarks to assess AI performance in psychological contexts, ensuring that models are not only accurate but also interpretable and aligned with human cognitive processes. Despite these advancements, there remains a significant gap between the expectations and the reality of AI adoption in psychological research. Studies on AI in software testing, for example, reveal that while AI holds promise, its real-world impact has been limited, with many systems failing to deliver on their potential [14]. This trend is echoed in the healthcare domain, where AI-based clinical decision support systems often struggle to translate theoretical success into practical benefits. Such findings emphasize the importance of responsible AI practices, including transparency, explainability, and ethical considerations, which are increasingly being integrated into AI design and deployment [20]. Moreover, the role of human-AI interaction has become a central theme in psychological research. Studies on AI-assisted decision-making, such as those exploring how AI can support complex decision-making by providing different kinds of cognitive support, suggest that the most effective AI systems are those that enhance human capabilities rather than replace them [18]. This perspective is further reinforced by research on human-AI teaming, which highlights the need for adaptive, context-aware systems that can dynamically adjust to user needs and preferences [16]. In addition to these developments, there is growing interest in the use of AI for personalized learning and educational applications. Research on Socratic tutors and AI-driven learning systems demonstrates the potential of AI to support research question development and student reflection, with some studies exploring multi-agent strategies for automated assessment [17]. These approaches not only improve the efficiency of educational processes but also enhance the quality of learning by providing tailored feedback and support. Similarly, the application of AI in persona development and agent-based modeling has opened new avenues for understanding human behavior and decision-making in complex environments [15]. Overall, the current state of the art in AI for psychological research reflects a dynamic and rapidly evolving field. While significant progress has been made in areas such as mental health classification, clinical decision support, and human-AI collaboration, challenges remain in terms of evaluation, ethical considerations, and real-world implementation. Future research will likely focus on bridging the gap between theoretical advancements and practical applications, ensuring that AI systems are not only powerful but also trustworthy, interpretable, and aligned with the needs of psychological science and human users.

## Future Directions

The integration of artificial intelligence (AI) into psychological research has opened new frontiers in understanding human cognition, behavior, and mental health. As the field continues to evolve, several future directions emerge, driven by the insights and challenges identified in recent studies. One critical area of development lies in the refinement of AI systems to better align with the complexities of human psychological processes. Research has shown that large language models (LLMs) can exhibit computational structures that mirror psychopathological patterns, suggesting that AI may not only simulate but also, in some ways, replicate aspects of mental disorders [25]. This raises important questions about the ethical implications of such capabilities, particularly in clinical and therapeutic settings. Future work should focus on developing more nuanced models that can distinguish between simulation and genuine psychological phenomena, while also addressing the potential risks of AI reinforcing or misrepresenting mental health conditions. Another significant direction involves the enhancement of explainability and transparency in AI systems, especially within health and well-being applications. Current efforts in this area emphasize the need for structured evaluation frameworks that go beyond traditional metrics, incorporating real-world usability and contextual relevance [26]. As AI becomes more integrated into psychological research and clinical decision-making, the ability of these systems to provide clear, interpretable explanations will be crucial for building trust and ensuring responsible deployment. This includes not only technical advancements in model interpretability but also the development of user-centered evaluation methods that consider the diverse needs of researchers, clinicians, and patients. Human-AI interaction in mental health contexts remains a key area of focus, with growing concerns about the psychological effects of emotionally engaging AI systems. Studies have highlighted the potential for such interactions to lead to psychological deterioration, particularly in vulnerable populations [28]. Future research should explore ways to safeguard these interactions, ensuring that AI tools support rather than harm mental health. This may involve the development of adaptive systems that can recognize and respond to user emotional states, as well as the implementation of ethical guidelines that govern the design and deployment of AI in mental health applications. The evaluation of AI systems in psychological research also requires more rigorous and ecologically valid approaches. Traditional metrics, such as trust and reliance, have been critiqued for their inadequacy in capturing the real-world utility of AI-based clinical decision support systems [22]. Future work should prioritize the creation of context-specific evaluation frameworks that account for the dynamic and often unpredictable nature of psychological and mental health interventions. This includes the use of longitudinal studies, real-world deployment trials, and interdisciplinary collaboration between AI researchers, psychologists, and clinicians. Ethical and safety considerations remain central to the future of AI in psychological research. As AI systems become more capable and pervasive, the risks associated with their misuse or misinterpretation grow. Studies have pointed to the need for comprehensive fairness assessments, ensuring that AI models do not perpetuate biases or disparities in mental health care [23]. Additionally, the potential for AI to influence human behavior and cognition, as seen in the framing of psychological phenomena, necessitates careful scrutiny [24]. Future research should address these concerns through the development of robust ethical frameworks, regulatory standards, and ongoing monitoring of AI impacts on psychological well-being. Finally, the intersection of AI with cognitive science and neural data analysis presents new opportunities for advancing our understanding of human cognition. Techniques such as sequence modeling for by-trial decoding of cognitive strategies and adversarial learning for multi-site fMRI mental disorder identification demonstrate the potential for AI to uncover novel insights into brain function and behavior [27]. These developments suggest that AI will play an increasingly important role in both theoretical and applied psychological research, offering tools to analyze complex data and generate hypotheses that were previously inaccessible. As the field moves forward, interdisciplinary collaboration and a commitment to ethical, transparent, and user-centered AI design will be essential in realizing the full potential of these technologies.

## Conclusion

The integration of artificial intelligence (AI) into psychological research has emerged as a pivotal development, offering novel methodologies for understanding human cognition, emotion, and behavior. This paper has explored the transformative role of AI in psychological research, highlighting its capacity to enhance diagnostic accuracy, support clinical decision-making, and enable personalized interventions. Key contributions include the application of machine learning and natural language processing to analyze behavioral patterns, the use of deep learning for mental health classification, and the development of AI-driven tools for cognitive modeling and therapeutic support. These advancements underscore the potential of AI to complement and expand traditional psychological approaches, fostering more efficient and effective research and clinical practices. The current state of the field reflects significant progress, with AI technologies increasingly being embedded in psychological studies, clinical assessments, and therapeutic applications. Researchers have demonstrated the effectiveness of AI in identifying mental health conditions from unstructured data, predicting behavioral outcomes, and supporting personalized treatment plans. However, challenges remain, particularly in ensuring the ethical use of AI, addressing biases in algorithmic decision-making, and maintaining the human element in psychological care. Looking ahead, future research should focus on refining AI systems to better capture the nuances of human psychological processes, improving interpretability and transparency, and fostering interdisciplinary collaboration between psychologists, computer scientists, and ethicists. Additionally, there is a need for robust validation of AI tools in diverse populations and real-world settings. Addressing these challenges will be essential to ensuring that AI serves as a reliable and equitable tool in psychological research and practice. In conclusion, AI holds great promise for advancing psychological research, but its successful integration requires careful consideration of technical, ethical, and practical dimensions. As the field continues to evolve, ongoing dialogue and innovation will be crucial to harnessing AI's full potential in ways that benefit both researchers and individuals seeking psychological support.

## References

1. Beyond Detection: Designing AI-Resilient Assessments with Automated Feedback Tool to Foster Critical Thinking

2. Resonance: Drawing from Memories to Imagine Positive Futures through AI-Augmented Journaling

3. Towards Responsible and Trustworthy Educational Data Mining: Comparing Symbolic, Sub-Symbolic, and Neural-Symbolic AI Methods

4. Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models

5. Tasks and Roles in Legal AI: Data Curation, Annotation, and Verification

6. Virtual Reality and Artificial Intelligence as Psychological Countermeasures in Space and Other Isolated and Confined Environments: A Scoping Review

7. Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment

8. What is AI, what is it not, how we use it in physics and how it impacts... you

9. Increasing happiness through conversations with artificial intelligence

10. Measurement of LLM's Philosophies of Human Nature

11. How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics

12. Investigating Affective Use and Emotional Well-being on ChatGPT

13. AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence

14. Expectations vs Reality -- A Secondary Study on AI Adoption in Software Testing

15. How Is Generative AI Used for Persona Development?: A Systematic Review of 52 Research Articles

16. Unraveling Human-AI Teaming: A Review and Outlook

17. Resurrecting Socrates in the Age of AI: A Study Protocol for Evaluating a Socratic Tutor to Support Research Question Development in Higher Education

18. AI, Help Me Think${x2014

19. Artificial Intelligence Index Report 2025

20. Trustworthy AI Must Account for Interactions

21. A new training approach for text classification in Mental Health: LatentGLoss

22. Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support

23. Enhancements for Developing a Comprehensive {AI

24. "i am a stochastic parrot, and so r u": Is AI-based framing of human behaviour and cognition a conceptual metaphor or conceptual engineering?

25. Emergence of psychopathological computations in large language models

26. Towards an Evaluation Framework for Explainable Artificial Intelligence Systems for Health and Well-Being

27. Semantic Commit: Helping Users Update Intent Specifications for {AI

28. EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety
