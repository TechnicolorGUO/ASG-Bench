# Subjective Well-Being in Psychology: A Comprehensive Survey

## Abstract

**Abstract** Subjective well-being (SWB), a central construct in psychology, encompasses an individual's cognitive evaluations and affective experiences of their life. This survey paper provides a comprehensive overview of the evolution, current state, and future directions of SWB research. Historically, SWB has been rooted in hedonic theories, but contemporary models now integrate psychological, social, and neuroscientific perspectives. The paper highlights the shift from traditional self-report measures to advanced methodologies, including the application of artificial intelligence (AI) and machine learning (ML) to analyze multimodal data such as speech, facial expressions, and eye-tracking. These innovations have enhanced the depth and accuracy of SWB assessments, offering new insights into emotional and cognitive processes. Furthermore, the paper addresses the growing need for culturally sensitive and interpretable assessment tools, particularly in the context of AI-driven systems like large language models. By synthesizing key findings and trends, this review underscores the interdisciplinary nature of SWB research and its potential to inform interventions aimed at improving mental health and quality of life. The contributions of this paper lie in its critical evaluation of methodological advances and its identification of emerging challenges and opportunities, providing a foundation for future research in this dynamic field.

## Keywords

large language models, multimodal learning, natural language processing, machine learning, artificial intelligence

## Introduction

Subjective well-being, often referred to as happiness or life satisfaction, has long been a central topic in psychology, reflecting the complex interplay between individual experiences, social contexts, and cognitive processes. Over the past few decades, the study of subjective well-being has evolved from purely theoretical frameworks to more empirically grounded investigations, incorporating insights from cognitive science, neuroscience, and increasingly, artificial intelligence. The integration of computational methods, particularly natural language processing (NLP) and large language models (LLMs), has opened new avenues for understanding how individuals perceive and express their well-being. Recent studies have shown that personality traits and demographic factors significantly influence the subjective evaluation of experiences, suggesting that models of well-being must account for individual differences to be effective [1]. This has led to the development of more nuanced approaches that go beyond simplistic measures, emphasizing the need for personalized and context-sensitive assessments. In parallel, the role of causality in human-robot interaction (HRI) has been explored as a means to enhance the adaptability of robotic systems in mental well-being coaching, demonstrating that models grounded in causal reasoning can better explain and predict human behaviors [2]. These findings highlight the importance of not only capturing the surface-level expressions of well-being but also understanding the underlying mechanisms that shape them. At the same time, the evaluation of personality tests and the alignment of AI systems with human values have revealed both the potential and the limitations of machine-based assessments. While LLMs have shown promise in certain aspects of content validity, human expertise remains indispensable in handling complex, behaviorally rich items [1]. This suggests that the future of well-being research may lie in hybrid systems that combine the strengths of human judgment and machine learning. Additionally, the growing interest in moral reasoning and ethical alignment has prompted the development of benchmarks to assess how well AI systems align with human moral standards, particularly in the context of utilitarian dilemmas [15]. These efforts underscore the broader implications of well-being research, extending beyond individual psychology to the design of ethical and socially responsible AI. As the field continues to advance, the challenge remains to develop models that are not only accurate but also interpretable, adaptable, and aligned with the diverse and dynamic nature of human experience. The convergence of psychology and AI thus presents both opportunities and challenges, calling for interdisciplinary collaboration to ensure that technological innovations contribute meaningfully to the understanding and enhancement of subjective well-being.

## Background

Subjective well-being, a central construct in psychology, refers to an individual's evaluation of their life and emotional experiences, encompassing both cognitive judgments and affective states. Over the decades, it has garnered significant attention due to its relevance in understanding human happiness, mental health, and quality of life. The concept has evolved from early hedonic theories, which emphasized the balance of pleasure and pain, to more contemporary models that incorporate psychological needs, personal goals, and social relationships. Researchers have explored various dimensions of well-being, such as emotional well-being, psychological well-being, and social well-being, each contributing to a more nuanced understanding of what it means to lead a fulfilling life. In recent years, the integration of artificial intelligence (AI) into psychological research has opened new avenues for studying and enhancing subjective well-being, particularly through the development of conversational agents, personalized mental health interventions, and advanced analytical tools. These innovations have been driven by the increasing availability of large-scale datasets and the advancement of machine learning techniques, which enable more accurate and contextually relevant assessments of emotional and psychological states. For instance, the MentalChat16K dataset has provided a valuable resource for training and evaluating AI models in mental health assistance, offering a diverse range of conversational scenarios that reflect real-world challenges faced by individuals seeking emotional support [3]. Similarly, studies on anxiety level detection have demonstrated the potential of AI to identify and respond to emotional distress with high accuracy, using transformer-based models that can generate personalized guidance based on contextual cues [5]. These developments highlight the growing role of AI in mental health, where the focus is not only on diagnosis and intervention but also on fostering empathetic and meaningful interactions. However, the application of AI in psychological domains raises important ethical and methodological considerations, including issues of privacy, bias, and the need for interpretability. The CLASH dataset, for example, underscores the limitations of current language models in handling value-based reasoning and high-stakes moral dilemmas, suggesting that AI systems must be designed with a deeper understanding of human values and decision-making processes [4]. Furthermore, the integration of AI into mental health ecosystems requires careful attention to human-AI collaboration, ensuring that technology serves as a supportive tool rather than a replacement for human expertise. As research continues to advance, the intersection of psychology and AI presents both opportunities and challenges, calling for interdisciplinary approaches that combine insights from cognitive science, ethics, and computational modeling. The ongoing exploration of subjective well-being in this evolving landscape reflects a broader commitment to improving mental health outcomes through innovative and responsible technological solutions.

## Current State of the Art

The study of subjective well-being (SWB) has seen significant advancements in recent years, particularly with the integration of artificial intelligence (AI) and machine learning (ML) techniques into psychological research. Contemporary approaches have moved beyond traditional self-report measures and observational studies, incorporating multimodal data sources such as eye-tracking, facial expressions, and speech to gain deeper insights into emotional and psychological states. AI-based methods have shown promise in detecting and modeling psychological conditions, with applications ranging from mental health screening to personalized emotional support systems. For instance, AI-driven models utilizing convolutional neural networks (CNNs) on eye-gaze data have demonstrated moderate accuracy in distinguishing between individuals with depression and social anxiety, achieving up to 62\ In parallel, the role of large language models (LLMs) in psychological tasks has gained increasing attention. Studies have shown that models like GPT-4 can perform reliably in annotating emotion appraisal ratings, often matching or even surpassing human performance when provided with well-structured prompts and sufficient contextual information [12]. This suggests that LLMs can serve as valuable tools in psychological research, particularly in tasks involving emotional understanding and interpretation. Furthermore, research on the integration of psychological theory into AI systems has led to the development of stage-aware and deep-thinking models, such as DeepPsy-Agent, which incorporates principles from cognitive-behavioral therapy to enhance emotional support interventions [6]. These systems demonstrate that the fusion of psychological frameworks with AI can lead to more effective and contextually sensitive interventions. Another emerging area is the enhancement of affective theory-of-mind (ToM) in AI systems. Approaches such as Rank-O-ToM have introduced novel methods for capturing emotional nuances through ordinal ranking, allowing models to better understand and represent complex emotional states [10]. This advancement is particularly relevant for applications involving human-computer interaction, where the ability to interpret and respond to emotional cues is critical. Additionally, research into the modeling of emotions in face-to-face settings has emphasized the importance of integrating eye-tracking data, personality traits, and temporal dynamics to create more accurate and contextually rich representations of emotional experiences [11]. Beyond technical developments, the field has also begun to grapple with the ethical and philosophical implications of AI in psychological contexts. Papers such as "Palatable Conceptions of Disembodied Being" have raised important questions about the nature of consciousness, selfhood, and the limitations of current language in describing non-embodied entities [8]. These discussions are essential as AI systems become more integrated into mental health care, prompting a reevaluation of their role as ethical and adaptive co-creators rather than mere tools [9]. At the same time, efforts to align AI models with human values, such as through soft prompt tuning and adaptive interaction design, underscore the growing emphasis on creating systems that are not only effective but also culturally and ethically sensitive [7]. Despite these advancements, challenges remain in ensuring the reliability, validity, and generalizability of AI-based approaches to SWB. While some models excel in specific tasks, such as emotion annotation or mental health screening, their performance often depends on the quality and representativeness of the training data. Moreover, the integration of psychological theory into AI systems requires careful consideration of how to translate abstract concepts into computable frameworks. As the field continues to evolve, it is clear that the intersection of AI and psychology holds great promise for advancing our understanding of subjective well-being and improving mental health care through innovative, data-driven solutions.

## Future Directions

The future of research on subjective well-being in psychology is poised to benefit significantly from advancements in artificial intelligence, multimodal data integration, and the development of more interpretable and culturally sensitive assessment tools. As the field moves forward, there is a growing emphasis on enhancing the reliability and validity of psychological assessments, particularly in the context of large language models (LLMs) and other AI-driven systems. For instance, the Core Sentiment Inventory (CSI) has demonstrated the potential of implicit sentiment analysis to capture nuanced emotional patterns in LLMs, offering a more robust and context-aware approach to psychological trait evaluation compared to traditional self-reporting methods [16]. This suggests that future work should explore how such tools can be adapted for broader psychological research, including the assessment of well-being in human populations. Another critical direction involves the integration of multimodal and multilingual approaches to capture the complexity of subjective experiences. The use of multimodal data—such as text, facial expressions, and speech—has already shown promise in areas like depression detection and emotion recognition [18], [21]. Future studies should aim to develop more comprehensive frameworks that combine these modalities in a way that reflects the dynamic and context-dependent nature of well-being. Moreover, the multilingual capabilities of tools like CSI highlight the importance of designing assessments that are culturally and linguistically inclusive, ensuring that subjective well-being metrics are applicable across diverse populations. Interpretability and user customization are also emerging as key priorities in the development of psychological assessment tools. The QuestMF framework, for example, not only improves the accuracy of depression detection but also enhances interpretability by providing question-wise modality fusion [18]. This level of transparency is essential for building trust in AI-driven psychological assessments and for enabling clinicians to make informed decisions. Similarly, systems that integrate real-time emotion detection with personalized interventions, such as music recommendations, demonstrate the potential for AI to support emotional well-being in everyday contexts [21]. Future research should explore how such personalized and adaptive systems can be scaled and integrated into broader mental health care frameworks. The role of human-AI collaboration is another promising area for future exploration. While some studies have shown that LLMs can generate therapy notes that are comparable to those written by humans in terms of completeness and conciseness [19], there remains a gap in their ability to maintain faithfulness to the original content. This suggests that future work should focus on improving the alignment between AI-generated outputs and human intentions, ensuring that AI tools are not only accurate but also ethically sound and contextually appropriate. Additionally, the development of socially-aware AI systems, such as those that incorporate perspective-shifted neuro-symbolic models, highlights the potential for AI to better understand and navigate human social interactions [17]. Such advancements could lead to more empathetic and socially intelligent systems that support well-being in both individual and collective settings. Finally, the increasing sophistication of AI models necessitates a greater focus on ethical considerations, including the mitigation of biases and the prevention of harmful outputs. Recent studies have highlighted the risks associated with AI systems that lack self-awareness, such as the tendency to produce low-level visual hallucinations or to inadvertently reinforce unethical behaviors [20], [14]. As AI becomes more deeply integrated into psychological research and practice, it will be essential to develop robust evaluation protocols and safety mechanisms that ensure these systems are aligned with human values and well-being. Overall, the future of subjective well-being research in psychology will likely be shaped by a combination of technical innovation, ethical reflection, and a deeper understanding of the complex interplay between human emotions, social contexts, and AI capabilities.

## Conclusion

In conclusion, this survey paper has explored the multifaceted nature of subjective well-being (SWB) in psychology, highlighting its evolution from early theoretical constructs to a well-established area of empirical research. The paper has traced the conceptual development of SWB, emphasizing its dual components—cognitive evaluations of life and affective experiences—and its significance in understanding human happiness, mental health, and quality of life. The integration of cognitive science, neuroscience, and increasingly artificial intelligence has transformed the study of SWB, enabling more nuanced and data-driven analyses. The current state of the field reflects a dynamic and interdisciplinary landscape, where traditional self-report measures are being augmented by multimodal data sources and AI-driven analytical techniques. These innovations have enhanced the ability to capture the complexity of emotional and psychological states, offering new possibilities for both research and practical applications. However, challenges remain in ensuring the reliability, validity, and cultural sensitivity of these emerging methods. Looking ahead, future research on SWB should focus on refining AI-based assessment tools, improving the interpretability of machine learning models, and developing culturally responsive frameworks that account for diverse expressions of well-being. The integration of large language models and other AI technologies presents both opportunities and ethical considerations, particularly in terms of data privacy and algorithmic bias. Additionally, there is a need for longitudinal studies that examine the stability and change of SWB over time, as well as the role of environmental and socio-economic factors in shaping well-being. Ultimately, the study of subjective well-being continues to be a vital area of psychological inquiry, with the potential to inform policies, interventions, and technologies that promote human flourishing. As the field advances, it is essential to maintain a balanced approach that values both empirical rigor and humanistic insights, ensuring that the pursuit of well-being remains rooted in a deep understanding of the human experience.

## References

1. Modeling Subjectivity in Cognitive Appraisal with Language Models

2. Exploring Causality for HRI: A Case Study on Robotic Mental Well-being Coaching

3. MentalChat16K: {A

4. In Pursuit of Predictive Models of Human Preferences Toward AI Teammates

5. Exploring the Panorama of Anxiety Levels: A Multi-Scenario Study Based on Human-Centric Anxiety Level Detection and Personalized Guidance

6. DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System

7. Cultural Alignment in Large Language Models Using Soft Prompt Tuning

8. Palatable Conceptions of Disembodied Being

9. Position: Beyond Assistance -- Reimagining LLMs as Ethical and Adaptive Co-Creators in Mental Health Care

10. Rank-O-ToM: Unlocking Emotional Nuance Ranking to Enhance Affective Theory-of-Mind

11. Modelling Emotions in Face-to-Face Setting: The Interplay of Eye-Tracking, Personality, and Temporal Dynamics

12. Assessing the Reliability and Validity of GPT-4 in Annotating Emotion Appraisal Ratings

13. AI-Based Screening for Depression and Social Anxiety Through Eye Tracking: An Exploratory Study

14. Manipulation and the AI Act: Large Language Model Chatbots and the Danger of Mirrors

15. The Greatest Good Benchmark: Measuring LLMs' Alignment with Utilitarian Moral Dilemmas

16. Leveraging Implicit Sentiments: Enhancing Reliability and Validity in Psychological Trait Evaluation of LLMs

17. Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation

18. Enhancing Depression Detection via Question-wise Modality Fusion

19. TN-Eval: Rubric and Evaluation Protocols for Measuring the Quality of Behavioral Therapy Notes

20. Mitigating Low-Level Visual Hallucinations Requires Self-Awareness: Database, Model and Training Strategy

21. Emotion Detection and Music Recommendation System
