{
  "outline": [
    [
      1,
      "Literature Review: Review on model predictive control- an engineering perspective."
    ],
    [
      2,
      "Introduction and Research Motivation"
    ],
    [
      2,
      "Key Concepts and Foundational Principles"
    ],
    [
      2,
      "Historical Development and Milestones"
    ],
    [
      2,
      "Current State-of-the-Art Methods and Techniques"
    ],
    [
      2,
      "Applications and Industrial Case Studies"
    ],
    [
      2,
      "Challenges and Open Problems"
    ],
    [
      2,
      "Future Research Directions"
    ],
    [
      2,
      "Conclusion"
    ],
    [
      1,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "Literature Review: Review on model predictive control- an engineering perspective.",
      "level": 1,
      "content": "*Generated on: 2025-12-25 19:55:49*\n*Topic Index: 4/10*\n\n---\n\nThis research aims to synthesize the current body of knowledge on model predictive control (MPC) within engineering contexts. It will explore the theoretical foundations, historical development, state-of-the-art techniques, and practical applications across relevant domains such as process control, robotics, and autonomous systems. The review will critically assess implementation challenges, identify existing research gaps, and outline future research trajectories, providing a structured and rigorous analysis suitable for publication in a top-tier academic journal.# A Systematic Review of Model Predictive Control: An Engineering Perspective"
    },
    {
      "heading": "Introduction and Research Motivation",
      "level": 2,
      "content": "Model Predictive Control (MPC) has evolved from a specialized industrial process control algorithm into a versatile and powerful paradigm for the management of complex dynamic systems across a multitude of engineering domains. Its core philosophy, which involves using a predictive model to determine an optimal sequence of future control actions while explicitly respecting operational constraints, has proven to be exceptionally effective in industries where process optimization, safety, and efficiency are paramount [[6,7]]. The development and widespread adoption of MPC represent one of the most significant advancements in control engineering over the past four decades. The research motivation for this review stems from the profound impact of MPC on modern industry and its expanding influence in emerging fields such as robotics, autonomous systems, and energy management. Understanding its trajectory—from foundational principles to state-of-the-art implementations—is critical for engineers and researchers seeking to leverage its capabilities or contribute to its ongoing evolution.\n\nThe primary objective of this paper is to provide a comprehensive systematic literature review of MPC from an engineering perspective. This review aims to dissect the multifaceted nature of MPC by tracing its historical development, analyzing its key concepts and current methodologies, examining its diverse applications, and critically assessing the challenges that define the field's present state and future potential. By synthesizing findings from seminal works, influential review papers, and recent research, this report seeks to construct a holistic view of MPC. It will explore how the symbiotic relationship between theoretical advancement and practical implementation has driven its success, identify the persistent technical hurdles that limit its applicability, and illuminate the promising new frontiers being explored through integration with machine learning and advanced computing paradigms. Ultimately, this review aspires to serve as a foundational resource for understanding the current landscape of MPC and to highlight the open problems and future research directions that will shape its next decade of innovation.\n\nThe significance of this review lies in its attempt to bridge the gap between the foundational principles of MPC and its contemporary, often highly sophisticated, implementations. While many texts focus on either the theory or the application, this review integrates both, providing an engineering perspective that appreciates the real-world constraints and objectives that have historically guided MPC's development. It will address fundamental questions central to the field: How did a control method born in the petrochemical industry become applicable to autonomous vehicles? What makes it so effective at handling constraints, yet what inherent weaknesses does this strength create? What are the true computational bottlenecks, and can they be overcome? By answering these questions, this review provides not only a summary of the state of the art but also a framework for understanding the trade-offs and synergies that define the practice of MPC engineering today."
    },
    {
      "heading": "Key Concepts and Foundational Principles",
      "level": 2,
      "content": "At its core, Model Predictive Control is an advanced feedback control strategy designed to manage multivariable systems with explicit constraints [[6,7]]. Unlike conventional controllers such as Proportional-Integral-Derivative (PID) regulators, which operate based on current error, MPC uses a dynamic model of the system to predict its future behavior over a finite time horizon [[6]]. This predictive capability allows MPC to solve an online, constrained optimization problem at each sampling instant to determine the optimal sequence of control moves that will drive the system towards its goals while respecting physical and operational limits [[5]]. The first move in this optimized sequence is then applied to the plant, and the entire process is repeated at the next sampling time, a mechanism known as the receding horizon principle [[5]].\n\nThe defining characteristics of MPC can be distilled into several key concepts. First is **predictive modeling**. The accuracy of the system model is paramount, as it directly influences the quality of the predictions and, consequently, the effectiveness of the control action. Early industrial implementations relied on impulse response models due to their ease of identification from step tests [[5]]. However, the theoretical maturation of MPC in the 1990s saw a shift towards state-space representations, which offer a more general and robust framework for analysis and design [[1,2]]. Second is **constrained optimization**. One of MPC's greatest strengths is its native ability to handle hard constraints on inputs (e.g., actuator limits), outputs (e.g., product purity specifications), and states (e.g., temperature limits). This is achieved by embedding these constraints directly into the online optimization problem, preventing the controller from proposing actions that would violate them [[7]]. Third is the **receding horizon**. The optimization is performed over a finite prediction horizon, but only the first control move is implemented. The process is then repeated at the next time step with the horizon sliding forward in time, allowing the controller to react to new measurements and adapt its plan accordingly [[5]].\n\nThe theoretical underpinnings of MPC were solidified throughout the 1990s and early 2000s. A major milestone was the establishment of stability guarantees. Initially, nominal MPC was not inherently stable; however, a consensus emerged around the use of Lyapunov functions, terminal cost terms, and terminal state constraints to ensure asymptotic stability [[7]]. The seminal work of Mayne et al. (2000) provided a comprehensive treatment of stability and robustness, establishing the conditions under which MPC could be guaranteed to stabilize a system [[7]]. Another critical concept is robustness, which addresses the performance of the controller in the presence of uncertainty. Uncertainty can arise from disturbances, model inaccuracies, or estimation errors [[1,7]]. Nominal MPC, which performs an open-loop optimization, is suboptimal under uncertainty because it does not account for future disturbances. To address this, robust MPC formulations have been developed, such as those based on H-infinity (H∞) control or L∞-norm optimization, which aim to find control policies that perform well against worst-case scenarios within a bounded uncertainty set [[5,7]]. The distinction between deterministic MPC, which assumes perfect knowledge of the future, and stochastic MPC, which deals with probabilistic uncertainties, marks a significant divergence in the literature and requires fundamentally different approaches, particularly regarding the structure of the solution policy [[7]]."
    },
    {
      "heading": "Historical Development and Milestones",
      "level": 2,
      "content": "The history of Model Predictive Control is a compelling narrative of industrial pragmatism driving academic inquiry, leading to a mature and widely adopted technology. The genesis of MPC occurred in the late 1970s, a period characterized by rapid industrial adoption in the refining and petrochemical sectors, spurred by the need for greater process efficiency and tighter control [[2,3]]. Three landmark publications from this era laid the conceptual groundwork for the field: Richalet et al.'s \"Model Predictive Heuristic Control\" (1978), Cutler and Ramaker's \"Dynamic Matrix Control\" (DMC) (1980), and Clarke, Mohtadi, and Tuffs' \"Generalized Predictive Control\" (GPC) (1987) [[1,4]]. These pioneering works, though formulated independently and using different mathematical foundations, shared a common philosophy of using a process model for prediction and optimization.\n\nThe first decade of MPC's existence (the 1980s) was marked by its successful implementation in industry, particularly at companies like Shell Oil, which developed DMC for complex processes like catalytic cracking units [[2,5]]. This initial wave of industrial deployment generated immense interest but also confusion within the academic community, as the proprietary nature of many commercial algorithms made it difficult to discern their underlying theoretical principles [[3]]. The second decade (the 1990s) became the crucible for the theoretical maturation of MPC. Under the leadership of control theorists like Manfred Morari at Caltech and later at ETH Zurich, the field transitioned from a collection of heuristically effective algorithms to a rigorous branch of control theory [[5,6]]. This period saw the introduction of state-space formulations, which provided a more general and powerful framework than the transfer function-based methods of the 1980s [[1,2]]. Concurrently, significant progress was made in proving stability and robustness properties, moving MPC from a pragmatic tool to a theoretically sound methodology [[2,3]]. This theoretical breakthrough led to the development of more flexible and powerful second-generation commercial MPC software packages [[3]].\n\nThe third decade (the 2000s) focused on overcoming the primary limitation of MPC at the time: computational complexity. For systems with fast dynamics, the online optimization required by standard MPC was too slow to be practical. This spurred the development of what is now termed \"fast MPC,\" aimed at drastically improving online computational efficiency [[2]]. Key innovations during this period included Explicit MPC (e-MPC), which pre-computes the optimal control law offline as a piecewise affine function of the state, allowing for direct lookup during runtime without online optimization [[2,5]]. Other advances included the development of specialized online solvers, such as the fast gradient method by Richter et al. (2010), and the exploration of on-line optimization techniques [[2]]. This push for speed enabled MPC to be applied to faster-sampling systems, including power electronics and other applications requiring rapid response [[5]]. The following table summarizes some of the foundational milestones in MPC's history.\n\n| Decade | Period | Key Developments & Contributions | Key Figures & Institutions |\n| :--- | :--- | :--- | :--- |\n| **First Decade** | 1980s | Rapid industrial adoption in refining and petrochemicals. Seminal works on MPHC (Richalet et al.) and DMC (Cutler & Ramaker). | Richalet, Rault, Testud, Papon; Cutler, Ramaker; Shell Oil Company. |\n| **Second Decade** | 1990s | Theoretical maturation. Shift to state-space formulations. Rigorous proofs of stability and feasibility. Emergence of second-generation commercial software. | Manfred Morari (Caltech/ETH Zurich); Garcia, Morari, Lee, Rawlings, Mayne. |\n| **Third Decade** | 2000s | Focus on computational efficiency. Development of \"fast MPC\" techniques like Explicit MPC (e-MPC), online solvers, and move blocking. Expansion to faster-sampling systems. | Bemporad, Borrelli, Efron; John Lygeros (ETH Zurich); Richter, Boyd. |\n\nThis tripartite division—industrial birth, theoretical adolescence, and computational maturity—illustrates a powerful theme in the history of MPC: the continuous interplay between the needs of industry and the pursuit of theoretical rigor. Each phase built upon the last, creating a self-reinforcing cycle where practical successes highlighted the need for better theory, and theoretical breakthroughs unlocked new industrial applications."
    },
    {
      "heading": "Current State-of-the-Art Methods and Techniques",
      "level": 2,
      "content": "The contemporary landscape of Model Predictive Control is defined by a rich diversity of methods tailored to specific applications and computational requirements. While the fundamental principles remain constant, the implementation techniques have evolved significantly beyond the original heuristic algorithms. The choice of method is typically dictated by the nature of the system being controlled (linear vs. nonlinear), the sampling rate (slow vs. fast), and the available computational resources. A prominent dichotomy exists between linear MPC (LMPC) and nonlinear MPC (NMPC).\n\nFor linear systems, LMPC remains the dominant approach in industry due to its computational tractability. The optimization problem solved at each time step is a quadratic program (QP), which can be solved efficiently using established numerical methods [[4]]. The most prevalent forms are Dynamic Matrix Control (DMC) and Generalized Predictive Control (GPC), which have been extensively refined over decades [[1,4]]. Stability and robustness are handled using established techniques, such as adding terminal penalty and constraint sets to the QP formulation to ensure convergence to a desired operating point [[7]]. Commercial software packages from vendors like AspenTech and The MathWorks (MATLAB/Simulink) provide mature, user-friendly platforms for designing, simulating, and deploying LMPC controllers [[4,5]].\n\nFor nonlinear systems, NMPC is the appropriate methodology, though it presents far greater challenges. The online optimization problem becomes a nonlinear program (NLP), which is computationally much more demanding and may have multiple local optima [[1]]. Despite these complexities, NMPC is essential for controlling highly nonlinear processes found in chemical reactors, bioreactors, and advanced robotics. The solution of NLPs relies on powerful numerical solvers, and significant research effort is dedicated to developing efficient algorithms and tailored problem formulations to make NMPC solutions tractable in real-time [[1]]. A related area is Stochastic MPC, which explicitly accounts for uncertainty by optimizing the expected value of a cost function or by constraining the probability of constraint violation. This requires more sophisticated mathematical tools, such as chance-constrained programming or recourse policies, and represents a frontier where the deterministic world of traditional MPC meets the probabilistic world of estimation and decision-making under uncertainty [[4,7]].\n\nIn parallel with these developments, a major thrust of research has been the creation of \"fast MPC\" techniques designed to reduce the online computational burden. As previously mentioned, Explicit MPC (e-MPC) is a powerful approach where the control law is computed offline and represented as a set of polyhedral regions in the state space, with an associated affine control law for each region [[2,5]]. This allows the controller to simply look up the correct control action online, eliminating the need for an online optimization solver entirely. While e-MPC offers extremely fast execution, its main drawback is the potentially enormous memory requirement for storing the partition, which scales poorly with the number of states and inputs. Another technique is move blocking, where the sequence of manipulated variables is held constant over several time steps, thereby reducing the dimension of the online optimization problem and thus its complexity [[5]]. These methods, along with others like online interior-point methods and warm-starting strategies, form a toolkit of solutions for making MPC applicable to systems with very fast sampling rates, such as those found in power electronics and high-speed manufacturing [[2,5]]. The availability of high-performance computing (HPC) and cloud-based platforms is further enabling the use of more complex MPC formulations by offloading computation from embedded hardware [[6]]."
    },
    {
      "heading": "Applications and Industrial Case Studies",
      "level": 2,
      "content": "The versatility of Model Predictive Control has facilitated its adoption across a vast range of engineering disciplines, from traditional process industries to cutting-edge applications in autonomous systems and sustainable energy management. Its ability to handle multiple inputs and outputs simultaneously, respect operational constraints, and optimize performance indices makes it uniquely suited for complex, multivariable control problems where other methods struggle [[6,7]]. By 2003, there were already over 4,600 documented industrial MPC applications, primarily concentrated in the chemical, petrochemical, and refining sectors [[5]].\n\nIn the realm of **process control**, MPC has become a cornerstone technology. It is widely used in distillation columns to maintain product purity and maximize yield, in polyethylene reactors to ensure consistent product quality, and in PVC plants to manage complex reaction kinetics [[5]]. A notable case study demonstrated that applying DMC to stone mills resulted in a 66% reduction in power consumption [[5]]. Similarly, the use of NN-MPC in polyethylene reactors led to 30% faster transitions between different product grades, showcasing the benefits of combining predictive control with data-driven models [[5]]. In agriculture, MPC has been reviewed for its potential in irrigation control and crop management, highlighting its utility in managing resources under environmental constraints [[4]].\n\nMore recently, MPC has found a natural home in the domains of **robotics and autonomous systems**. The need to navigate environments safely, avoid obstacles, track trajectories, and adhere to mechanical limits makes MPC an ideal control framework for mobile robots and unmanned vehicles [[4]]. Its ability to integrate path planning and trajectory tracking into a single optimization problem is a significant advantage. Furthermore, in **power electronics and AC drives**, MPC's fast sampling capabilities are crucial. It is used to control converters and inverters with sampling times as low as 83 microseconds, ensuring precise waveform generation and efficient power conversion [[5]]. In the domain of **building climate control**, MPC has been shown to deliver tangible energy savings. At Google's data centers, an MPC-based HVAC system successfully reduced cooling costs by 9%, demonstrating its potential for large-scale energy management [[5]].\n\nThe table below presents a selection of case studies illustrating the performance improvements achieved through the application of various MPC techniques.\n\n| Application Domain | Specific Process/System | MPC Technique Used | Performance Improvement | Source(s) |\n| :--- | :--- | :--- | :--- | :--- |\n| **Process Control** | Stone Mills | DMC | 66% reduction in power consumption | [[5]] |\n| **Process Control** | Polyethylene Reactor | Neural Network - MPC (NN-MPC) | 30% faster product grade transitions | [[5]] |\n| **Process Control** | Propane Devaporizer | Not specified | 60% quicker settling time | [[5]] |\n| **Building Climate Control** | Google Data Center HVAC | MPC | 9% reduction in cooling costs | [[5]] |\n| **Manufacturing** | Milling/Welding | MPC | Enhanced process control and quality | [[5]] |\n| **Power Electronics** | AC Drives | MPC | Sampling times as low as 83 μs | [[5]] |\n| **Robotics/Autonomous Systems** | Mobile Robots / Unmanned Vehicles | MPC | Improved trajectory tracking and obstacle avoidance | [[4]] |\n\nThese examples underscore a critical insight: the success of MPC is not merely about the control algorithm itself, but about the synergy between the algorithm and the underlying model. The impressive results in each of these cases are predicated on having a sufficiently accurate model of the system dynamics and a clear definition of the performance objectives. As systems become more complex and interconnected, the role of MPC is poised to expand further, particularly in areas like smart grids, autonomous manufacturing, and intelligent transportation systems, where its inherent ability to manage trade-offs and constraints will be increasingly valuable."
    },
    {
      "heading": "Challenges and Open Problems",
      "level": 2,
      "content": "Despite its widespread success and theoretical maturity, Model Predictive Control faces several significant challenges and open problems that continue to drive research and limit its broader application. These issues span the entire MPC design loop, from system identification and modeling to real-time implementation and robustness under uncertainty. A recurring theme in the literature is that these challenges are often deeply interconnected, forming a complex web of trade-offs that engineers must navigate [[1]].\n\nOne of the most fundamental challenges is **modeling accuracy**. The performance of any MPC controller is fundamentally limited by the fidelity of its predictive model [[1,6]]. Inaccurate models can lead to poor control performance, instability, or constraint violations. Obtaining high-quality models can be difficult and expensive, especially for complex, nonlinear, or multi-physics systems. This challenge is compounded by the fact that models are often simplified approximations of reality, neglecting unmeasured dynamics or interactions. Consequently, much research focuses on integrating system identification techniques to build or refine models from input-output data [[1]].\n\nA closely related issue is **computational complexity**. While \"fast MPC\" techniques have addressed the problem for many applications, the online optimization problem remains a bottleneck for systems with very fast dynamics or a large number of variables [[5,6]]. The need for real-time solutions imposes strict timing constraints on the controller, which can be difficult to meet on low-cost embedded hardware. This has spurred the development of specialized algorithms, hardware acceleration, and novel reformulations like move blocking [[2,5]]. The trade-off between the accuracy of a detailed model (which increases complexity) and the speed of a simpler model (which may sacrifice performance) is a central dilemma in MPC implementation.\n\nPerhaps the most significant challenge in modern MPC is the effective handling of **uncertainty** [[7]]. The assumption of perfect state information and a perfectly known model, which underpins nominal MPC, is rarely valid in practice. Disturbances, measurement noise, and model inaccuracies can degrade performance and even destabilize the closed-loop system [[1,7]]. While robust and stochastic MPC frameworks exist to address this, they often come at a steep computational price or require strong assumptions about the nature of the uncertainty [[7]]. The development of computationally efficient and practically implementable robust MPC schemes remains an active area of research. Furthermore, the integration of MPC with advanced state estimation and fault diagnosis techniques is crucial for building truly resilient control systems, as faults and estimation errors are themselves sources of uncertainty [[1]].\n\nFinally, the challenge of **real-time implementation** extends beyond raw computational speed. Issues such as communication delays in networked control systems, the impact of quantization on digital implementations, and the difficulty of tuning the controller parameters (such as horizons and weighting matrices) all pose practical hurdles [[6]]. The design of an MPC controller is not just a mathematical exercise; it is an engineering endeavor that requires careful consideration of the entire control architecture, including sensors, actuators, and the computational platform. Overcoming these challenges requires a holistic approach that considers the entire system, rather than focusing solely on the control algorithm itself [[1]]."
    },
    {
      "heading": "Future Research Directions",
      "level": 2,
      "content": "The future of Model Predictive Control is poised for a transformative evolution, driven by the confluence of three major technological trends: machine learning, distributed systems, and Industry 4.0. These trends are pushing MPC beyond its traditional boundaries and opening up new possibilities for creating intelligent, adaptive, and collaborative control systems. The research directions currently being explored aim to address the long-standing challenges of modeling, computation, and uncertainty by leveraging the power of data and distributed intelligence.\n\nA primary future direction is the deep integration of MPC with **machine learning and artificial intelligence**. The reliance on accurate first-principles models is a significant barrier to entry for many applications. Machine learning offers a powerful alternative for data-driven system identification and modeling. Researchers are exploring the use of neural networks (NNs) to approximate system dynamics, which can then be embedded within an MPC framework [[5]]. This hybrid approach, often called Learning-Based MPC, can learn complex, nonlinear relationships from data without requiring a detailed physical understanding of the system. One innovative technique involves using NNs to approximate the entire solution space of the MPC optimization problem. After an initial training phase, this NN can rapidly evaluate the optimal control action, achieving computation speeds up to 200 times faster than traditional solvers, enabling real-time control on resource-constrained devices [[5]]. Beyond modeling, reinforcement learning is being investigated for learning optimal control policies directly from interaction with the environment, bypassing the need for an explicit model altogether.\n\nAnother critical avenue of research is the development of **distributed and decentralized MPC**. Many modern engineering systems are inherently large-scale and spatially distributed, such as smart grids, traffic networks, and fleets of autonomous vehicles. Controlling such systems with a single, centralized MPC controller is often impractical due to excessive communication overhead and computational load. Distributed MPC (DMPC) addresses this by decomposing the overall control problem into smaller, coupled sub-problems that can be solved locally by individual agents or subsystems [[5]]. Each agent optimizes its own actions while exchanging information with its neighbors to coordinate behavior and achieve a global objective. This paradigm shift enables scalable and robust control of complex networks, aligning perfectly with the principles of distributed computing.\n\nFinally, the rise of **Industry 4.0** and the Internet of Things (IoT) is creating unprecedented opportunities for MPC. The massive influx of data from sensors and connected devices provides a rich source of information for enhancing MPC performance [[6]]. This data can be used for improved real-time state estimation, more accurate model calibration, and proactive fault detection and diagnosis [[1]]. The integration of MPC with cloud computing platforms allows for the offloading of heavy computational tasks, enabling the use of more complex MPC formulations and facilitating real-time optimization over large, geographically dispersed systems [[6]]. This fusion of MPC with big data analytics and high-performance computing promises to unlock new levels of efficiency, resilience, and autonomy in engineered systems, paving the way for smarter factories, cities, and infrastructure. The ultimate goal is to create a seamless ecosystem where MPC acts as the intelligent brain, continuously learning, adapting, and optimizing the operation of a connected world."
    },
    {
      "heading": "Conclusion",
      "level": 2,
      "content": "In conclusion, this review has traced the journey of Model Predictive Control from its origins in the petrochemical industry to its status as a mature and indispensable tool in modern engineering. The analysis reveals that MPC's enduring success is rooted in its unique ability to balance predictive foresight with the enforcement of hard constraints, a feature that sets it apart from classical control paradigms. The field's history is a testament to the symbiotic relationship between industrial need and academic rigor, where practical challenges have consistently fueled theoretical innovation, and theoretical breakthroughs have opened the door to new applications.\n\nThe key finding of this review is that MPC is not a monolithic technology but a flexible and evolving paradigm. Its current state is characterized by a diverse array of methods tailored to specific needs, from the computationally efficient linear and explicit MPCs used in industry to the more complex nonlinear and robust formulations required for challenging applications. The literature clearly shows that the primary challenges limiting MPC's applicability are no longer confined to the control algorithm itself. Instead, they lie in the peripheral domains of modeling, state estimation, and fault diagnosis, which are collectively influenced by the accuracy of the system model, the precision of measurements, and the ability to handle inevitable uncertainties [[1,7]]. The historical progression from industrial adoption to theoretical maturity and now to computational speed demonstrates a clear trajectory toward solving these challenges.\n\nLooking forward, the future of MPC is intrinsically linked to its integration with machine learning, distributed systems, and the data-rich environments of Industry 4.0 [[5,6]]. The emergence of learning-based MPC, which leverages data to create surrogate models and accelerate computation, holds the promise of overcoming the longstanding barrier of model dependency. Simultaneously, the development of distributed MPC architectures is enabling the control of large-scale, networked systems in a scalable and decentralized manner. These future directions suggest that the next chapter in MPC's story will be one of increased intelligence, adaptability, and connectivity. The continued evolution of MPC will undoubtedly play a pivotal role in shaping the future of automation and control across all engineering disciplines.\n\n---"
    }
  ],
  "references": [
    "1. Model predictive control: past, present and future",
    "2. Model predictive control: Review of the three decades of ...",
    "3. Model Predictive Control: Review of the Three Decades ...",
    "4. Model predictive control: Past, present and future",
    "5. Review on model predictive control: an engineering perspective",
    "6. How Model Predictive Control took the Chemical Industry",
    "7. Model predictive control: Recent developments and future ..."
  ]
}