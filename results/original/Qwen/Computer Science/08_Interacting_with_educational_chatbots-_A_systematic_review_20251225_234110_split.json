{
  "outline": [
    [
      1,
      "Literature Review: Interacting with educational chatbots- A systematic review."
    ],
    [
      2,
      "Introduction and Background"
    ],
    [
      2,
      "Key Concepts and Historical Development"
    ],
    [
      2,
      "Current State-of-the-Art Methods and Techniques"
    ],
    [
      2,
      "Applications and Case Studies"
    ],
    [
      2,
      "Challenges and Open Problems"
    ],
    [
      2,
      "Future Research Directions"
    ],
    [
      2,
      "Conclusion"
    ],
    [
      1,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "Literature Review: Interacting with educational chatbots- A systematic review.",
      "level": 1,
      "content": "*Generated on: 2025-12-25 23:41:10*\n*Topic Index: 8/10*\n\n---\n\nThis research aims to synthesize existing knowledge on interactions with educational chatbots, focusing on their design, implementation, and impact across learning environments. The review will cover key definitions, historical milestones, state-of-the-art techniques, real-world applications, persistent challenges, and emerging research trajectories. It emphasizes a comprehensive, critical analysis of scholarly works to identify gaps and guide future studies, adhering to academic rigor suitable for publication in a top-tier journal.# Interacting with Educational Chatbots: A Systematic Review"
    },
    {
      "heading": "Introduction and Background",
      "level": 2,
      "content": "The integration of Artificial Intelligence (AI) into educational systems represents one of the most significant technological shifts in modern pedagogy. Among the various AI-driven tools, chatbots have emerged as a particularly versatile and accessible medium for enhancing learning and teaching. An educational chatbot is defined as an AI system designed to mimic human conversation through text or voice, providing immediate support by answering questions, offering explanations, and supplying relevant resources [[2]]. These systems are not merely automated responders; they are sophisticated applications of natural language processing (NLP), machine learning, and deep learning that hold the potential to revolutionize student support, personalized learning, and administrative efficiency. The rapid proliferation of these technologies, especially following the launch of advanced Large Language Model (LLM) chatbots like ChatGPT, has created an urgent need for a systematic review to consolidate findings, identify patterns, and chart the future direction of this field.\n\nThe motivation for this research stems from several converging trends. Firstly, there is a growing body of evidence suggesting that AI chatbots can significantly impact student outcomes. Studies have reported positive effects on cognitive, behavioral, emotional, and agency engagement, particularly when using generative AI [[3]]. Meta-analyses indicate that chatbots generally have a small to moderate positive effect on learning performance, with some analyses finding a large effect size, especially in higher education contexts [[4,10]]. This suggests that chatbots are more than a novelty; they are a tool with tangible pedagogical value. Secondly, their utility extends beyond direct instruction. They are being deployed for homework assistance, skill development in writing and problem-solving, administrative tasks like scheduling, and even companionship to foster a sense of belonging [[2,12]]. For educators, they offer time savings in grading and content generation, allowing them to focus on higher-order pedagogical strategies [[2,6]]. Thirdly, the technology itself is evolving at a blistering pace, moving from simple pattern-matching systems to complex, context-aware agents capable of nuanced interaction. This evolution necessitates a review that can contextualize historical developments alongside current state-of-the-art capabilities and anticipate future trajectories.\n\nThis systematic literature review aims to provide a comprehensive analysis of the field of interacting with educational chatbots. Its primary objective is to synthesize existing research to address several key questions. What are the foundational concepts and historical milestones that have shaped the development of these technologies? What are the prevailing methods, techniques, and theoretical frameworks underpinning their design and implementation? How are they being applied across different educational levels and disciplines, and what are their documented impacts on learning? Furthermore, the review will critically examine the challenges, ethical dilemmas, and open problems that researchers and practitioners face. By synthesizing this information, the paper seeks to identify critical gaps in the current body of knowledge and propose actionable directions for future research, ultimately contributing to the responsible and effective integration of conversational AI into education. The scope of this review encompasses empirical studies, theoretical papers, and design-oriented research published between 2018 and 2025, drawing upon a wide array of sources including meta-analyses, experimental studies, and conceptual frameworks to build a holistic picture of the field."
    },
    {
      "heading": "Key Concepts and Historical Development",
      "level": 2,
      "content": "To understand the contemporary landscape of educational chatbots, it is essential to trace their historical development and clarify the key concepts that define them. The journey of chatbots began long before the advent of modern AI, rooted in early experiments in artificial intelligence and human-computer interaction. The seminal work of Alan Turing in 1950, who introduced the Turing Test as a criterion for machine intelligence, laid the philosophical groundwork for developing machines that could convincingly simulate human thought [[1]]. The first practical steps were taken in the 1960s. Joseph Weizenbaum's ELIZA (1966) at MIT was a groundbreaking program that simulated a Rogerian psychotherapist by using simple pattern-matching and scripted responses, demonstrating for the first time how a computer could engage in seemingly meaningful conversation [[1,2,8]]. This was followed in 1972 by PARRY, developed by Dr. Kenneth Colby, which aimed to simulate paranoid schizophrenia, pushing the boundaries of psychological simulation and sparking early ethical discussions about AI [[1,2,8]].\n\nThe 1990s marked a period of standardization and broader accessibility. The emergence of Artificial Intelligence Markup Language (AIML) enabled rule-based chatbot development, making the technology more approachable for developers outside of academic labs [[1]]. A prominent example was ALICE (1995), created by Dr. Richard Wallace, which became a successful open-source project and demonstrated the potential for community-driven AI development [[1,2,8]]. In the early 2000s, SmarterChild (2001) represented a significant step towards mainstream adoption, operating on popular instant messaging platforms like AOL Instant Messenger and MSN Messenger to provide information retrieval services [[1,2]]. These early systems were primarily based on predefined rules and scripts, limiting their adaptability and depth of interaction.\n\nThe 2010s heralded a paradigm shift with the integration of advanced Natural Language Processing (NLP) and machine learning. This era saw the rise of voice-first assistants like Apple's Siri (2011) and IBM's Watson (2011), which demonstrated improved contextual awareness and the ability to handle more complex queries [[1,9]]. Google Duplex (2018) further advanced conversational AI by showcasing near-human fluency in spoken dialogue [[1]]. However, the true watershed moment came with the release of Large Language Models (LLMs). OpenAI's GPT-3-powered ChatGPT (launched November 2022) set a new benchmark for natural language understanding, contextual coherence, and broad application potential, becoming a global phenomenon and a catalyst for widespread interest in generative AI [[1,8,20]]. This was quickly followed by other powerful models like Google Bard (announced May 2023) and Microsoft's Samantha West (2017), solidifying the dominance of LLMs in the chatbot space [[1,2]].\n\nIn parallel with this technical evolution, the concept of the chatbot itself has been refined. Researchers now distinguish between basic chatbots and more sophisticated AI tutors. While a basic chatbot typically provides generic, pre-programmed answers to common questions, an AI tutor is a highly specialized system designed for pedagogical purposes [[6]]. Key differentiators include personalization, where the tutor adapts to the individual student's needs and progress; curriculum alignment, ensuring the content is relevant to educational standards; and adaptive feedback, which uses guided explanations and hint-based scaffolding to promote mastery [[6]]. Successful AI tutors are often integrated with Learning Management Systems (LMS) via standards like LTI 1.3 and OneRoster, allowing them to leverage student data for context-aware interactions [[6]]. This distinction is crucial, as it separates transactional, question-answering tools from transformative, pedagogically-grounded learning partners. The table below summarizes key milestones in chatbot history.\n\n| Year | System/Model | Developer(s)/Organization | Key Contribution/Milestone | Citations |\n| :--- | :--- | :--- | :--- | :--- |\n| 1950 | Not Available | Alan Turing | Introduced the Turing Test as a criterion for machine intelligence. | `[[1]]` |\n| 1966 | ELIZA | Joseph Weizenbaum (MIT) | First chatbot to use pattern-matching and scripted responses to simulate a psychotherapist. | `[[1,2,8]]` |\n| 1972 | PARRY | Dr. Kenneth Colby | Simulated paranoid schizophrenia using pattern-based responses, contributing to AI psychology. | `[[1,2,8]]` |\n| 1995 | ALICE | Dr. Richard Wallace | Prominent open-source chatbot developed using Artificial Intelligence Markup Language (AIML). | `[[1,2,8]]` |\n| 2001 | SmarterChild | ActiveBuddy (Inc.) | Early mainstream chatbot on instant messaging platforms for information retrieval. | `[[1,2]]` |\n| 2011 | Siri / Watson | Apple / IBM | Integration of NLP and ML for voice-first, context-aware assistants. | `[[1,9]]` |\n| 2018 | Google Duplex | Google | Advanced conversational AI with near-human fluency in spoken dialogue. | `[[1]]` |\n| 2022 | ChatGPT | OpenAI | Release of GPT-3.5-powered LLM, setting a new benchmark for conversational AI and generative capabilities. | `[[8,20]]` |\n| 2023 | Khanmigo / Q-Chat | Khan Academy / Quizlet | Deployment of GPT-4 powered AI tutors for specific educational domains. | `[[20]]` |"
    },
    {
      "heading": "Current State-of-the-Art Methods and Techniques",
      "level": 2,
      "content": "The current state of educational chatbots is overwhelmingly dominated by advancements in Large Language Models (LLMs), which have redefined the capabilities of conversational AI. These models, such as OpenAI's GPT series (including GPT-4o used in the Iris tutor), Google's Gemini, and Meta's Llama-3.1, form the core of many modern educational agents [[8,11,17]]. Their power lies in their ability to generate fluent, contextually aware text, enabling rich and dynamic interactions. However, deploying these powerful but general-purpose models effectively in an educational context requires a sophisticated methodological toolkit. The most prominent technique is Retrieval-Augmented Generation (RAG), which addresses a critical weakness of LLMs: the tendency to \"hallucinate\" or fabricate information. RAG connects LLMs to curated, domain-specific knowledge bases, ensuring that the generated responses are grounded in factual, reliable content [[20]]. For instance, a chatbot for a university course might be trained on lecture slides, textbooks, and syllabi using a RAG pipeline, guaranteeing its answers are accurate to the specific curriculum [[14,19]].\n\nAnother key technique is fine-tuning, where a pre-trained LLM is further trained on a smaller, specialized dataset to adapt its behavior to a specific domain or task [[20]]. This allows for greater customization of tone, style, and pedagogical approach. For example, a chatbot designed to tutor students in English as a Foreign Language (EFL) would benefit from being fine-tuned on a corpus of language learning dialogues. Beyond adapting the model itself, prompt engineering plays a vital role in guiding the LLM's output. Techniques like zero-shot prompting (for straightforward definitions), few-shot prompting (providing a few examples of the desired input-output format), and chain-of-thought (CoT) prompting (encouraging the model to \"think step-by-step\") are used to enhance the quality, accuracy, and logical coherence of the chatbot's responses [[21]]. The development of custom-built systems often involves a complex data ingestion pipeline. Such pipelines preprocess raw data from various sources—like CSV files, university webpages, and social media groups—through steps including cleaning, tokenization, lemmatization, and chunking before generating embeddings for storage in a vector database like ChromaDB [[19]].\n\nPedagogically, the field is moving away from simple question-and-answer systems toward more sophisticated tutoring paradigms. A central concept is Socratic tutoring, which emphasizes guiding the learner to discover answers themselves rather than simply providing solutions. This is operationalized through mechanisms like scaffolded hints and non-revealing feedback [[11,17]]. Research on the AI tutor Iris, for example, found that its adherence to principles from cognitive load theory and self-explanation led to high-quality, pedagogically sound interactions [[17]]. Another emerging technique is the use of multi-agent systems, where multiple LLMs collaborate or debate to solve a problem or evaluate a response, thereby enhancing the robustness and quality of the final output [[20]]. To ensure these complex systems function effectively, a rigorous evaluation framework is essential. A unified taxonomy for assessing LLM-powered tutors has been proposed, comprising eight pedagogical dimensions: mistake identification, mistake location, revealing of the answer, providing guidance, actionability, coherence, tutor tone, and human-likeness [[11]]. This framework, grounded in learning sciences principles, moves evaluation beyond simple metrics like accuracy to assess the quality of the pedagogical interaction itself. The development of benchmarks like MRBench, which contains annotated dialogues between LLMs and human tutors, facilitates standardized evaluation and comparison of different models' pedagogical effectiveness [[11]]."
    },
    {
      "heading": "Applications and Case Studies",
      "level": 2,
      "content": "Educational chatbots are being deployed across a diverse range of applications and settings, transforming both instructional delivery and student support services. Their applications span from discipline-specific tutoring and administrative automation to fostering collaborative skills and enhancing language acquisition. A primary application is in providing personalized, just-in-time support for complex subjects. For example, a study at the Singapore Institute of Technology (SIT) implemented an AI chatbot named Chem Quest to improve engagement in an online chemistry course, where initial completion rates were low [[8]]. Similarly, a GPT-based tutor was built for an undergraduate blockchain course at the University of Split, where it successfully supported student-centered learning by implementing teaching, cognitive, and social presence [[14]]. In programming education, chatbots are used to generate exercises and provide help with algorithms, as seen in the Iris tutor's application for a task involving the Burrows-Wheeler Transform algorithm [[8,17]]. In mathematics, the TutorBot showed significant improvements in content access and time savings for students compared to traditional LMS users [[8]].\n\nBeyond subject-specific tutoring, chatbots are increasingly used for administrative and pastoral care functions. They can automate responses to frequently asked questions (FAQs), assist with scheduling, and provide students with information about exams, financial aid, and library resources [[2,19]]. At the Hong Kong University of Science and Technology, a Google Dialogflow-based chatbot was deployed to train 550 Graduate Teaching Assistants (GTAs) [[8]]. In a case study at BRAC University, a hybrid chatbot was developed to answer over 1,800 questions across 14 categories, including academic progress, exams, and financial aid, demonstrating the potential for creating comprehensive institutional knowledge hubs [[19]]. Voice-based chatbots are also being used to enhance language learning, with studies showing they can improve communicative competence and reduce foreign language anxiety by providing a low-stakes environment for practice [[18]]. Platforms like Duolingo and Quizlet have launched their own AI tutors, leveraging GPT-4 to personalize language learning experiences [[20]].\n\nA significant area of growth is the use of chatbots to facilitate collaborative and self-regulated learning. Kim and Lim (2025) developed design principles for chatbots that support collective efficacy in group projects, focusing on features that promote team cohesion, shared goals, and real-time scaffolding [[15]]. Other research has identified eight core roles for chatbots in supporting students' self-regulated learning (SRL), including acting as motivational facilitators, metacognitive scaffolds, and performance trackers across Zimmerman’s forethought, performance, and reflection phases [[22]]. A study evaluating a chatbot for autonomous exam preparation found that it effectively supported students' self-regulation, with usage intensity correlating with exam performance, though in a non-linear fashion [[21]]. The table below presents a summary of selected case studies.\n\n| Study Context | Chatbot Name/System | Application Area | Key Findings & Contributions | Citations |\n| :--- | :--- | :--- | :--- | :--- |\n| **Singapore Institute of Technology** | Chem Quest | Online Chemistry Course | Improved student engagement and addressed low initial course completion rates. | `[[8]]` |\n| **University of Split** | Custom GPT Tutor | Undergraduate Blockchain Course | Implemented Community of Inquiry framework; high student engagement, persistence, and mastery. | `[[14]]` |\n| **BRAC University** | Hybrid RAG-based Chatbot | University Administrative Support | Answered 1,866 Q&A pairs from various sources; achieved high semantic relevance scores. | `[[19]]` |\n| **Hong Kong University of Science and Technology** | Google Dialogflow Bot | GTA Training Program | Trained 550 Graduate Teaching Assistants on pedagogical practices. | `[[8]]` |\n| **Technical University of Munich** | Iris (with GPT-4o) | Programming Education | Compared to ChatGPT and no-AI control; highlighted issues of context awareness and \"trust tax.\" | `[[17]]` |\n| **Multiple Disciplines** | Various Generative AI | Homework Assistance & Skill Development | Meta-analysis showed a small-to-moderate positive effect on learning performance, with benefits in STEM fields. | `[[4]]` |\n| **Various Institutions** | Ada / Replika / Socratic | Personalized Tutoring & Companionship | Examples of commercial tools highlighting different user-facing applications of chatbot technology. | `[[2]]` |\n\nThese case studies illustrate a clear trend: the most successful implementations are those that move beyond simple Q&A to become integrated, context-aware partners in the learning process. They are tailored to specific educational needs, whether it is mastering a difficult concept, navigating university bureaucracy, or collaborating with peers."
    },
    {
      "heading": "Challenges and Open Problems",
      "level": 2,
      "content": "Despite the immense potential of educational chatbots, their widespread adoption is constrained by a host of significant challenges and open problems. These can be broadly categorized into pedagogical limitations, technical hurdles, ethical dilemmas, and systemic barriers. Pedagogically, one of the most critical issues is the inherent limitation of current LLMs. While they excel at generating fluent text, they often lack deep, world-like understanding and struggle with genuine empathy, nuance, and the ability to handle complex, ambiguous, or novel situations [[8,9]]. This leads to a fundamental tension between solution-seeking and actual learning, especially when students are under time pressure [[17]]. Research on the MRBench benchmark revealed that top-performing LLMs like GPT-4 function more effectively as question-answering systems than as pedagogical tutors, often impairing learning by revealing answers outright instead of providing helpful guidance [[11]]. Furthermore, there is a risk of overreliance on AI, which can undermine the development of critical thinking and self-regulation skills [[8,22]].\n\nTechnical challenges remain formidable. A persistent problem is the generation of \"hallucinations\"—confident but factually incorrect information—which poses a serious threat to the credibility of educational tools [[2,8]]. This directly impacts reliability and accuracy, with studies showing that ChatGPT provided incorrect medical facts or agricultural information in a majority of cases [[2,8]]. Speech recognition issues can also affect intelligibility and lead to unnatural, frustrating interactions, particularly in voice-based chatbots [[18]]. Data privacy and security are paramount concerns, especially given regulations like FERPA and GDPR. The collection and use of student data to personalize interactions must be handled with extreme care to avoid breaches and misuse [[6,15]]. Moreover, there is a pressing need for better methods to detect AI-generated content to uphold academic integrity. Existing detection tools have proven unreliable; OpenAI discontinued its classifier due to a mere 26% accuracy rate, while Turnitin reports that a significant portion of university essays contain AI-written text [[8,20]].\n\nEthical considerations permeate every aspect of chatbot deployment. Algorithmic bias is a major concern, as models trained on vast datasets may inadvertently perpetuate societal stereotypes and inequalities, disadvantaging certain student populations [[15]]. There is also a lack of teacher technical knowledge and infrastructure issues in many institutions, hindering effective implementation [[12]]. Perhaps the most widely discussed challenge is the erosion of academic integrity. Surveys show that a high percentage of students use AI to complete coursework, raising significant questions about assessment validity [[8]]. This has led to bans on tools like ChatGPT in several countries and school districts due to cheating concerns [[2]]. The \"trust tax\" associated with general-purpose chatbots, where users must expend extra effort to verify information manually, further complicates their utility [[17]]. Finally, there is a notable gap in equitable deployment. Many studies are conducted in Western contexts, and underrepresented groups and K-12 settings remain significantly underexplored [[12,22]]. Addressing these multifaceted challenges requires a concerted effort from technologists, educators, policymakers, and ethicists to develop more robust, fair, and trustworthy AI systems."
    },
    {
      "heading": "Future Research Directions",
      "level": 2,
      "content": "To overcome the current challenges and unlock the full potential of educational chatbots, future research must pursue several strategic directions. A primary focus should be on advancing the pedagogical sophistication of AI tutors. This involves moving beyond simple scaffolding to designing systems that can implement complex, adaptive pedagogical strategies grounded in learning science. Research should explore how to engineer LLMs to function less as answer-providers and more as effective Socratic guides, adept at asking probing questions, identifying misconceptions, and providing targeted, non-revealing feedback [[11,17]]. Developing calibrated autonomy models that can dynamically adjust the level of support based on a student's progress and affective state is a promising avenue [[22]]. Furthermore, there is a need to investigate the role of chatbots in fostering higher-order skills like reflective practice and emancipatory critique, areas that are currently underexplored [[16,22]].\n\nTechnologically, research should concentrate on improving the reliability, trustworthiness, and personalization of chatbots. A key area is enhancing grounding and verifiability to combat hallucinations. This includes developing more sophisticated RAG architectures and integrating provenance technologies like statistical watermarking to make AI-generated content detectable and traceable [[20]]. The development of multimodal analytics that can interpret and respond to students' emotional cues through facial expressions or vocal tones is another critical frontier [[22]]. Expanding multilingual support is essential for equitable deployment, requiring the development and adaptation of models like mBERT and Multilingual T5 for non-English educational contexts [[19]]. Longitudinal studies are needed to understand the long-term impacts of sustained interaction with chatbots, as well as to investigate differential effects across diverse student demographics and cultural backgrounds [[2,12]].\n\nMethodological rigor must be elevated across the field. Much of the current research relies on short-term, single-group interventions without adequate control groups, making it difficult to establish causality [[14]]. Future studies should employ more robust designs, such as randomized controlled trials, and conduct deeper qualitative analyses to understand the nuances of student-chatbot interactions. There is a significant need for more research in underrepresented educational contexts, particularly K-12 settings and diverse global regions [[12,22]]. Participatory methods that involve educators and students in the design and validation of chatbots are also recommended to ensure the resulting systems are both usable and useful [[22]]. Finally, research must continue to grapple with the profound ethical implications. This includes developing robust frameworks for mitigating bias, ensuring transparent and fair data practices compliant with regulations like FERPA/GDPR [[6]], and establishing clear institutional policies for AI deployment [[15]]. The creation of universally accepted ethical guidelines for the use of AI in education will be paramount as these technologies become more deeply embedded in the learning ecosystem."
    },
    {
      "heading": "Conclusion",
      "level": 2,
      "content": "This systematic review has mapped the rapidly evolving landscape of educational chatbots, from their conceptual foundations to their current applications and future potential. The evidence clearly indicates that these technologies are transitioning from niche tools to integral components of the modern educational ecosystem, driven by the disruptive capabilities of Large Language Models. The review has synthesized findings that reveal a field characterized by significant promise and equally significant challenges. On one hand, a substantial body of research demonstrates that well-designed chatbots can positively influence learning outcomes, enhance student engagement, and provide valuable administrative and pedagogical support [[3,4,6]]. The development of sophisticated methods like Retrieval-Augmented Generation (RAG) and pedagogical frameworks like Socratic tutoring signals a maturation of the field, moving beyond simple Q&A toward more intelligent, context-aware, and adaptive learning partners [[17,20]].\n\nHowever, this same review has illuminated a complex web of interconnected problems. The very power of LLMs introduces risks of misinformation, algorithmic bias, and a weakening of academic integrity that threaten the credibility and fairness of education [[2,8,15]]. Technical hurdles like poor speech recognition and the \"trust tax\" hinder usability, while systemic issues such as a lack of teacher preparedness and infrastructure gaps impede widespread, equitable adoption [[12,18]]. The most insightful finding from this synthesis is the recurring theme of a \"pedagogical paradox\": the most advanced technology is not always the best pedagogical tool. Analysis shows that powerful LLMs can sometimes undermine learning by giving away answers instead of guiding discovery, highlighting a critical gap between technical capability and pedagogical wisdom [[11]].\n\nIn conclusion, the path forward for educational chatbots requires a deliberate and interdisciplinary pivot. The focus must shift from simply deploying more powerful AI to building more intelligent *pedagogical* AI. Future research must prioritize the development of systems that are not only technically proficient but also ethically sound, emotionally attuned, and pedagogically astute. This involves fostering a deeper collaboration between computer scientists, learning theorists, and educators to create a new generation of chatbots that can truly act as effective, supportive, and trustworthy co-participants in the lifelong journey of learning.\n\n---"
    }
  ],
  "references": [
    "1. The Evolution of Chatbots - A Historical Overview",
    "2. Role of AI chatbots in education: systematic literature review",
    "3. A systematic review and meta-analysis of the effectiveness ...",
    "4. Chatbots in education: Hype or help? A meta-analysis",
    "5. A framework and exemplars for ethical and responsible ...",
    "6. AI Tutor vs. Simple Chatbot: What Actually Improves ...",
    "7. A comparative study between virtual- and robot-based tutors",
    "8. AI Chatbots in Education: Challenges and Opportunities",
    "9. AI Chatbots in Education: Challenges and Opportunities",
    "10. Do AI chatbots improve students learning outcomes ...",
    "11. Unifying AI Tutor Evaluation: An Evaluation Taxonomy for ...",
    "12. A meta systematic review of artificial intelligence in higher ...",
    "13. (PDF) Chatbots and AI in Education (AIEd) tools: The good, ...",
    "14. Pedagogical Qualities of Artificial Intelligence-Assisted ...",
    "15. AI chatbot design principles to enhance the collective efficacy ...",
    "16. Pedagogical AI conversational agents in higher education",
    "17. Towards Understanding the Impact of Context-Aware AI ...",
    "18. The use of artificially intelligent chatbots in English ...",
    "19. An AI Powered Chatbot Approach to University Guidance",
    "20. AI-Powered Educational Agents: Opportunities, Innovations ...",
    "21. Subject-Specialized Chatbot in Higher Education as a ...",
    "22. Designing artificial intelligence chatbots for self-regulated ..."
  ]
}