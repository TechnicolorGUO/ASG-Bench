{
  "outline": [
    [
      1,
      "Literature Review: Digital competence in higher education research- A systematic literature review."
    ],
    [
      2,
      "Introduction and Background"
    ],
    [
      2,
      "Key Concepts and Defining Frameworks"
    ],
    [
      2,
      "Historical Development and Milestones"
    ],
    [
      2,
      "Current State-of-the-Art Methods and Techniques"
    ],
    [
      2,
      "Applications and Case Studies in Higher Education"
    ],
    [
      2,
      "Challenges and Open Problems"
    ],
    [
      2,
      "Future Research Directions"
    ],
    [
      2,
      "Conclusion"
    ],
    [
      1,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "Literature Review: Digital competence in higher education research- A systematic literature review.",
      "level": 1,
      "content": "*Generated on: 2025-12-25 04:55:22*\n*Topic Index: 6/10*\n\n---\n\nThis research aims to systematically review the body of literature on digital competence within higher education, focusing on conceptual foundations, historical evolution, state-of-the-art methods, practical applications, persistent challenges, and emerging research trajectories. The scope includes global perspectives and spans foundational to contemporary studies, ensuring comprehensive coverage of theoretical and empirical contributions. The review will critically analyze strengths and gaps in the field to inform future scholarship, adhering to rigorous academic standards suitable for publication in a top-tier journal.# A Systematic Literature Review of Digital Competence in Higher Education Research"
    },
    {
      "heading": "Introduction and Background",
      "level": 2,
      "content": "The integration of digital technologies into higher education has fundamentally reshaped the landscape of teaching, learning, research, and administration. This transformation is not merely about the adoption of new tools but represents a profound shift in pedagogical practices, knowledge dissemination, and institutional operations [[19]]. In response to this evolution, the concept of 'digital competence' has emerged as a central theme in educational research and policy, signifying the ability to use information and communication technologies (ICTs) confidently, critically, creatively, and responsibly for personal, professional, and civic purposes [[6,7]]. The significance of this competence extends beyond individual skill acquisition; it is increasingly viewed as a critical determinant of academic success, employability, and societal participation in the 21st century [[6]]. The European Commission, for instance, formally recognizes digital competence as one of eight key competences for lifelong learning, underscoring its foundational role in modern education systems [[6,7]].\n\nThe impetus for scholarly investigation into digital competence has been accelerated by several concurrent global trends. The most significant of these was the COVID-19 pandemic, which forced a rapid and widespread transition to remote and hybrid learning models. This abrupt shift exposed both the potential and the profound limitations of existing digital infrastructures and educator preparedness, highlighting a critical need for robust digital competence across all levels of academia [[15,24]]. Prior to the pandemic, however, momentum was already building. The European Union's Digital Education Action Plan (2021–2027) serves as a powerful policy driver, aiming to support member states in fostering digital skills and transforming education systems through technology [[15]]. Concurrently, national strategies like China's \"Education Informatization 2.0 Action Plan\" and \"China Education Modernization 2035\" reflect a global trend where governments are actively promoting the integration of technology into higher education as a core component of their long-term development goals [[7]]. This confluence of policy mandates, technological advancements, and real-world crises has created an urgent demand for a clear understanding of what constitutes digital competence in higher education and how it can be effectively developed and assessed.\n\nDespite the growing importance of the topic, research in this area reveals a field characterized by fragmentation and a lack of consensus. While numerous frameworks have been proposed to define and structure digital competence, there is no universally accepted standard, particularly for university-level professionals whose roles encompass teaching, research, management, and community engagement [[23]]. Studies frequently rely on self-reporting measures, which are known to be susceptible to bias and overestimation, and often fail to capture the full complexity of digitally-enabled practices [[7,12]]. Furthermore, much of the existing research focuses narrowly on student or teacher perceptions of competence rather than on objective performance metrics or the impact on tangible outcomes like academic achievement [[7,10]]. This review aims to address these gaps by providing a comprehensive systematic literature analysis. Its objectives are threefold: first, to synthesize the key conceptual frameworks, historical developments, and current state-of-the-art methods used to study digital competence; second, to analyze the primary challenges, open problems, and research gaps that currently characterize the field; and third, to identify and articulate promising future research directions. By systematically mapping the existing body of knowledge, this paper seeks to provide a rigorous foundation for future inquiry and to inform more effective policies and practices for cultivating digital competence in higher education."
    },
    {
      "heading": "Key Concepts and Defining Frameworks",
      "level": 2,
      "content": "The conceptualization of digital competence is a dynamic and contested terrain, marked by a proliferation of terms and frameworks that reflect evolving understandings of technology's role in education. At its core, digital competence refers to the confident, critical, and creative use of ICT to achieve goals related to work, employability, learning, leisure, inclusion, and participation in society [[6]]. This definition, articulated by the European Commission, encapsulates the multifaceted nature of the construct, moving beyond simple technical proficiency to include cognitive, ethical, and social dimensions. However, the terminology itself is inconsistent. Within the provided literature, researchers frequently use the terms 'digital literacy,' 'digital competence,' and 'digital skills' almost interchangeably, despite subtle differences in nuance [[20]]. For example, some scholars draw a distinction, with 'digital literacy' often referring to foundational skills related to information consumption and processing, while 'competence' encompasses a broader set of integrated abilities including creation, collaboration, and problem-solving [[14,21]]. This terminological ambiguity poses a significant challenge to research synthesis and comparative analysis.\n\nA landmark event in the formalization of digital competence was the European Union's 2006 Recommendation on Key Competences for Lifelong Learning, which officially designated digital competence as one of eight essential areas for citizens [[6,14]]. This policy move catalyzed the development of structured frameworks designed to operationalize the concept. The most prominent of these is the European Framework for the Digital Competence of Citizens, commonly known as DigComp [[7]]. First published in 2013, DigComp outlines five core areas of competence: Information and Data Literacy, Communication and Collaboration, Digital Content Creation, Safety, and Problem Solving [[7,16]]. The framework has since been updated to versions 2.0 and 2.1, incorporating refinements and adding proficiency levels to help users self-assess their skills [[5,16]]. The influence of DigComp has been extensive, serving as a foundational model for other frameworks and a common basis for evaluation instruments in studies across Europe and beyond [[4,8]].\n\nRecognizing that educators require a distinct set of skills, the European Commission further developed the European Framework for the Digital Competence of Educators, or DigCompEdu [[2]]. Launched in 2017, this framework adapts the citizen-focused model for an educational context, organizing 22 specific competences into six areas: Professional Engagement, Using Digital Tools to Teach and Support Learners, Creating and Sharing Digital Content, Assessing Learners’ Digital Competence, Empowering Learners to be Safe and Responsible Digital Citizens, and Developing One’s Own Professional Practice and that of the Community [[2,7]]. DigCompEdu is explicitly designed to guide the professional development of teachers at all educational levels, including higher education, emphasizing the pedagogical application of technology over mere technical know-how [[2]]. It has become a widely adopted reference point in higher education research, particularly in Europe [[4,11]].\n\nBeyond European initiatives, other influential frameworks have emerged globally. UNESCO has played a pivotal role with its ICT Competency Framework for Teachers (ICT CFT), which provides guidance for pre- and in-service teacher training and supports national policy development [[13]]. The latest version, 3.0, incorporates contemporary technological advances such as AI, mobile technologies, and Open Educational Resources, while emphasizing inclusive principles like non-discrimination and gender equality [[13]]. In the United States, Mishra and Koehler's Technological Pedagogical Content Knowledge (TPACK) model has become highly influential, particularly in studies on technology integration in teaching [[6,23]]. TPACK posits that effective technology integration requires a complex interplay between three primary forms of knowledge: content knowledge, pedagogical knowledge, and technological knowledge [[23]]. Other notable frameworks include Spain's Common Digital Competence Framework for Teachers (CDCFT), which is adapted from DigComp and DigCompEdu, and China's own standards, such as the Digital Literacy of Teachers Standards (2022) and the National Educational Technology Guides for Teachers (CETG) [[7,9,17]].\n\nThe table below summarizes the key characteristics of these dominant frameworks, illustrating the diversity and specialization within the field.\n\n| Feature | European Framework for the Digital Competence of Citizens (DigComp) | European Framework for the Digital Competence of Educators (DigCompEdu) | UNESCO ICT Competency Framework for Teachers (ICT CFT) | TPACK Model |\n| :--- | :--- | :--- | :--- | :--- |\n| **Primary Audience** | All citizens, including students [[7]] | Educators across all sectors [[2]] | Pre- and in-service teachers [[13]] | Teacher educators and practicing teachers [[23]] |\n| **Core Structure** | Five areas: Information/Data, Communication/Collaboration, Content Creation, Safety, Problem-Solving [[7]] | Six areas: Professional Engagement, Digital Resources, Teaching & Learning, Assessment, Empowering Learners, Facilitating Learners' Digital Competence [[2]] | Four macro-areas covering awareness, operation, integration, and innovation. Includes sub-competencies for each level [[13]] | Three overlapping knowledge domains (TK, PK, CK) forming a hexagon with their intersections representing specialized knowledge [[23]] |\n| **Key Emphasis** | Confident, critical, and creative use of ICT for various life domains [[6]] | Pedagogical use of technology to enhance and innovate teaching [[2]] | Integrating ICT for pedagogy to foster knowledge society skills and support sustainable development [[13]] | Integration of technology, pedagogy, and content knowledge for effective instruction [[23]] |\n| **Regional Influence** | Primarily European Union, but widely cited globally [[4]] | European Union [[4,15]] | Global, guides national policy development [[13]] | Global, especially in North America and Asia [[4,17]] |\n\nThis multiplicity of frameworks reflects the field's maturation but also highlights a significant challenge: the lack of a single, unified standard for digital competence in higher education. Many studies simply adapt existing frameworks for their specific context, leading to variations in scope and focus [[3,23]]. This fragmentation complicates efforts to compare findings across studies and regions, reinforcing the need for continued dialogue and alignment among international bodies and researchers."
    },
    {
      "heading": "Historical Development and Milestones",
      "level": 2,
      "content": "The intellectual trajectory of digital competence research traces a path from foundational concepts of information access to the complex, multi-faceted skill sets required in today's networked society. The origins of this discourse can be found in the late 20th century, predating the widespread availability of the internet. Paul Gilster's 1997 book, *Digital Literacy*, is frequently cited as a seminal work that first introduced the term to a broad audience [[20,22]]. Gilster defined digital literacy as the ability to understand and use information in multiple formats from a wide range of sources when presented via computers [[20]]. This early conception focused primarily on the cognitive skills required to navigate and interpret digital information, laying the groundwork for later, more expansive definitions.\n\nAs technology evolved, so did the conceptual vocabulary. In parallel with the rise of the internet, researchers began to explore the socio-technical aspects of computer use. Martin (2006) and Martin & Grudziecki (2006) contributed the DigEuLit model, an early conceptualization of digital literacy development that emphasized a developmental approach to skill acquisition [[14]]. Around the same time, Van Dijk (2006) proposed a more structured model of digital skills, dividing them into technical, information-seeking, and strategic dimensions [[20]]. These early models began to hint at the multi-layered nature of what would become known as digital competence, suggesting it involved not just knowing how to use a tool, but knowing how to use it strategically to achieve a goal.\n\nA major milestone in the field's institutionalization occurred with the European Union's 2004 Key Competences Framework for Lifelong Learning, which was later updated in 2006 [[14,24]]. This policy document formally identified digital competence as one of eight key competences for all citizens, signaling a shift from an individual skill to a core societal competency. This move by the EU provided the political and intellectual impetus for the development of more detailed and standardized frameworks. The culmination of this effort was the publication of the first version of the European Framework for the Digital Competence of Citizens (DigComp) in 2013 by the Joint Research Centre [[5,6]]. This framework provided a comprehensive and modular structure for digital competence, which quickly became a cornerstone for research and policy across Europe and influenced similar efforts globally.\n\nThe next wave of development specifically targeted educators. The recognition that teaching with technology required a unique set of skills led to the creation of frameworks tailored for them. Redecker et al. (2017) laid the groundwork with publications on the needs for an educator-specific framework, culminating in the official launch of the European Framework for the Digital Competence of Educators (DigCompEdu) in 2019 [[2,7]]. DigCompEdu expanded upon the citizen-focused model by embedding digital practices within pedagogical contexts, focusing on how educators can use technology to teach, assess, and empower learners [[2]]. This marked a crucial step in acknowledging the distinct professional requirements of digital competence in higher education.\n\nIn recent years, the field has continued to evolve in response to new technological and societal pressures. The most significant catalyst has arguably been the COVID-19 pandemic, which acted as a massive, unplanned experiment in digital education. The sudden shift to remote learning exposed deep-seated inequalities and highlighted the critical importance of digital competence for both educators and students [[19,25]]. This period spurred a surge in research focused on digital teaching competence, online pedagogy, and the challenges of virtual assessment [[15,24]]. Concurrently, the rapid advancement of artificial intelligence has prompted calls for frameworks to incorporate AI literacy and ethical considerations. The Qatar University Teacher Digital Competency Framework (TDCF), developed in 2024, is a prime example of this forward-looking approach, explicitly integrating AI-related competencies such as leveraging AI to enhance teaching and using AI to create learning materials [[3]]. Similarly, UNESCO's ICT CFT 3.0 has been updated to include competencies related to AI and the Internet of Things [[13]]. This ongoing adaptation demonstrates that the conceptualization of digital competence is not a static endpoint but a living process, continuously shaped by technological innovation and changing educational paradigms. The journey from Gilster's initial definition of digital literacy to today's holistic frameworks for educators illustrates a field that has matured from a niche interest into a central pillar of modern education policy and practice."
    },
    {
      "heading": "Current State-of-the-Art Methods and Techniques",
      "level": 2,
      "content": "The methodological landscape of digital competence research in higher education is characterized by a strong quantitative orientation, though with increasing experimentation with mixed-methods approaches. A bibliometric analysis revealed that empirical studies are predominantly quantitative and questionnaire-based, relying on self-report surveys to gather data [[6]]. This approach is consistent across numerous reviews, with one analysis finding that 24 out of 33 studies used quantitative methods, primarily involving survey questionnaires administered to students or faculty [[7]]. The most common instrument is the validated self-assessment checklist based on established frameworks like the European DigCompEdu [[4,11]] or adapted versions of it [[8]]. These surveys typically ask participants to rate their perceived competence on a Likert scale across the different domains of a chosen framework. For instance, one study used a 30-item survey based on the five DigComp domains to assess university students in Brunei [[8]], while another surveyed Chinese foreign language teachers using a questionnaire based on China's national standards [[9]].\n\nWhile convenient and efficient for large-scale data collection, this reliance on self-reporting is a significant methodological limitation. Multiple studies and reviews have explicitly noted this weakness, pointing to the well-documented risk of response bias, where individuals tend to overestimate their own abilities [[7,12]]. A 2025 study by Horváth et al., for example, found that self-assessments of Teacher Digital Competence (TDC) were significantly inflated compared to computed scores derived from objective criteria, thereby invalidating the use of the tool for accurate measurement [[12]]. To mitigate this issue, some researchers advocate for the use of more robust psychometric techniques. Several validation studies have employed advanced statistical methods to ensure the reliability and validity of their instruments. These methods include Confirmatory Factor Analysis (CFA) to test the hypothesized factor structure of a framework, and Cronbach's alpha or composite reliability tests to measure internal consistency [[1,8]]. For example, a study validating the DigComp 2.1 framework in Brunei utilized CFA in JASP and reliability testing in ADANCO to demonstrate excellent model fit and strong reliability [[8]].\n\nAlongside traditional survey methods, a number of qualitative and mixed-methods approaches are being employed to gain deeper insights. Some studies have utilized the Delphi method to reach expert consensus on defining competencies or developing assessment tools, as seen in the creation of a nursing digital competence checklist [[1]] and a preliminary design for the Qatar University TDCF [[3]]. Qualitative methods such as interviews and focus groups are also used to explore influencing factors and contextual nuances that quantitative surveys might miss [[24]]. A small but growing number of studies have adopted mixed-methods designs, combining survey data with qualitative follow-ups or observational data to triangulate findings [[7]]. Furthermore, Structural Equation Modelling (SEM), particularly Partial Least Squares SEM (PLS-SEM), is emerging as a powerful technique for analyzing complex relationships between variables. PLS-SEM allows researchers to test entire theoretical models simultaneously, examining direct and indirect effects. This method was used in studies to analyze the influence of personal variables on digital competence [[5]] and to confirm the validity of the DigCompEdu framework while identifying mediating paths, such as the effect of Professional Engagement on Facilitating Learners’ Digital Competence [[12]].\n\nThe table below outlines the spectrum of research methods identified in the literature, highlighting the dominance of quantitative approaches and the presence of more sophisticated analytical techniques.\n\n| Methodological Approach | Description | Representative Examples from Context | Strengths | Limitations |\n| :--- | :--- | :--- | :--- | :--- |\n| **Quantitative Surveys** | Self-report questionnaires using Likert scales to assess perceived competence across framework domains. | Most studies in reviews by López-Nuñez et al. (2024) and Cabezas-González et al. (2023) [[4,7]]. | Efficient for large sample sizes; easy to administer and quantify. | Prone to response bias and social desirability; measures perception, not performance. |\n| **Qualitative Interviews/Focus Groups** | In-depth, semi-structured conversations to explore experiences, attitudes, and contextual factors. | Mentioned as used in the review by Fernández-Batanero et al. (2021) [[24]]. | Provides rich, nuanced data; captures depth and complexity of experience. | Difficult to generalize findings; time-consuming and resource-intensive. |\n| **Delphi Method** | An iterative, structured communication technique used to reach a consensus among a panel of experts. | Used to develop the DCAC checklist for nursing students [[1]] and the TDCF for Qatar University [[3]]. | Builds consensus and incorporates expert judgment; reduces researcher bias. | Can be slow and expensive; relies on the expertise and honesty of the panel. |\n| **Mixed-Methods** | Combines quantitative and qualitative data collection and analysis in a single study. | A few studies in the review by Cabezas-González et al. (2023) [[7]]. | Triangulates data for greater validity; leverages the strengths of both approaches. | Complex to design and execute; requires expertise in both methodologies. |\n| **Psychometric Validation** | Uses statistical techniques (e.g., CFA, reliability analysis) to test the validity and reliability of an instrument. | Validating the DigComp 2.1 framework in Brunei [[8]]; validating the DCAC checklist [[1]]. | Produces robust, reliable, and valid measurement tools. | Requires sufficient sample size and statistical expertise; may not capture all facets of competence. |\n| **Structural Equation Modeling (SEM)** | A multivariate statistical framework used to test and estimate causal relationships between observed and latent variables. | Used to confirm the structure of DigCompEdu [[12]] and to analyze mediation effects [[5]]. | Allows for complex model testing; can handle multiple dependent variables. | Requires large sample sizes; assumptions must be met for results to be valid. |\n\nIn summary, while quantitative survey-based research remains the predominant methodology, there is a clear recognition of its limitations. The field is gradually moving towards employing more sophisticated and diverse methods, including psychometric validation, SEM, and mixed-methods designs, to build a more accurate and comprehensive picture of digital competence. This methodological evolution is crucial for overcoming the inherent biases of self-assessment and for generating evidence that can directly inform the design of effective training programs and institutional policies."
    },
    {
      "heading": "Applications and Case Studies in Higher Education",
      "level": 2,
      "content": "The application of digital competence frameworks and the pursuit of developing these skills manifest in a variety of ways across higher education institutions worldwide, reflecting diverse institutional priorities, regional policies, and research interests. These applications range from large-scale institutional assessments and curriculum integration to targeted professional development programs and national policy implementation. The case studies and research findings from different contexts provide valuable insights into how digital competence is being understood and enacted in practice.\n\nOne of the most common applications is the assessment of digital competence levels among students and faculty. For example, a 2024 study conducted across Chinese universities surveyed foreign language teachers and found they rated their overall competence at an intermediate level, with notable weaknesses in the application of digital technologies for assessment [[9]]. Another study of university students in Brunei, using the DigComp 2.1 framework, found they possessed intermediate levels of competence, but with higher scores in Digital Safety and Communication and lower scores in Digital Content Creation and Problem Solving [[8]]. A large-scale European study using the Check-In tool based on DigCompEdu found that nearly 70% of academics across seven countries had an intermediate level of competence [[11]]. These assessments serve as baseline measurements, helping institutions identify strengths and weaknesses and tailor interventions accordingly.\n\nCurriculum integration and pedagogical enhancement are central to the purpose of developing digital competence. Researchers highlight the transformative potential of digital technologies to improve accessibility, engagement, and personalization in learning [[19]]. Specific examples include the use of Artificial Intelligence (AI) to create personalized and adaptive learning systems like Smart Sparrow, which provide real-time feedback and tailor content to individual student needs [[19]]. Mobile learning (m-learning) platforms enable flexible, on-the-go education, while Massive Open Online Courses (MOOCs) from providers like Coursera and edX democratize access to high-quality educational resources [[19]]. In practice, successful integration often involves aligning technology use with sound pedagogical principles. For instance, Finland's student-centric model integrates tools like Fronter and Edmodo with comprehensive teacher training to enhance STEM education [[19]]. Similarly, Singapore's national Student Learning Space (SLS) provides multimedia resources for all students, demonstrating a top-down commitment to creating a cohesive digital ecosystem [[19]].\n\nProfessional development and training are consistently identified as critical levers for improving digital competence. The need for continuous, flexible, and personalized training is repeatedly emphasized [[23]]. Recommended training modalities include nano-MOOCs (NOOCs), cMOOCs, t-MOOCs, micro-courses, and the use of Web 2.0 tools [[23]]. A study in Karnataka, India, demonstrated that institutional support for technology integration significantly enhances pedagogical strategies and teacher performance, which in turn boosts student engagement [[25]]. This underscores that competence is not just an individual attribute but is heavily mediated by the institutional environment. Factors influencing the effectiveness of training include targeted training sessions, personal motivation, and self-learning, with institutional support being a key enabler [[9]].\n\nNational and institutional policies play a crucial role in shaping these applications. China provides a compelling example of a top-down approach, where national strategies like the \"Double World-Class Project\" and the \"Education Informatization 2.0 Action Plan\" drive the development of digital competence, leading to significant regional disparities in implementation and outcomes [[7,9]]. In contrast, the European Union's approach is more collaborative and standard-setting, with frameworks like DigComp and DigCompEdu serving as common references for member states to develop their own policies [[2,15]]. A notable case of local adaptation is the development of the Qatar University Teacher Digital Competency Framework (TDCF). This three-tiered model was meticulously crafted to align with Qatar University's strategic goals and the Gulf Cooperation Council (GCC) context, explicitly integrating emerging technologies like AI and Universal Design for Learning (UDL) principles [[3]]. Such bespoke frameworks allow institutions to address their specific needs and cultural contexts, moving beyond generic, one-size-fits-all solutions. These diverse applications—from continental policy initiatives to localized institutional frameworks—illustrate the practical relevance of digital competence research and its direct impact on teaching and learning in higher education."
    },
    {
      "heading": "Challenges and Open Problems",
      "level": 2,
      "content": "Despite the growing emphasis on digital competence, the field is beset by a series of interconnected challenges and open problems that hinder progress and limit the impact of interventions. These issues span from fundamental definitional ambiguities to systemic barriers within higher education institutions. A primary challenge lies in the very definition of the construct. As previously noted, the lack of a universally accepted definition and the interchangeable use of terms like 'literacy,' 'skill,' and 'competence' create confusion and impede meaningful comparison across studies [[20,23]]. This terminological fragmentation is compounded by the absence of a single, holistic framework that adequately addresses the full range of professional functions in higher education. A systematic review concluded that while many frameworks exist, none specifically define competencies for all four substantive functions of a university: teaching, research, management, and community engagement, with the latter two being largely absent in the literature [[23]].\n\nMethodological limitations represent another significant hurdle. The pervasive reliance on self-reporting instruments is a recurring criticism, as they are susceptible to response biases and often yield inflated estimates of competence [[7,12]]. The validation study of DigCompEdu found that self-assessments significantly overestimated actual competence, undermining the utility of the tool for diagnostic purposes [[12]]. Even when validated instruments are used, studies often suffer from other methodological weaknesses, such as small sample sizes, non-probabilistic sampling, and data collection issues, which compromise the generalizability of findings [[7]]. Furthermore, a review noted that only a small fraction of studies employ mixed-methods designs, indicating a missed opportunity to combine quantitative breadth with qualitative depth to generate richer, more nuanced understandings [[7]].\n\nSystemic barriers within higher education institutions present formidable obstacles to developing digital competence. A consistent finding across multiple reviews is the lack of adequate institutional support, which manifests in several ways. This includes insufficient funding for infrastructure, inadequate access to reliable technology and high-speed internet, and a lack of dedicated administrative and technical staff [[19,24]]. Insufficient training is another major challenge, with many educators reporting that the training they receive is either inadequate or not aligned with their specific needs [[6,24]]. This is often exacerbated by a culture of resistance to change, where faculty members are hesitant to adopt new technologies or pedagogical approaches [[24]]. The COVID-19 pandemic starkly illuminated these pre-existing weaknesses, revealing a \"digital divide\" not just in terms of access to devices and connectivity, but also in terms of preparedness and capability among educators and students [[19]].\n\nIndividual-level challenges also play a crucial role. These include a lack of motivation among some faculty to engage with digital tools, a fear of technology, and a lack of confidence in their own abilities [[6]]. Interestingly, some studies have found negative correlations between years of teaching experience and digital competence, suggesting that older faculty may face greater difficulties in adapting to new technologies [[7,9]]. Conversely, factors like targeted training, personal motivation, and self-directed learning have been identified as key positive influences [[9]]. Finally, a significant open problem is the difficulty in linking digital competence directly to improved educational outcomes. While many assume a positive correlation between teacher competence and student engagement or academic performance, the evidence base connecting these dots is still developing. More research is needed to move beyond assessing competence levels to evaluating the impact of that competence on student learning and institutional quality [[6,15]]."
    },
    {
      "heading": "Future Research Directions",
      "level": 2,
      "content": "To overcome the extant challenges and fully realize the potential of digital competence in higher education, future research must pursue several key directions. These avenues of inquiry aim to deepen our understanding of the construct, refine our measurement and intervention strategies, and broaden the scope of our investigations to capture the full complexity of digital life in academia. A primary direction is the development of more robust and valid assessment instruments. Given the documented problems with self-reporting, future studies should prioritize the creation and validation of performance-based assessments that measure actual competence rather than perceived competence [[7,12]]. This could involve the use of simulations, portfolio assessments, or even automated analysis of digital artifacts produced by students and teachers. Continued investment in psychometric validation using advanced techniques like Confirmatory Factor Analysis and Item Response Theory is essential to ensure that any instrument used is reliable, valid, and free from bias [[1,8]].\n\nAnother critical area for future research is the exploration of digital competence as a dynamic and evolving construct. Current frameworks, while useful, often treat competence as a static set of skills. Future studies should investigate the longitudinal development of competence throughout a career, tracking how it changes with experience, training, and exposure to new technologies. There is also a need for more mixed-methods research that combines quantitative data with qualitative insights from interviews and observations to understand the contextual factors that facilitate or hinder competence development [[7,24]]. Specifically, research should delve deeper into the influence of institutional culture, leadership, and peer networks on individual adoption of digital practices.\n\nFuture research must also expand its scope to address the identified gaps in the current literature. A major gap exists in the development of comprehensive frameworks that cover the full range of university functions, particularly community engagement [[23]]. Future work should strive to create holistic models that integrate teaching, research, management, and outreach. Additionally, there is a pressing need for more research on graduate students and faculty, who are often underrepresented in studies focused on undergraduates [[7]]. Further investigation is needed into the specific digital competencies required for research, such as data management, scholarly communication in digital environments, and the use of AI for knowledge production [[13,23]].\n\nFinally, the ultimate goal of this research is to inform practice. Therefore, future studies should move beyond descriptive analyses and focus on evaluating the efficacy of different interventions. Randomized controlled trials (RCTs) or quasi-experimental designs could be used to compare the effectiveness of different professional development models, such as MOOCs versus peer-led communities of practice. Research should also investigate the cost-effectiveness and scalability of various training technologies [[23]]. Moreover, given the increasing importance of AI and data analytics, future research must grapple with the ethical implications of these technologies in education. This includes exploring issues of algorithmic bias, data privacy, and the responsible integration of AI into pedagogy and assessment. By pursuing these future directions, the field can move closer to establishing a solid evidence base for fostering genuine, impactful digital competence in higher education."
    },
    {
      "heading": "Conclusion",
      "level": 2,
      "content": "This systematic literature review has mapped the complex and rapidly evolving landscape of digital competence research in higher education. The analysis reveals a field driven by powerful policy imperatives and technological transformations, yet one that is simultaneously constrained by definitional ambiguity, methodological limitations, and systemic barriers. The journey from foundational concepts of digital literacy to sophisticated, multi-domain frameworks like DigCompEdu and TPACK reflects a maturing but fragmented discipline [[3,14]]. While the call for digital competence is universal, the reality on the ground is one of inconsistency, with a heavy reliance on self-reporting instruments that likely inflate competence levels and a scarcity of holistic models that address the full spectrum of university functions [[12,23]].\n\nThe key findings of this review converge on several critical points. First, digital competence is a vital, cross-cutting skill, but its conceptualization lacks a global consensus, hindering comparative research and policy alignment. Second, while quantitative survey methods dominate the field, their inherent limitations necessitate a greater embrace of psychometrically robust instruments and mixed-methods approaches to generate more credible evidence. Third, the development of digital competence is not merely an individual responsibility but is profoundly shaped by institutional factors, including leadership, infrastructure, and support systems, which are often found to be deficient [[19,24]]. Finally, the field is ripe for future inquiry that moves beyond description to evaluate the impact of competence on student outcomes and to design and test effective, scalable interventions.\n\nIn conclusion, the path forward requires a concerted effort to bridge the gap between rhetoric and reality. Future research must prioritize the development of valid performance-based assessments, conduct longitudinal studies to understand competence development, and create comprehensive frameworks that encompass the entirety of academic life. Only through such rigorous and holistic inquiry can we hope to build a solid evidence base capable of guiding institutions in their mission to cultivate truly competent and critically reflective digital practitioners for the 21st century.\n\n---"
    }
  ],
  "references": [
    "1. Development of theoretical framework and digital ...",
    "2. Digital Competence Framework for Educators (DigCompEdu)",
    "3. A Digital Competency Framework for University Teachers",
    "4. A Systematic Review of Digital Competence Evaluation in ...",
    "5. Theoretical Models Explaining the Level of Digital ...",
    "6. Bibliometric analysis and systematic review of digital ...",
    "7. Digital competence in higher education research: A systematic ...",
    "8. Validating the DigComp framework among university students ...",
    "9. Assessing the digital competence and its influencing ...",
    "10. Digital competence in higher education research",
    "11. The Digital Competence of Academics in Higher Education",
    "12. Validity evidence regarding the use of DigCompEdu as a self ...",
    "13. UNESCO ICT Competency Framework for Teachers",
    "14. Digital competence and digital literacy in higher education ...",
    "15. How do students perceive educators' digital competence in ...",
    "16. Digital Competence in Higher Education: Students ...",
    "17. Assessing the digital competence of in-service university ...",
    "18. Assessment of digital competencies in higher education ...",
    "19. Digital learning in the 21st century: trends, challenges, and ...",
    "20. Key factors in digital literacy in learning and education",
    "21. A scoping review of digital literacy, digital competence ...",
    "22. digital literacy and competence for educators",
    "23. Standards of Teacher Digital Competence in Higher ...",
    "24. Digital Teaching Competence in Higher Education",
    "25. Revolutionizing pedagogy: navigating the integration of ..."
  ]
}