{
  "outline": [
    [
      1,
      "A Survey of Computational Thinking in Education with Scratch"
    ],
    [
      1,
      "1 Abstract"
    ],
    [
      1,
      "2 Introduction"
    ],
    [
      1,
      "3 Empirical Evaluation of CT Tools"
    ],
    [
      2,
      "3.1 Curriculum Development and Pilot Testing"
    ],
    [
      3,
      "3.1.1 Iterative refinement of educational frameworks through real-world implementation"
    ],
    [
      3,
      "3.1.2 Integration of assessment instruments and feedback mechanisms for continuous improvement"
    ],
    [
      2,
      "3.2 Tool Evaluation and User Feedback"
    ],
    [
      3,
      "3.2.1 Analysis of student engagement and learning outcomes through surveys and observational studies"
    ],
    [
      3,
      "3.2.2 Assessment of tool usability and effectiveness in diverse educational settings"
    ],
    [
      2,
      "3.3 Collaborative and Design-Based Research"
    ],
    [
      3,
      "3.3.1 Co-design processes involving educators, developers, and students for context-sensitive solutions"
    ],
    [
      3,
      "3.3.2 Development of open-source tools and curricula through iterative prototyping and testing"
    ],
    [
      1,
      "4 Pedagogical Approaches in CT Education"
    ],
    [
      2,
      "4.1 Instructional Strategies and Frameworks"
    ],
    [
      3,
      "4.1.1 Problem-project-oriented learning and decomposition as core pedagogical techniques"
    ],
    [
      3,
      "4.1.2 Integration of abstraction, modeling, and debugging in curriculum design"
    ],
    [
      2,
      "4.2 Technology-Enhanced Learning"
    ],
    [
      3,
      "4.2.1 Application of generative AI and LLMs for test case generation and assessment"
    ],
    [
      3,
      "4.2.2 Use of visual programming and gamification to enhance engagement and understanding"
    ],
    [
      2,
      "4.3 Teacher and Student Perceptions"
    ],
    [
      3,
      "4.3.1 Analysis of educator and student attitudes toward CT tools and methodologies"
    ],
    [
      3,
      "4.3.2 Exploration of the role of conversational agents and AI in scaffolding learning"
    ],
    [
      1,
      "5 Theoretical and Methodological Frameworks for CT"
    ],
    [
      2,
      "5.1 Conceptual Models and Frameworks"
    ],
    [
      3,
      "5.1.1 Development of classification schemes for CT competencies and task complexity"
    ],
    [
      3,
      "5.1.2 Mapping CT activities to cognitive models such as Kahneman’s two-systems framework"
    ],
    [
      2,
      "5.2 Assessment and Validation Methods"
    ],
    [
      3,
      "5.2.1 Mixed-methods approaches for test development and validation in CT education"
    ],
    [
      3,
      "5.2.2 Empirical evaluation of CT constructs through surveys, case studies, and experimental designs"
    ],
    [
      2,
      "5.3 Cross-Disciplinary Integration"
    ],
    [
      3,
      "5.3.1 Integration of CT with STEM subjects through case studies and curricular alignment"
    ],
    [
      3,
      "5.3.2 Analysis of CT in non-traditional domains such as astrophysics and kinematics"
    ],
    [
      1,
      "6 Future Directions"
    ],
    [
      1,
      "7 Conclusion"
    ],
    [
      1,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "A Survey of Computational Thinking in Education with Scratch",
      "level": 1,
      "content": ""
    },
    {
      "heading": "1 Abstract",
      "level": 1,
      "content": "Computational thinking (CT) has become a critical skill in the 21st century, essential for fostering problem-solving, logical reasoning, and creativity in both academic and professional contexts. As education systems increasingly integrate CT into K–12 and higher education, the need for a comprehensive understanding of its pedagogical and technological dimensions has grown. This survey paper examines the role of Scratch, a visual programming language, in promoting CT through empirical studies, pedagogical strategies, and technological innovations. The review explores the design, implementation, and evaluation of CT tools, emphasizing their effectiveness in supporting diverse learner needs and enhancing educational outcomes. Key findings reveal that Scratch and similar tools significantly improve student engagement, problem-solving abilities, and conceptual understanding of programming. The integration of assessment mechanisms, feedback systems, and collaborative design processes further enhances the pedagogical value of these tools. Additionally, the paper highlights challenges such as teacher training, curriculum alignment, and the need for more robust evaluation frameworks. By synthesizing current research and identifying gaps, this review contributes to the ongoing development of CT education and provides a foundation for future innovations in computational learning. Ultimately, the integration of CT into education is a dynamic and evolving process that requires continuous refinement of both pedagogical and technological approaches."
    },
    {
      "heading": "2 Introduction",
      "level": 1,
      "content": "Computational thinking (CT) has emerged as a fundamental skill in the 21st century, essential for navigating an increasingly digital and technology-driven world [1]. As education systems strive to equip students with the ability to solve complex problems, think logically, and create computational solutions, CT has become a central focus in both formal and informal learning environments [2]. The integration of CT into K–12 education has gained momentum, driven by the recognition that these skills are not only relevant for future careers in technology but also for fostering critical thinking, creativity, and adaptability across disciplines [3]. Educational frameworks and tools have been developed to support this integration, with an emphasis on making computational concepts accessible and engaging for young learners. This growing interest in CT underscores the need for a comprehensive review of existing research, pedagogical strategies, and technological innovations that shape its implementation in education [4].\n\nThis survey paper focuses on the role of Scratch, a widely used visual programming language, in promoting computational thinking in educational settings [5]. Scratch has been extensively studied for its ability to introduce young learners to programming concepts through a block-based interface, fostering creativity, problem-solving, and logical reasoning [6]. The paper explores the design, implementation, and evaluation of CT tools and curricula that incorporate Scratch, with an emphasis on their effectiveness in supporting diverse learner needs. By examining empirical studies, pedagogical approaches, and technological innovations, this review provides a holistic understanding of how Scratch and similar tools contribute to the development of CT skills. It also highlights the challenges and opportunities associated with integrating these tools into formal and informal educational contexts.\n\nThe paper begins by reviewing the empirical evaluation of CT tools, focusing on curriculum development, real-world implementation, and the integration of assessment instruments and feedback mechanisms. It discusses how iterative refinement processes improve the effectiveness of educational frameworks, ensuring they align with both theoretical and practical pedagogical goals. The analysis of student engagement and learning outcomes through surveys and observational studies reveals the impact of interactive tools like Painting with Code on computational thinking development. Additionally, the paper examines the usability and adaptability of CT tools in diverse educational settings, emphasizing the importance of teacher support and curriculum alignment. It also explores collaborative and design-based research methods that involve educators, developers, and students in co-designing context-sensitive solutions, ensuring that tools are both pedagogically sound and user-friendly. The development of open-source tools and curricula through iterative prototyping and testing further highlights the importance of community-driven innovation in CT education.\n\nThe paper also delves into pedagogical approaches in CT education, analyzing instructional strategies such as problem-project-oriented learning and decomposition [2]. It explores how these techniques foster deep understanding and practical application of programming concepts. The integration of abstraction, modeling, and debugging into curriculum design is examined, emphasizing their role in developing higher-order thinking skills. The use of generative AI and large language models (LLMs) for test case generation and assessment is discussed, along with the challenges and opportunities they present in educational contexts. Visual programming and gamification are analyzed as effective methods for enhancing engagement and understanding, while the role of conversational agents and AI in scaffolding learning is explored. Finally, the paper addresses the importance of teacher and student perceptions in shaping the effectiveness of CT tools and methodologies [4].\n\nThis survey paper contributes to the field of computational thinking education by providing a comprehensive synthesis of current research, pedagogical practices, and technological innovations [4]. It offers insights into the effectiveness of Scratch and similar tools in fostering CT skills, identifies gaps in existing research, and highlights the need for continued refinement of pedagogical strategies and assessment methods. By integrating empirical findings, theoretical frameworks, and practical applications, this review serves as a valuable resource for educators, researchers, and policymakers seeking to enhance CT education [7]. It also sets the stage for future research by identifying emerging trends, challenges, and opportunities in the evolving landscape of computational thinking in education [8]."
    },
    {
      "heading": "3.1.1 Iterative refinement of educational frameworks through real-world implementation",
      "level": 3,
      "content": "The iterative refinement of educational frameworks through real-world implementation plays a critical role in shaping effective pedagogical strategies for K–12 computer science education. This process involves continuous evaluation and adjustment of teaching methodologies based on empirical data gathered from classroom settings. By embedding real-world implementation into the design cycle, educators and researchers can identify gaps in current frameworks, such as misalignment between learning objectives and practical application, and refine instructional approaches to better meet the needs of diverse learners. This cyclical process ensures that educational tools and curricula evolve in response to observed challenges and emerging pedagogical insights.\n\nReal-world implementation also facilitates the integration of feedback mechanisms that enhance the adaptability of educational frameworks. Through pilot studies and classroom trials, educators can gather qualitative and quantitative data on student engagement, comprehension, and skill development. This data-driven approach enables the refinement of instructional materials, the adjustment of pacing, and the incorporation of contextual adaptations that reflect local educational needs. Furthermore, iterative refinement supports the development of flexible frameworks that can be tailored to different learning environments, whether in traditional classrooms or informal settings, thereby promoting inclusivity and accessibility in computer science education.\n\nThe iterative nature of this refinement process is essential for addressing the dynamic and complex challenges of teaching computational thinking. As new tools and technologies emerge, educational frameworks must be continuously updated to remain relevant and effective. By grounding these frameworks in real-world implementation, researchers and educators can ensure that they are not only theoretically sound but also practically viable. This approach fosters a culture of continuous improvement, where each iteration builds upon previous experiences to create more robust and responsive educational systems."
    },
    {
      "heading": "3.1.2 Integration of assessment instruments and feedback mechanisms for continuous improvement",
      "level": 3,
      "content": "The integration of assessment instruments and feedback mechanisms is a critical component in fostering continuous improvement within computational thinking (CT) education, particularly for young learners [4]. Effective assessment tools must align with developmental stages and learning objectives, ensuring that they provide meaningful insights into students' progress without overwhelming them. This requires a balance between structured evaluation and flexible, adaptive feedback that supports individual learning trajectories. By embedding assessment within the learning process, educators can identify gaps in understanding and adjust instructional strategies in real time, promoting a more responsive and personalized learning environment.\n\nFeedback mechanisms play a pivotal role in this integration, as they directly influence student engagement and motivation. While corrective feedback is essential for skill development, it must be carefully designed to maintain intrinsic motivation and enjoyment [9]. This is especially important for children aged 8–10, who are at a crucial stage for building computational fluency [6]. Tools that incorporate both formative and summative assessment, such as mind maps and task breakdowns, enable teachers to provide timely and targeted guidance. These mechanisms not only help students refine their problem-solving approaches but also encourage self-reflection and metacognitive development.\n\nMoreover, the iterative design of assessment instruments and feedback systems is vital for long-term effectiveness. Pilot testing, as demonstrated in various educational programs, allows for the refinement of tools based on real-world usage and stakeholder input. This process ensures that assessments remain relevant and aligned with evolving pedagogical goals. By integrating feedback loops into the learning cycle, educators can create a dynamic framework that supports continuous improvement, adapts to diverse learner needs, and fosters a deeper understanding of computational concepts."
    },
    {
      "heading": "3.2.1 Analysis of student engagement and learning outcomes through surveys and observational studies",
      "level": 3,
      "content": "The analysis of student engagement and learning outcomes through surveys and observational studies provides critical insights into the effectiveness of interactive learning tools like Painting with Code. These studies reveal that students exhibit higher levels of engagement when using visual-first, domain-specific languages (DSLs), which align with their cognitive development and prior knowledge. Quantitative data from pre- and post-assessments indicate significant improvements in computational thinking (CT) scores, while qualitative feedback highlights increased motivation and a deeper understanding of abstract programming concepts [10]. Observational studies further support these findings, showing that students are more likely to persist through complex tasks when the interface is intuitive and visually engaging, reinforcing the role of learnability in educational technology design.\n\nSurveys conducted with participants in the pilot study reveal that students perceive the tool as both accessible and enjoyable, with many reporting that it helped them grasp programming fundamentals more easily than traditional text-based environments. These responses are corroborated by classroom observations, which document increased collaboration and active participation during coding activities. The integration of playful elements and immediate visual feedback appears to foster a more inclusive learning environment, particularly for students with limited prior exposure to programming. Such findings underscore the importance of designing tools that not only teach technical skills but also cultivate a positive attitude toward learning, which is essential for long-term retention and interest in computer science.\n\nThe results of this analysis also highlight the need for continued refinement of pedagogical strategies to maximize the benefits of such tools. While the initial pilot demonstrates promising outcomes, the variability in student performance suggests that personalized support and adaptive feedback mechanisms are necessary to address diverse learning needs. Future work should focus on expanding the scope of these studies to include larger and more diverse student populations, as well as integrating longitudinal assessments to evaluate the sustained impact of the tool on student learning trajectories."
    },
    {
      "heading": "3.2.2 Assessment of tool usability and effectiveness in diverse educational settings",
      "level": 3,
      "content": "The assessment of tool usability and effectiveness in diverse educational settings is a critical component in evaluating the viability of programming environments tailored for young learners. Painting with Code, designed as a domain-specific language (DSL) for visual art, was evaluated across multiple classroom contexts to determine its adaptability and pedagogical value [6]. Usability metrics focused on ease of navigation, clarity of interface, and responsiveness to user input, while effectiveness was measured through student engagement, learning outcomes, and the development of computational thinking (CT) skills. The tool’s constrained JavaScript syntax, combined with immediate visual feedback, was found to significantly enhance user experience, particularly in settings where students had limited prior programming exposure [6].\n\nIn varied educational environments, including formal classroom settings and informal after-school programs, Painting with Code demonstrated consistent usability and adaptability [6]. Teachers reported that the tool’s visual orientation and structured approach reduced cognitive load, enabling students to focus on creative problem-solving rather than syntax errors. However, effectiveness varied depending on the level of teacher support and the integration of the tool into broader curricular goals. In settings where educators provided guided instruction and contextualized tasks, students showed greater improvement in CT scores and creative output. Conversely, in environments with minimal support, the tool’s potential was underutilized, highlighting the importance of teacher training and curriculum alignment.\n\nOverall, the evaluation underscores the importance of designing tools that not only support technical learning but also align with pedagogical practices and contextual needs. Painting with Code’s success in diverse settings suggests that domain-specific programming environments can be effective when tailored to the developmental and cognitive needs of young learners. Future work should focus on expanding the tool’s adaptability and providing more robust support structures for educators to maximize its impact across different educational landscapes."
    },
    {
      "heading": "3.3.1 Co-design processes involving educators, developers, and students for context-sensitive solutions",
      "level": 3,
      "content": "Co-design processes involving educators, developers, and students are essential in creating context-sensitive solutions that align with pedagogical goals and user needs. These collaborative frameworks ensure that the design of educational tools and curricula reflects the realities of classroom environments, student capabilities, and technological constraints. By integrating the perspectives of all stakeholders, co-design fosters the development of systems that are not only technically sound but also pedagogically relevant and user-friendly. This approach emphasizes iterative feedback loops, where educators provide insights into learning outcomes, developers refine technical implementations, and students contribute to usability and engagement assessments, resulting in more effective and adaptable solutions.\n\nThe co-design process often involves structured workshops, iterative prototyping, and participatory design sessions that allow for continuous refinement of the educational experience. Educators play a critical role in identifying learning objectives and challenges, while developers translate these insights into functional tools that support creative and computational thinking. Students, as end-users, provide direct feedback on the accessibility, intuitiveness, and motivational aspects of the tools. This tripartite collaboration ensures that the final product is not only aligned with curricular standards but also responsive to the dynamic and diverse needs of the learning community. Such processes are particularly vital in fields like computational thinking, where the interplay between pedagogy, technology, and student engagement is complex and multifaceted.\n\nMoreover, co-design practices enable the creation of adaptable frameworks that can be customized for different educational contexts, cultural backgrounds, and technological infrastructures. This flexibility is crucial in ensuring that solutions are scalable and sustainable across varied settings. By embedding co-design principles into the development lifecycle, educational technologies can evolve in response to real-world feedback, leading to more inclusive and effective learning environments. Ultimately, this collaborative approach not only enhances the quality of educational tools but also empowers all stakeholders by giving them a voice in shaping the future of learning."
    },
    {
      "heading": "3.3.2 Development of open-source tools and curricula through iterative prototyping and testing",
      "level": 3,
      "content": "The development of open-source tools and curricula for K–12 computer science education has increasingly relied on iterative prototyping and testing to ensure alignment with pedagogical goals and student needs. This approach involves creating initial versions of tools and materials, evaluating their effectiveness through real-world use, and refining them based on feedback from educators and learners. By leveraging open-source frameworks, developers can foster collaboration, transparency, and continuous improvement, allowing for rapid adaptation to evolving educational standards and technological advancements. The process often includes designing modular components that can be customized for different age groups, learning objectives, and classroom environments, ensuring broader accessibility and usability.\n\nIterative prototyping also plays a crucial role in addressing the block-to-text gap, where students transition from visual programming to text-based languages. Through repeated testing and refinement, open-source tools can incorporate features that bridge this gap, such as syntax highlighting, real-time feedback, and gradual abstraction. These tools are often accompanied by curricula that emphasize computational thinking practices, including problem decomposition, iterative refinement, and collaboration. By embedding these practices into both software and teaching materials, educators can create a more cohesive learning experience that supports students as they develop programming skills. The iterative nature of this development ensures that both tools and curricula remain responsive to user needs and pedagogical insights.\n\nThe integration of open-source tools and curricula into K–12 education has been further strengthened by the involvement of educators in the design and testing phases. This participatory approach ensures that the resulting materials are not only technically sound but also pedagogically relevant and practically applicable. Workshops, pilot studies, and classroom trials are commonly used to gather feedback and validate the effectiveness of these resources. As a result, the tools and curricula are continuously improved, leading to more robust and adaptable solutions for teaching computer science. This iterative and collaborative process has proven essential in creating inclusive, engaging, and effective learning environments that support diverse student populations."
    },
    {
      "heading": "4.1.1 Problem-project-oriented learning and decomposition as core pedagogical techniques",
      "level": 3,
      "content": "Problem-project-oriented learning (PPO) and decomposition are central to modern computational education, particularly in fostering deep understanding and practical application of programming concepts. This pedagogical approach emphasizes real-world problem-solving by engaging students in extended projects that require them to break down complex tasks into manageable components. Through decomposition, learners develop the ability to analyze problems systematically, identify subtasks, and structure solutions effectively [2]. This method aligns with the principles of computational thinking, where the focus shifts from rote coding to structured reasoning and strategic planning. By integrating decomposition into the learning process, educators help students build the cognitive frameworks necessary for tackling intricate programming challenges.\n\nDecomposition, as a core technique, is often implemented through both top-down and bottom-up strategies, each offering distinct benefits. Top-down decomposition involves starting with a broad problem and progressively breaking it into smaller, more specific subproblems, while bottom-up decomposition begins with individual components and integrates them into a cohesive solution. Research indicates that expert programmers frequently employ both approaches, depending on the context and available resources. However, many current curricula emphasize top-down methods, potentially limiting students' ability to flexibly apply decomposition techniques. Incorporating both strategies into instructional design ensures that learners can adapt their problem-solving approaches to different scenarios, enhancing their overall computational literacy and resilience in the face of complex tasks.\n\nThe integration of problem-project-oriented learning with decomposition also supports the development of metacognitive skills, such as planning, monitoring, and evaluating one's own problem-solving process [2]. Techniques like test-driven development (TDD) exemplify this by encouraging students to construct test cases before writing code, thereby externalizing their reasoning and reinforcing structured thinking. Additionally, the use of large language models (LLMs) in educational settings has introduced new challenges and opportunities, as students must learn to interact with these tools in a way that complements rather than replaces their own problem-solving abilities [11]. By embedding decomposition and PPO into the curriculum, educators can help students navigate these evolving technological landscapes while cultivating essential skills for computational thinking and lifelong learning."
    },
    {
      "heading": "4.1.2 Integration of abstraction, modeling, and debugging in curriculum design",
      "level": 3,
      "content": "The integration of abstraction, modeling, and debugging in curriculum design represents a critical shift in computational education, emphasizing the development of higher-order thinking skills alongside technical proficiency [4]. Abstraction allows students to focus on essential problem characteristics while ignoring irrelevant details, a skill crucial for managing complex systems. Modeling, in this context, involves creating simplified representations of real-world phenomena, enabling learners to explore and manipulate these systems through computational lenses. Debugging, as an integral component, fosters resilience and analytical thinking by requiring students to identify and resolve errors systematically. Together, these elements form a cohesive framework that supports the development of computational thinking, encouraging students to approach problems with structured and reflective strategies [12].\n\nCurriculum design that incorporates abstraction, modeling, and debugging often relies on iterative and scaffolded learning experiences. These approaches help students build conceptual understanding gradually, moving from concrete examples to more abstract representations. For instance, code structuring exercises that emphasize abstraction enable learners to practice identifying and extracting reusable components, while modeling activities provide opportunities to simulate and analyze system behavior. Debugging is frequently embedded within these exercises, offering real-time feedback that reinforces problem-solving skills. By integrating these components, educators can create learning environments that not only teach technical skills but also cultivate deeper cognitive processes essential for effective computational practice.\n\nThe challenges of integrating these elements into curricula are significant, particularly in adapting to emerging technologies such as large language models (LLMs). While these tools offer new possibilities for generating exercises and providing feedback, they also introduce complexities in maintaining the integrity of core computational concepts. Educators must balance the use of such tools with traditional pedagogical strategies to ensure that students develop a robust understanding of abstraction, modeling, and debugging. This requires careful curriculum design that aligns with educational goals, ensuring that technological advancements enhance rather than undermine the learning outcomes associated with these critical skills."
    },
    {
      "heading": "4.2.1 Application of generative AI and LLMs for test case generation and assessment",
      "level": 3,
      "content": "Generative AI and large language models (LLMs) have emerged as powerful tools for automating test case generation and assessment in educational and software development contexts [13]. These models can analyze problem descriptions, code snippets, and requirements to produce a wide range of test cases that cover various edge cases and scenarios. By leveraging natural language processing and deep learning techniques, LLMs can generate test cases that are not only diverse but also semantically aligned with the intended functionality of the code. This capability significantly reduces the manual effort required by educators and developers to create comprehensive test suites, while also improving the robustness of software testing processes.\n\nThe integration of generative AI into test case assessment introduces new dimensions for evaluating student performance and code quality. LLMs can be trained to assess the correctness, efficiency, and completeness of generated test cases, providing automated feedback that supports iterative learning. This approach enables real-time evaluation of student submissions, allowing for immediate identification of gaps in understanding or implementation. Furthermore, the use of LLMs in assessment helps de-emphasize syntactic correctness in favor of conceptual and logical reasoning, aligning with broader educational goals of fostering computational thinking and problem-solving skills [11].\n\nDespite these advantages, challenges remain in ensuring the reliability and consistency of AI-generated test cases and assessments. Issues such as overfitting to specific problem statements, generating redundant or irrelevant test cases, and potential biases in training data must be addressed. Additionally, the integration of LLMs into educational workflows requires careful design to maintain pedagogical integrity and prevent over-reliance on automated tools. Ongoing research focuses on refining these models to enhance their accuracy, adaptability, and alignment with educational objectives, ensuring that they serve as effective complements to traditional testing and assessment methods."
    },
    {
      "heading": "4.2.2 Use of visual programming and gamification to enhance engagement and understanding",
      "level": 3,
      "content": "Visual programming and gamification have emerged as powerful tools to enhance student engagement and deepen understanding in computational thinking (CT) education [5]. By transforming abstract programming concepts into interactive and visually intuitive experiences, visual programming environments reduce cognitive load and make learning more accessible, particularly for beginners [5]. These platforms often utilize drag-and-drop interfaces, block-based coding, and real-time feedback to support iterative learning and immediate problem-solving. Gamification further complements this by incorporating elements such as points, levels, and challenges, which motivate students to persist through complex tasks and foster a sense of achievement. Together, these approaches create an immersive learning environment that aligns with the cognitive and motivational needs of diverse learners.\n\nResearch indicates that visual programming and gamification not only improve engagement but also enhance conceptual understanding by encouraging active participation and experiential learning [14]. For instance, gamified activities often require students to apply CT skills in simulated scenarios, promoting deeper processing of knowledge and reinforcing problem-solving strategies. Visual programming, on the other hand, allows students to focus on logical structures and algorithmic thinking without being overwhelmed by syntax errors [5]. This dual emphasis on engagement and comprehension is particularly valuable in introductory computer science courses, where students often struggle with abstract concepts and lack confidence in their abilities. By integrating these methods, educators can create more inclusive and effective learning pathways that support both novice and advanced learners.\n\nDespite their benefits, the implementation of visual programming and gamification requires careful design to ensure that they do not oversimplify or misrepresent core computational concepts. While these tools can enhance motivation and accessibility, they must be complemented with traditional programming practices to develop a well-rounded understanding of coding. Additionally, student perspectives must be considered, as some may perceive these methods as reducing the need for teacher involvement or as undermining the rigor of programming education. Balancing innovation with pedagogical integrity remains a key challenge, requiring ongoing research and adaptation to meet the evolving needs of learners in a rapidly changing technological landscape."
    },
    {
      "heading": "4.3.1 Analysis of educator and student attitudes toward CT tools and methodologies",
      "level": 3,
      "content": "Educator and student attitudes toward computational thinking (CT) tools and methodologies reveal a complex interplay between perceived utility, pedagogical alignment, and cognitive engagement [10]. Many educators recognize the value of integrating CT into curricula, particularly in introductory courses, as it fosters skills such as problem decomposition, abstraction, and logical reasoning [2]. However, there is significant variability in how CT is framed and implemented, leading to inconsistent learning outcomes. Students, particularly first-year learners, often express mixed opinions about the academic use of tools like ChatGPT, with some viewing them as beneficial for generating ideas or clarifying concepts, while others perceive them as potentially undermining the development of core problem-solving skills. This divergence highlights the need for structured guidance to ensure that CT tools enhance, rather than hinder, the learning process.\n\nThe extent to which first-year students can effectively utilize CT tools without formal training varies widely, influenced by prior exposure, self-regulation, and the complexity of the tools themselves. While some students demonstrate an intuitive grasp of basic CT concepts, others struggle with the abstract nature of computational reasoning, particularly when tools such as large language models (LLMs) are involved. This gap in proficiency underscores the importance of scaffolding and targeted instruction to support students in developing a deeper understanding of CT methodologies. Additionally, the integration of CT into teaching practices often faces challenges related to curriculum design, faculty training, and the alignment of assessment strategies with CT objectives. These factors collectively shape the effectiveness of CT tools in both educational and practical contexts [4].\n\nThe impact of CT tools on learning experiences and teaching practices is multifaceted, influencing not only student engagement but also pedagogical approaches [4]. While some studies suggest that CT tools can enhance cognitive engagement and foster strategic thinking, others caution that overreliance on such tools may weaken foundational skills, particularly in programming and problem-solving. Educators often report a need for clearer frameworks to guide the implementation of CT methodologies, ensuring that tools are used in ways that align with learning goals [7]. As CT continues to evolve within educational settings, ongoing research and collaboration between educators and researchers are essential to refine practices and address the challenges associated with integrating these tools effectively [4]."
    },
    {
      "heading": "4.3.2 Exploration of the role of conversational agents and AI in scaffolding learning",
      "level": 3,
      "content": "Conversational agents and artificial intelligence (AI) have emerged as pivotal tools in scaffolding learning, particularly in domains requiring complex problem-solving and conceptual understanding. These systems provide real-time feedback, adaptive guidance, and personalized support, which are critical for fostering deeper engagement and knowledge retention. By simulating human-like interactions, conversational agents can help learners navigate abstract concepts, reinforce metacognitive strategies, and encourage reflective thinking. This role is especially significant in computational thinking and programming education, where AI-driven scaffolding can bridge the gap between theoretical knowledge and practical application. The integration of AI into learning environments enables dynamic adjustments to instructional content, ensuring that learners receive targeted assistance based on their progress and needs [15].\n\nThe influence of AI-based code generation tools, such as ChatGPT, on student learning and professional development has sparked considerable debate. While these tools offer efficiency and accessibility, they also raise concerns about over-reliance and the erosion of fundamental problem-solving skills. First-year students, in particular, are at a critical stage where the development of computational thinking and programming proficiency is essential [10]. The perception of AI tools as either facilitators or hindrances to skill acquisition varies widely, depending on how these tools are integrated into the learning process. When used strategically, conversational agents can enhance learning by encouraging students to engage more deeply with the material, ask meaningful questions, and reflect on their own understanding. However, without proper guidance, students may become passive users, neglecting the development of critical thinking and independent problem-solving abilities.\n\nResearch indicates that the effectiveness of conversational agents in scaffolding learning is contingent upon their design, adaptability, and alignment with pedagogical goals. AI systems that provide structured feedback, encourage exploration, and support iterative learning are more likely to foster long-term skill development. In contrast, tools that prioritize speed and convenience over conceptual understanding may inadvertently undermine the learning process. As AI continues to evolve, it is imperative to evaluate its role in education through empirical studies and user-centered design principles. This ensures that conversational agents and AI-based tools are not only technically advanced but also pedagogically sound, ultimately contributing to a more effective and equitable learning experience [16]."
    },
    {
      "heading": "5.1.1 Development of classification schemes for CT competencies and task complexity",
      "level": 3,
      "content": "The development of classification schemes for computational thinking (CT) competencies and task complexity has emerged as a critical area of research, aiming to structure and standardize the understanding of CT skills [3]. Early efforts focused on identifying core CT concepts such as decomposition, pattern recognition, abstraction, and algorithm design, while later frameworks expanded to incorporate domain-specific applications. These classification systems often integrate both cognitive and technical dimensions, reflecting the multifaceted nature of CT. By categorizing competencies based on skill levels and task demands, researchers have sought to provide a foundation for curriculum design, assessment, and instructional strategies tailored to different learning contexts.\n\nTask complexity in CT has been approached through various dimensions, including problem structure, cognitive load, and the integration of multiple CT elements. Some frameworks emphasize the hierarchical nature of tasks, distinguishing between routine and non-routine problem-solving scenarios. Others focus on the interplay between abstract thinking and practical implementation, highlighting the need for adaptive strategies in different domains. These classifications have been instrumental in guiding the development of pedagogical tools and assessments, enabling educators to better align instruction with the cognitive demands of CT tasks [4]. However, the diversity of approaches has also led to challenges in establishing a unified framework that accommodates varying educational and professional contexts.\n\nDespite significant progress, the field continues to grapple with the dynamic and evolving nature of CT. As new technologies and interdisciplinary applications emerge, classification schemes must adapt to reflect contemporary demands. This necessitates ongoing refinement of both competency definitions and task complexity metrics. Future research is likely to focus on enhancing the granularity of these classifications, ensuring they remain relevant and applicable across diverse educational and professional landscapes. Such developments will be crucial in supporting the effective teaching and assessment of CT in an increasingly complex digital world [4]."
    },
    {
      "heading": "5.1.2 Mapping CT activities to cognitive models such as Kahneman’s two-systems framework",
      "level": 3,
      "content": "The integration of computational thinking (CT) activities with cognitive models, such as Kahneman’s two-systems framework, provides a structured approach to understanding how individuals process information and solve problems [17]. Kahneman’s model distinguishes between System 1, which is fast, intuitive, and automatic, and System 2, which is slow, deliberate, and analytical [17]. Mapping CT activities to these systems allows researchers to evaluate how different types of problem-solving tasks engage either intuitive or analytical thinking. This alignment helps in designing CT exercises that effectively target specific cognitive processes, thereby enhancing learning outcomes and cognitive development.\n\nCT activities often involve decomposition, pattern recognition, abstraction, and algorithmic thinking, which can be associated with both cognitive systems [2]. For instance, tasks that require rapid decision-making or pattern identification may align with System 1, while those involving logical reasoning or complex problem-solving may engage System 2. This dual-system perspective offers insights into how CT can be tailored to different learning contexts and individual cognitive preferences. By identifying the cognitive demands of CT tasks, educators and researchers can better align instructional strategies with the underlying mental processes involved in computational reasoning [18].\n\nFurthermore, the application of Kahneman’s framework to CT activities enables a deeper analysis of how learners interact with computational problems. It highlights the interplay between intuitive and analytical thinking, revealing how CT skills can be developed through targeted practice [4]. This mapping also supports the design of assessments that measure not only technical proficiency but also the cognitive strategies employed during problem-solving. Ultimately, integrating CT with cognitive models like the two-systems framework enhances the theoretical foundation of computational education and informs more effective pedagogical approaches."
    },
    {
      "heading": "5.2.1 Mixed-methods approaches for test development and validation in CT education",
      "level": 3,
      "content": "Mixed-methods approaches have emerged as a critical strategy in the development and validation of assessments for computational thinking (CT) education, offering a comprehensive framework to integrate both quantitative and qualitative data. These approaches enable researchers to capture the multifaceted nature of CT, which encompasses cognitive, behavioral, and emotional dimensions essential for knowledge acquisition [7]. By combining structured metrics such as standardized test scores with in-depth qualitative insights from interviews or observations, mixed-methods designs provide a more nuanced understanding of how CT skills are developed and assessed across different educational contexts.\n\nThe application of mixed-methods in CT education often involves iterative processes where initial quantitative data from pilot tests inform the refinement of qualitative data collection tools. This iterative feedback loop ensures that assessments are both reliable and valid, reflecting the complex interplay between theoretical constructs and real-world application. Furthermore, such methods allow for the exploration of contextual factors that influence CT development, such as teaching strategies, technological resources, and learner characteristics [4]. This holistic perspective is particularly valuable in addressing the challenges of standardizing CT assessments across diverse educational settings.\n\nDespite the advantages of mixed-methods approaches, their implementation requires careful consideration of methodological rigor, data integration, and interpretation. Researchers must balance the strengths of each method while mitigating potential biases or limitations. As CT education continues to evolve, the use of mixed-methods will remain essential in developing robust, context-sensitive assessments that accurately reflect the dynamic and interdisciplinary nature of computational thinking [7]."
    },
    {
      "heading": "5.2.2 Empirical evaluation of CT constructs through surveys, case studies, and experimental designs",
      "level": 3,
      "content": "Empirical evaluation of computational thinking (CT) constructs has been extensively explored through surveys, case studies, and experimental designs to assess their validity and effectiveness [3]. Surveys often focus on self-reported CT skills and their perceived utility across different domains, providing insights into how individuals recognize and apply CT principles. Case studies, on the other hand, offer in-depth analysis of CT implementation in real-world settings, such as educational curricula or interdisciplinary projects, revealing practical challenges and success factors. Experimental designs, including controlled comparisons between CT interventions and traditional methods, help quantify the impact of CT training on problem-solving abilities and cognitive development.\n\nRecent studies have demonstrated that CT constructs can be reliably measured through structured assessments, with some models showing superior performance in specific domains. For instance, the o1-preview model outperformed human experts in five out of seven CT domains, including systematic thinking and scientific reasoning, while showing limitations in abstract reasoning tasks [19]. These findings highlight the potential of advanced models to support CT development but also underscore the need for further refinement in areas where human intuition and pattern recognition remain superior. Additionally, metacognitive assessments using calibration and sensitivity measures have provided evidence of improved self-evaluation capabilities in such models [20].\n\nDespite these advancements, the evaluation of CT remains complex due to its multifaceted nature and the variability in how it is applied across disciplines [7]. While surveys and case studies offer qualitative insights, experimental designs are essential for establishing causal relationships and validating CT interventions. The lack of a unified framework for CT assessment across different educational levels and subject areas further complicates the evaluation process. Future research should focus on developing standardized metrics and integrating diverse evaluation methods to better capture the dynamic and evolving nature of CT."
    },
    {
      "heading": "5.3.1 Integration of CT with STEM subjects through case studies and curricular alignment",
      "level": 3,
      "content": "The integration of computational thinking (CT) with STEM subjects represents a critical pathway for fostering interdisciplinary problem-solving and innovation [3]. Case studies across various educational levels demonstrate how CT can be embedded within science, technology, engineering, and mathematics curricula to enhance conceptual understanding and practical application [4]. For instance, in science education, CT principles such as decomposition and pattern recognition are utilized to analyze complex phenomena, while in engineering, algorithmic thinking supports the design and optimization of systems. These examples highlight the potential of CT to serve as a unifying framework that bridges theoretical knowledge with real-world problem-solving, thereby enriching the learning experience [2].\n\nCurricular alignment plays a pivotal role in ensuring that CT is effectively integrated into STEM education. This involves designing learning objectives, instructional strategies, and assessment methods that reflect the core components of CT while remaining consistent with established STEM standards. Educational frameworks have been developed to guide this process, emphasizing the need for scaffolded learning experiences that progress from basic computational concepts to advanced problem-solving tasks. Such alignment not only supports the development of CT skills but also ensures that students can apply these skills across diverse scientific and technological contexts, reinforcing the relevance of CT in modern education.\n\nDespite the growing recognition of CT's importance, challenges remain in creating universally effective curricula that cater to varying educational contexts and student needs. The development of case studies and curricular frameworks must account for differences in resources, teacher expertise, and institutional priorities. Moreover, ongoing research is needed to evaluate the long-term impact of CT integration on student outcomes and to refine pedagogical approaches that maximize its benefits. Addressing these challenges requires collaboration among educators, policymakers, and researchers to create sustainable and adaptable CT curricula that support the evolving demands of STEM education."
    },
    {
      "heading": "5.3.2 Analysis of CT in non-traditional domains such as astrophysics and kinematics",
      "level": 3,
      "content": "The integration of computational thinking (CT) into non-traditional domains such as astrophysics and kinematics represents a significant expansion of its applicability beyond conventional computing contexts [1]. In astrophysics, CT principles are increasingly used to model complex celestial phenomena, analyze vast datasets from telescopic observations, and simulate cosmic events. These applications leverage decomposition, pattern recognition, and abstraction to manage the high-dimensional data inherent in astronomical research. Similarly, in kinematics, CT aids in the analysis of motion and mechanical systems, enabling the development of algorithms for robotics, biomechanics, and vehicle dynamics. The adoption of CT in these fields highlights its versatility in addressing problems that require structured, algorithmic reasoning and data-driven decision-making.\n\nRecent studies have demonstrated that CT can enhance problem-solving capabilities in scientific domains by providing a framework for breaking down complex systems into manageable components. In astrophysics, for instance, CT has been employed to process and interpret data from space missions, leading to more efficient analysis and discovery. In kinematics, CT-based approaches have improved the accuracy of simulations and the design of mechanical systems. These advancements underscore the potential of CT to complement domain-specific knowledge, offering a systematic method for tackling intricate scientific challenges. The ability to abstract and model real-world systems using computational methods is particularly valuable in fields where precision and scalability are critical.\n\nDespite these successes, the application of CT in non-traditional domains presents unique challenges. The interdisciplinary nature of these fields requires tailored approaches that align with domain-specific requirements and constraints. Furthermore, the lack of standardized CT frameworks for such applications necessitates ongoing research to develop domain-adapted methodologies. As computational thinking continues to evolve, its role in astrophysics and kinematics is expected to grow, driven by the increasing reliance on data-intensive and algorithmic approaches in scientific inquiry. This evolution underscores the importance of fostering interdisciplinary collaboration to fully realize the potential of CT in these emerging domains."
    },
    {
      "heading": "6 Future Directions",
      "level": 1,
      "content": "Despite significant advancements in computational thinking (CT) education, several limitations and gaps persist in the current body of research. First, the majority of studies focus on short-term outcomes and immediate engagement, with limited attention to long-term skill retention and the transfer of CT skills across domains. This gap hinders the ability to assess the sustained impact of CT tools and pedagogical approaches. Additionally, there is a lack of standardized and universally applicable assessment frameworks that can effectively measure CT competencies across diverse educational contexts and age groups. Many existing tools and curricula are also designed for specific populations or learning environments, limiting their adaptability and scalability. Furthermore, while there is growing interest in integrating artificial intelligence and generative models into CT education, the pedagogical implications of these technologies remain underexplored, particularly in terms of their impact on student autonomy, critical thinking, and deep learning.\n\nFuture research should prioritize the development of longitudinal studies that track the development and application of CT skills over extended periods. These studies can provide insights into how CT competencies evolve and how they are applied in real-world contexts. Additionally, there is a need for the creation of more flexible and adaptable assessment frameworks that can accommodate diverse learning environments and student backgrounds. This includes the development of domain-specific metrics that align with the unique demands of different educational levels and disciplines. Another important direction is the exploration of how emerging technologies, such as generative AI and conversational agents, can be integrated into CT education in ways that support, rather than replace, core problem-solving and reasoning skills. Research should also focus on improving the usability and accessibility of CT tools, particularly for underrepresented and marginalized student populations, ensuring that these resources are inclusive and equitable. Finally, further investigation is needed into the role of teacher training and professional development in effectively implementing CT curricula, as well as the development of collaborative frameworks that involve educators, developers, and students in the co-design of CT tools and materials.\n\nThe proposed future work has the potential to significantly advance the field of CT education by addressing current limitations and expanding the scope of existing research. By developing more comprehensive assessment frameworks, longitudinal studies, and adaptable pedagogical strategies, researchers can better understand how CT skills are acquired, applied, and sustained over time. The integration of emerging technologies into CT education can also enhance learning experiences and provide new opportunities for personalized and adaptive instruction. Moreover, improving the accessibility and inclusivity of CT tools can help bridge the digital divide and ensure that all students have the opportunity to develop essential computational skills. These efforts will not only contribute to the refinement of CT education but also support the broader goal of equipping learners with the critical thinking and problem-solving abilities needed in an increasingly technology-driven world. Ultimately, the continued exploration of these research directions will help shape a more effective, equitable, and sustainable future for computational thinking in education."
    },
    {
      "heading": "7 Conclusion",
      "level": 1,
      "content": "This survey paper provides a comprehensive analysis of the role of computational thinking (CT) in educational settings, with a particular focus on the use of Scratch and similar tools in fostering CT skills among young learners. The review highlights the effectiveness of visual programming environments in promoting problem-solving, logical reasoning, and creativity, while also addressing the challenges associated with their implementation. Empirical studies demonstrate that iterative refinement of educational frameworks, the integration of assessment instruments, and the use of feedback mechanisms significantly enhance the learning outcomes of students. Furthermore, the analysis of pedagogical approaches reveals that strategies such as problem-project-oriented learning, decomposition, and the inclusion of abstraction and debugging in curricula are essential for developing higher-order thinking skills. The integration of generative AI and visual programming tools further underscores the evolving landscape of CT education, offering both opportunities and challenges for educators and learners alike.\n\nThe significance of this survey lies in its contribution to the growing body of literature on CT education, offering a structured synthesis of current research, pedagogical practices, and technological innovations. By examining empirical findings, theoretical frameworks, and practical applications, this review provides a valuable resource for educators, researchers, and policymakers seeking to enhance CT education. It identifies gaps in existing research, such as the need for more standardized assessment methods and the development of curricula that align with the diverse needs of learners. Additionally, the paper emphasizes the importance of collaboration between educators, developers, and students in co-designing context-sensitive solutions that are both pedagogically sound and user-friendly. These insights are critical for advancing the field and ensuring that CT education remains relevant and effective in an increasingly digital world.\n\nLooking ahead, there is a clear need for continued research and innovation in CT education to address emerging challenges and opportunities. Future studies should focus on refining pedagogical strategies, improving assessment methods, and exploring the long-term impact of CT tools on student learning. The integration of AI and other advanced technologies into CT education presents new possibilities for personalized learning and adaptive instruction, but also raises important questions about the balance between automation and human guidance. Educators and researchers must work together to develop frameworks that support both technical proficiency and critical thinking, ensuring that CT remains a foundational skill for future generations. Ultimately, the continued advancement of CT education will depend on a commitment to interdisciplinary collaboration, empirical validation, and a deep understanding of the evolving needs of learners in a rapidly changing technological landscape."
    }
  ],
  "references": [
    "[1] A Systematic Literature Review of Computer Science MOOCs for K-12  education",
    "[2] The CTSkills App -- Measuring Problem Decomposition Skills of Students  in Computational Thinking",
    "[3] AI in Computational Thinking Education in Higher Education  A Systematic Literature Review",
    "[4] Global Overview of Computational Thinking and Digital Tools for Teaching",
    "[5] Empowering Young Learners to Explore Blockchain with User-Friendly  Tools  A Method Using Google Blo",
    "[6] Closing the Block-to-Text Gap  A Domain-Specific JavaScript Editor for Early Computational Thinking",
    "[7] Developing a learning goal framework for computational thinking in computationally integrated physic",
    "[8] Introducing Computational Thinking in Calculus for Engineering",
    "[9] Common Problems and Effects of Feedback on Fun When Programming Ozobots  in Primary School",
    "[10] MindScratch  A Visual Programming Support Tool for Classroom Learning  Based on Multimodal Generativ",
    "[11] BOOP  Write Right Code",
    "[12] ML-Quest  A Game for Introducing Machine Learning Concepts to K-12  Students",
    "[13] Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests",
    "[14] Enhancing Kinematics Understanding through a Video Game Based on  Real-Time Motion Graphs",
    "[15] An Experience Report on a Pedagogically Controlled, Curriculum-Constrained AI Tutor for SE Education",
    "[16] Anticipating User Needs  Insights from Design Fiction on Conversational  Agents for Computational Th",
    "[17] A Two-Systems Perspective for Computational Thinking",
    "[18] Teachers' perspective on fostering computational thinking through  educational robotics",
    "[19] Can OpenAI o1 outperform humans in higher-order cognitive thinking",
    "[20] A Systematic Assessment of OpenAI o1-Preview for Higher Order Thinking in Education"
  ]
}