{
  "outline": [
    [
      1,
      "A Survey of Academic Success Prediction Using Educational Data Mining and Machine Learning"
    ],
    [
      1,
      "Abstract"
    ],
    [
      1,
      "1 Introduction"
    ],
    [
      1,
      "1.1 Significance of Academic Success Prediction"
    ],
    [
      1,
      "1.2 Role of Educational Data Mining and Machine Learning"
    ],
    [
      1,
      "1.3 Objectives and Scope"
    ],
    [
      1,
      "1.4 Key Research Questions"
    ],
    [
      1,
      "1.5 Structure of the Survey"
    ],
    [
      1,
      "2 Background and Core Concepts"
    ],
    [
      1,
      "2.1 Evolution of Educational Data Mining (EDM)"
    ],
    [
      1,
      "2.2 Predictive Analytics in Education"
    ],
    [
      1,
      "2.3 Machine Learning Techniques in Academic Success Prediction"
    ],
    [
      1,
      "2.4 Student Engagement Metrics and Their Importance"
    ],
    [
      1,
      "2.5 Interdisciplinary Nature of the Field"
    ],
    [
      1,
      "3 Data Sources and Preprocessing"
    ],
    [
      1,
      "3.1 Types of Data in Academic Success Prediction"
    ],
    [
      1,
      "3.2 Data Collection Methods and Challenges"
    ],
    [
      1,
      "3.3 Preprocessing Techniques"
    ],
    [
      1,
      "4 Machine Learning Models for Academic Success Prediction"
    ],
    [
      1,
      "4.1 Supervised Learning Models"
    ],
    [
      1,
      "4.2 Unsupervised Learning and Clustering Techniques"
    ],
    [
      1,
      "4.3 Ensemble and Hybrid Models"
    ],
    [
      1,
      "4.4 Comparative Analysis and Practical Applications"
    ],
    [
      1,
      "5 Predictive Analytics in Higher Education Outcomes"
    ],
    [
      1,
      "5.1 Early Warning Systems for At-Risk Students"
    ],
    [
      1,
      "5.2 Personalized Learning Recommendations"
    ],
    [
      1,
      "5.3 Curriculum Optimization and Institutional Decision-Making"
    ],
    [
      1,
      "5.4 Case Studies and Real-World Implementations"
    ],
    [
      1,
      "6 Challenges and Limitations"
    ],
    [
      1,
      "6.1 Model Interpretability and Transparency"
    ],
    [
      1,
      "6.2 Bias and Fairness in Predictive Models"
    ],
    [
      1,
      "6.3 Scalability and Computational Limitations"
    ],
    [
      1,
      "7 Future Directions"
    ],
    [
      1,
      "7.1 Advancements in Machine Learning Techniques"
    ],
    [
      1,
      "7.2 Multimodal Data Integration"
    ],
    [
      1,
      "7.3 Interdisciplinary Collaboration and Standardization"
    ],
    [
      1,
      "7.4 Emerging Technologies and Applications"
    ],
    [
      1,
      "7.5 Future Research Priorities"
    ],
    [
      1,
      "8 Conclusion"
    ],
    [
      1,
      "References"
    ],
    [
      1,
      "Disclaimer:"
    ]
  ],
  "content": [
    {
      "heading": "A Survey of Academic Success Prediction Using Educational Data Mining and Machine Learning",
      "level": 1,
      "content": "www.surveyx.cn"
    },
    {
      "heading": "Abstract",
      "level": 1,
      "content": "This comprehensive survey paper examines the multidisciplinary field of academic success prediction through educational data mining (EDM) and machine learning (ML) techniques. We systematically analyze methodologies for forecasting student performance, retention, and graduation likelihood in higher education, focusing on data-driven approaches that enable targeted interventions and optimized learning environments. The survey encompasses supervised, unsupervised, and ensemble learning models, evaluating their efficacy across diverse educational contexts from traditional classrooms to MOOC environments. Key findings highlight the transformative potential of early warning systems, personalized learning recommendations, and institutional decision-support tools, while addressing critical challenges in model interpretability, algorithmic fairness, and computational scalability. We identify emerging trends in multimodal data integration, interdisciplinary collaboration, and standardized benchmarking, offering a roadmap for future research directions that balance predictive accuracy with ethical considerations. This work synthesizes over two decades of research (2002-2024) to provide educators, researchers, and policymakers with a structured framework for implementing predictive analytics in academic settings while maintaining alignment with pedagogical objectives and institutional values."
    },
    {
      "heading": "1 Introduction",
      "level": 1,
      "content": "The increasing complexity of educational environments necessitates the development of sophisticated methodologies for predicting academic success. As educational institutions strive to enhance student outcomes and institutional efficiency, the integration of data-driven techniques becomes paramount. This review paper aims to synthesize the current state of research in academic success prediction, emphasizing the role of Educational Data Mining (EDM) and Machine Learning (ML) within this context. By systematically analyzing various methodologies and their implications, this work seeks to provide a comprehensive overview that not only highlights the advancements in the field but also identifies existing gaps and future research directions. The significance of this review is underscored by the pressing need for effective interventions in education, particularly as the landscape continues to evolve with technological advancements."
    },
    {
      "heading": "1.1 Significance of Academic Success Prediction",
      "level": 1,
      "content": "Predicting academic success is a crucial strategy for improving educational quality and institutional efficiency, as it leverages advanced data-driven techniques to analyze diverse student performance metrics, including the impact of various assessment methods, ultimately enabling educators to tailor interventions and enhance learning outcomes. This field’s importance manifests across three critical dimensions: early identification of at-risk students, optimization of learning processes, and strategic institutional planning. The capability to identify at-risk students early represents a fundamental application of predictive analytics in education. Adaptive minimum match algorithms demonstrate particular efficacy in health professions education, where timely intervention can significantly impact student outcomes [1]. Time-series analysis of behavioral trajectories further enhances this capability by modeling student progression patterns with greater temporal precision [2]. These approaches address key limitations of traditional assessment methods, particularly in contexts like Afghanistan’s Kankor exam system where predictive analytics can mitigate systemic inefficiencies [3].\n\n![](images/91ceef6fa6f89f87e9cce6c57d4a624d8a87dbb56b9d5268a553da53e0a27a9d.jpg)  \nFigure 1: chapter structure\n\nMoreover, big data analytics transforms institutional decision-making by processing complex educational datasets. The integration of expert intuition into quantifiable model features bridges the gap between pedagogical knowledge and computational methods [4]. This synthesis proves particularly valuable in Massive Open Online Course (MOOC) environments, where analysis of communication patterns yields insights into student engagement dynamics [5]. Unified prediction models extend beyond academic performance to incorporate employability metrics, addressing the multidimensional nature of educational success [6]. The evolution of this field reflects broader trends in educational technology and data science, signifying a shift towards personalized learning experiences driven by data insights.\n\nThe developments in predictive analytics must navigate the inherent challenges of big data implementation in education, including issues of data quality, privacy, and analytical scalability [7]. The resulting predictive frameworks enable institutions to allocate resources more effectively while personalizing learning experiences at scale. This multifaceted approach not only enhances the educational landscape but also fosters a culture of continuous improvement within academic institutions. Such advancements underscore the critical need for ongoing research and development in academic success prediction methodologies, as they hold the potential to reshape educational practices fundamentally."
    },
    {
      "heading": "1.2 Role of Educational Data Mining and Machine Learning",
      "level": 1,
      "content": "Educational Data Mining (EDM) and Machine Learning (ML) have revolutionized academic success prediction through three key mechanisms: scalable analytics frameworks, behavioral pattern recognition, and adaptive learning systems. The rise of Big Data has necessitated ML systems capable of learning complex models with millions of parameters to process massive educational datasets [8]. EDM techniques have proven particularly transformative in analyzing student behavior patterns in online learning environments [9]. Systematic ensemble approaches demonstrate how combining multiple ML algorithms can enhance prediction accuracy for student performance [10]. These methods address the fundamental challenges of implementing big data analytics in education, including data quality and scalability issues [7].\n\nTime-series analysis of both clickstream data and textual feedback provides richer insights into student engagement dynamics [2]. Generalized calibration frameworks extend predictive capabilities across diverse educational contexts while maintaining model reliability [11]. The integration of expert intuition into quantifiable features bridges the gap between pedagogical knowledge and computational methods [4]. This synthesis proves particularly valuable in MOOC environments, where analysis of communication patterns yields critical insights into learning processes [5].\n\nUnified prediction models demonstrate ML’s capacity to extend beyond academic performance metrics to incorporate employability outcomes [6]. Variational inference frameworks further enhance these capabilities by efficiently estimating skill levels while quantifying prediction uncertainty [12]. These technical advancements enable educational institutions to: (1) implement scalable predictive analytics systems, (2) identify at-risk students through behavioral pattern recognition, and (3) develop adaptive learning pathways tailored to individual needs. The transformative potential of EDM/ML lies in their ability to process heterogeneous educational data while maintaining interpretability and fairness. Continued advancements in ensemble methods, variational inference, and unified modeling frameworks promise to further enhance predictive accuracy across diverse educational contexts.\n\nThe integration of these technologies signifies a transformative shift from reactive to proactive educational analytics, harnessing advanced data mining and machine learning techniques to facilitate data-driven decision-making that enhances personalized learning experiences for students while also equipping educators and institutions with actionable insights at both individual and systemic levels [13, 14, 15, 16, 17]."
    },
    {
      "heading": "1.3 Objectives and Scope",
      "level": 1,
      "content": "This survey establishes four principal objectives: (1) to systematically review machine learning and educational data mining techniques for academic success prediction across diverse educational contexts, (2) to evaluate their practical implementations in both traditional and emerging learning environments, (3) to critically assess methodological limitations and ethical considerations, and (4) to identify key research directions for advancing the field. The scope encompasses five core educational analytics domains: knowledge discovery cycles, student engagement patterns, performance forecasting, intervention systems, and institutional decision support [17].\n\nThe temporal scope spans research from 2002 to 2024, capturing the evolution from traditional data mining to contemporary machine learning approaches in education [18]. The review focuses on predictive modeling techniques applicable to both classification and regression tasks, with particular emphasis on methodologies addressing temporal educational data [19] and imbalanced datasets [20]. Special consideration is given to developing educational contexts where predictive analytics can significantly impact student placement and retention [3], as well as specialized domains like virtual learning environments [21] and reinforcement learning applications [22].\n\nThe survey methodologically encompasses a diverse array of studies that utilize various assessment techniques, including coursework-based assessments, a combination of coursework and examinations, and traditional examination methods. It also incorporates advanced data mining processes to analyze educational data, focusing on factors such as the Coursework Assessment Ratio (CAR) and Module Assessment Index (MAI), which have been shown to significantly enhance the accuracy of predicting student performance. An examination of various studies reveals that students generally achieve higher academic scores when assessed through coursework-based methodseither fully coursework-assessed modules or a combination of coursework and examinationscompared to assessments relying solely on exams. This highlights the importance of considering assessment methods in educational data mining (EDM) processes, as traditional data preparation techniques often overlook the impact of coursework and examination weighting on prediction accuracy. To address this, a novel data preparation process was developed, analyzing over 230,000 student records to refine marks based on the assessment methods of enrolled modules. The findings suggest that student final marks should be contextualized within the framework of their assessment methods, leading to the proposal of a coursework assessment ratio (CAR) as a critical attribute for enhancing prediction accuracy in student performance forecasting [23, 24, 25, 26].\n\nThe survey excludes applications outside core educational analytics, such as pure linguistic analysis in language learning contexts [15], while maintaining focus on practical implementations at the intersection of data mining and pedagogical improvement [27]. Special attention is given to emerging applications in programming education [28] and graduation rate prediction [29], while addressing critical gaps in what-if analysis capabilities [30]. The survey also considers the integration of qualitative and quantitative analytics in educational research [31], particularly within MOOC environments [5]."
    },
    {
      "heading": "1.4 Key Research Questions",
      "level": 1,
      "content": "This survey systematically examines twelve critical research questions that span technical, ethical, and implementation dimensions of academic success prediction. The first cluster focuses on model performance and comparative effectiveness: (1) What are the relative strengths of traditional machine learning versus deep learning architectures in processing heterogeneous educational data [32]?"
    },
    {
      "heading": "1.5 Structure of the Survey",
      "level": 1,
      "content": "This survey adopts a systematic seven-part structure to comprehensively examine academic success prediction through educational data mining and machine learning. Section 1 establishes the foundational context by articulating the significance of predictive analytics in education [1], the transformative role of EDM/ML techniques [10], and the survey’s methodological scope [17]. Section 2 provides conceptual grounding by tracing the historical evolution of EDM from early statistical approaches to contemporary ML paradigms [18], while detailing core predictive analytics methodologies and their educational applications [19].\n\nSection 3 examines data infrastructure requirements, addressing both traditional institutional datasets and emerging multimodal sources [5], along with critical preprocessing challenges in educational contexts [7]. Section 4 presents a technical taxonomy of machine learning models, comparing supervised approaches [33], unsupervised techniques [34], and hybrid ensemble methods [10] while evaluating their respective performance characteristics.\n\nSection 5 analyzes practical implementations across higher education ecosystems, including early warning systems [2], personalized learning frameworks [12], and institutional decision support tools [6]. Section 6 critically assesses implementation barriers spanning model interpretability, algorithmic bias [3], and computational scalability constraints [8].\n\nThe concluding Section 7 outlines emerging research frontiers, including multimodal data integration [35], advanced ML architectures [22], and interdisciplinary standardization efforts [31]. This structure facilitates both technical depth in model analysis and breadth in educational applications while maintaining focus on practical implementation challenges and future research directions.The following sections are organized as shown in Figure 1."
    },
    {
      "heading": "2.1 Evolution of Educational Data Mining (EDM)",
      "level": 1,
      "content": "Educational Data Mining (EDM) has evolved through three key phases: initial statistical analysis, traditional data mining, and modern machine learning integration. Initially, descriptive statistics and hypothesis testing were used to analyze structured educational datasets, focusing on performance and demographic patterns [34]. However, these methods struggled with complex learning behaviors and unstructured data [36]. The development of techniques for optimal categorical attribute transformation marked a significant advancement in this foundational period [37]. As the limitations of traditional statistical analyses became apparent, a shift towards more sophisticated techniques was necessary.\n\nThe transition to traditional data mining introduced classification algorithms, clustering, and association rule mining to educational research [27]. This phase saw the creation of comprehensive taxonomies for EDM applications by methodology and context [18], enhancing the validation of key performance indicators [38]. Frameworks like [39] organized research across data stages, reflecting increasing methodological sophistication. These advancements improved educational predictions and broadened research questions addressed through EDM.\n\nContemporary EDM integrates advanced machine learning in supervised, unsupervised, and reinforcement learning paradigms. Modern approaches tackle technical challenges with innovations such as dynamic skill mastery modeling [40]. MOOC analytics have moved beyond traditional methods to analyze communication patterns and engagement in online environments [35]. Studies now evaluate prediction performance and fairness trade-offs [41], emphasizing machine learning frameworks capable of handling educational data complexities while ensuring equitable outcomes.\n\nEDM’s evolution reflects broader trends in managing uncertainty in large-scale educational hypotheses [7]. Virtual learning environments have particularly benefited, with classification and regression models enabling nuanced analysis of academic indicators [21]. Behavioral analysis in online learning has advanced, distinguishing active from passive engagement patterns [9]. Institutional analytics frameworks have progressed from descriptive to predictive models, enhancing decision-making [3]. This transformation illustrates EDM’s potential to inform educational practices and policies, improving student outcomes.\n\nThe integration of cognitive science with computational techniques has led to hybrid models incorporating observable behaviors and psychological mechanisms, advancing beyond traditional methods. Large Language Models (LLMs) enhance predictive analytics by quantifying expert insights [42, 14, 4]. Explainable AI frameworks provide transparent models that identify at-risk learners and generate tailored recommendations. This synthesis underscores the potential for sophisticated, knowledge-driven approaches across diverse fields, emphasizing performance and interpretability in model development. Contemporary EDM systems address technical challenges and epistemological considerations while focusing on educational objectives across diverse environments."
    },
    {
      "heading": "2.2 Predictive Analytics in Education",
      "level": 1,
      "content": "Predictive analytics in education systematically forecasts student outcomes using statistical modeling and machine learning. It operates through pattern recognition in historical data, real-time monitoring of behaviors, and probabilistic forecasting. These approaches transform raw data into actionable insights for educators and administrators [43], enhancing understanding of student needs and tailoring interventions to improve retention and success.\n\nApplications span individual learning optimization to institutional policy formulation. In language learning, cluster analysis personalizes curricula by identifying learner profiles [15]. Graph convolutional networks model interactions between educational features, enhancing prediction accuracy [44]. Transfer learning addresses limited data by leveraging proxy variables from related domains [45], identifying at-risk students, optimizing resources, and personalizing interventions.\n\nData quality and fairness are critical considerations. Imputation techniques for missing data require auditing to prevent biases affecting marginalized groups [46]. Balancing model complexity with interpretability ensures actionable outputs while maintaining accuracy. Robust validation protocols assess statistical performance and equity across demographics, fostering predictive analytics that enhance outcomes and promote inclusivity.\n\nPredictive analytics benefits extend beyond immediate outcomes to longitudinal trajectories. Science education research shows predictive modeling illuminates factors between strategies and mastery [43]. Identifying inflection points enables targeted support at critical moments, informing pedagogical adjustments and curricular reforms. This holistic perspective emphasizes continuous assessment and feedback, ensuring timely and relevant interventions.\n\nFuture advancements will focus on integrating multimodal data streams, refining explainable AI for educational contexts, and establishing evaluation metrics assessing accuracy and applicability [14, 16, 17, 2, 26]. These directions reflect maturation from technical exercises to frameworks aligning computational methods with pedagogical objectives and priorities."
    },
    {
      "heading": "2.3 Machine Learning Techniques in Academic Success Prediction",
      "level": 1,
      "content": "Machine learning in academic success prediction involves supervised learning for forecasting, unsupervised learning for pattern discovery, and ensemble methods combining approaches. Supervised learning dominates performance prediction, with context-dependent efficacy across models. The Adaptive Minimum Match K-Nearest Neighbors (AMMKNN) algorithm dynamically adjusts neighbors based on performance [1]. Systematic Ensemble Model Selection (SEMS) enhances grade prediction accuracy and identifies at-risk students [10].\n\nUnsupervised learning facilitates exploratory analysis through clustering and feature selection. KMeans clustering categorizes student behaviors in online environments [9]. HARVEST tests predictive power across data subsets [47]. These techniques uncover latent structures without predefined labels, supporting curriculum design and intervention planning.\n\nHybrid architectures integrate paradigms to address educational challenges. Click2State combines clickstream data and notes through time-series analysis [2]. The Unified Prediction Model (UPM) applies ensemble classification for employability outcomes [6]. VarFA introduces a variational inference framework for Bayesian learning analytics [12]. These models exemplify interdisciplinary collaboration, merging insights to create effective predictive systems.\n\nEmerging techniques incorporate domain knowledge and qualitative insights into ML architectures. Large Language Models (LLMs) quantify qualitative ’red flags’ [4]. These innovations address MOOC challenges with diverse datasets and non-standard benchmarks [35]. Integration must navigate big data challenges like real-time processing and scalability [7], developing robust models enhancing outcomes while ensuring scalability and efficiency.\n\nKey considerations include model interpretability for stakeholders, considering assessment methods and educational data characteristics [23, 26]. Feature engineering optimizes predictive accuracy, accounting for assessment methods and irrelevant attributes [48, 10, 26, 16]. Fairness constraints mitigate algorithmic bias, ensuring equitable outcomes [49, 46, 50]. Optimizing computational efficiency supports large-scale deployment, enhancing accuracy and instructional approaches [8, 51, 26, 52].\n\nThe field evolves through variational inference and ensemble learning, focusing on dynamic model adaptation, multimodal architectures, and explainability frameworks. These advancements improve predictive accuracy and applicability, addressing data quality and model generalization issues. Methodologies like coursework assessment ratio (CAR) refine predictions, and explainable AI provides actionable feedback for at-risk students, enhancing interventions and outcomes [14, 26]."
    },
    {
      "heading": "2.4 Student Engagement Metrics and Their Importance",
      "level": 1,
      "content": "Student engagement metrics predict academic success through behavioral indicators and cognitive participation patterns across learning environments. Data collection involves digital interaction logs, attendance records, and dialogue analysis. The DialogID dataset provides structured benchmarks for analyzing interactions [53], enabling systematic comparisons while addressing qualitative dynamics. These metrics inform teaching strategies to foster interactive learning environments.\n\nBehavioral engagement metrics are predictive when analyzed longitudinally. Early patterns correlate with outcomes, distinguishing successful from at-risk students [54]. Attendance credibility measures ensure data reliability [55]. Quantitative measures complement qualitative assessments, forming multidimensional profiles enhancing prediction accuracy.\n\nEngagement metrics follow three analytical paradigms: temporal pattern recognition in interactions, clustering behavioral archetypes, and predictive modeling using composite indices. LMS data allows detailed activity pattern analysis, while validated attendance records indicate engagement and commitment [25, 55, 56]. Dialogic instruction analysis captures engagement quality beyond frequency, emphasizing various dimensions in predicting success.\n\nKey challenges include tailored data preparation for diverse assessment methods, impacting prediction accuracy. Comprehensive analysis of standardized systems ensures effective data utilization and support [26, 3]. Recent studies show higher performance through coursework and exams, highlighting assessment methods’ importance in EDM [24, 25, 26].\n\nStandardizing engagement metrics across contexts enables data integration and comparisons, supporting targeted interventions [23, 54, 57, 21, 26]. Integrating multimodal data streams and predictive analytics identifies at-risk students and tailors interventions [54, 14]. Aligning behavioral indicators with outcomes enhances prediction accuracy [57, 26].\n\nEthical considerations in engagement monitoring involve privacy, data integrity, and biases. Transparent and responsible data collection ensures diverse experiences inform interventions while safeguarding rights [54, 4].\n\nThe evolution of engagement analytics aligns with multidimensional frameworks integrating behavioral, emotional, and cognitive indicators. Higher education emphasizes diverse cohorts and sophisticated data integration. Frameworks predict outcomes and emphasize explainable AI for tailored support, improving retention and completion [54, 14]. Future research focuses on dynamic models, non-invasive measurement, and integration with early warning systems, enhancing predictive validity and pedagogical utility while addressing interoperability and privacy challenges."
    },
    {
      "heading": "2.5 Interdisciplinary Nature of the Field",
      "level": 1,
      "content": "Academic success prediction is interdisciplinary, synthesizing education, data science, psychology, and computational modeling. This involves integrating pedagogical theory with machine learning, cognitive science informing features, and social science guiding ethics. Research bridges physics, data science, and education, transferring techniques across domains [58].\n\nEDM and learning analytics require dialogue between computer scientists and pedagogy experts [17], balancing model complexity with interpretability. Reinforcement learning combines algorithms with psychology for personalized curriculum designs [22].\n\nFairness considerations highlight interdisciplinary maturation, needing contributions from data scientists, ethicists, and educators. Evaluations of fairness measures adapt to pedagogical values and priorities [59]. Fairness in EDM requires collaborative frameworks addressing technical and equity concerns [60].\n\nSocial network analysis adds layers through models capturing community dynamics. Tie-decay algorithms simulate information flow, blending sociology and computational modeling [61]. Educational analytics apply geometric and topological analysis to social and behavioral patterns [31].\n\nInterdisciplinary collaboration integrates advanced modeling in EDM, focusing on STEM job prediction and assessment methodologies enhancing predictability. Collaborations leverage insights from data science, education, and psychology to improve predictions by considering knowledge states, assessment methods, and coursework ratios [62, 26].\n\nRecent studies show higher performance through coursework and exams, emphasizing assessment methods’ importance in EDM [24, 25, 26]. Joint development of predictive features integrates efficiency with pedagogical relevance, incorporating coursework assessment ratios [57, 26].\n\nModel evaluation metrics balance performance with educational utility. Nuanced data preparation accounts for coursework ratios, enhancing predictive accuracy. Adaptive metrics reflect learning dynamics, aligning evaluation with rigor and outcomes [57, 26].\n\nIntegrated frameworks address ethical challenges, emphasizing transparent data preparation and explainable AI for tailored interventions, ensuring models enhance performance while upholding ethics [14, 16, 26].\n\nUnified models connect behavioral data with cognitive processes, analyzing diverse assessment methods to enhance predictions of performance and engagement [26, 63].\n\nFuture trajectories focus on neuroscience insights with machine learning, collaboration between policymakers and data scientists, and unified frameworks reconciling terminologies. Initiatives like ASSISTments Data Mining predict STEM jobs from learning histories. Deep learning in EDM addresses knowledge tracing, behavior analysis, and personalized recommendations, highlighting interdisciplinary approaches in educational research [32, 62]. This synthesis enhances technical robustness and practical applicability while aligning with educational values."
    },
    {
      "heading": "3 Data Sources and Preprocessing",
      "level": 1,
      "content": "Understanding data sources and preprocessing is fundamental to effective predictive modeling in academic success prediction. This section outlines the types of data used, from structured institutional records to unstructured behavioral traces, and emphasizes the role of hybrid datasets in improving predictive accuracy. Figure 2 displays a hierarchical organization of the data sources and preprocessing techniques used in academic success prediction, highlighting the main categories of data types, the collection methods and challenges associated with data gathering, and the preprocessing methods to ensure data compatibility and accuracy in predictive modeling. Integrating diverse data sources is crucial for capturing the multifaceted nature of academic performance, reflecting cognitive, emotional, and social factors influencing student success. The following subsection explores specific data types integral to academic success prediction, analyzing their characteristics and implications for analytical approaches.\n\n![](images/632092337112778d997c5f673f8b76fd80a140462ee7e3f27b41d84ee547d5d8.jpg)  \nFigure 2: This figure displays a hierarchical organization of the data sources and preprocessing techniques used in academic success prediction, highlighting the main categories of data types, the collection methods and challenges associated with data gathering, and the preprocessing methods to ensure data compatibility and accuracy in predictive modeling."
    },
    {
      "heading": "3.1 Types of Data in Academic Success Prediction",
      "level": 1,
      "content": "Academic success prediction systems leverage structured institutional records, unstructured behavioral traces, and hybrid multimodal datasets, each offering distinct analytical advantages. Structured data, including grades, attendance records, and demographics, forms the basis of traditional predictive analytics. Studies by [1] and [3] illustrate the predictive power of structured data in analyzing performance patterns. These datasets serve as both primary inputs and validation benchmarks, enhancing model robustness.\n\nUnstructured data, captured through digital interaction logs and qualitative feedback, provides insights into learning processes. [9] and [2] demonstrate the use of Moodle logs and clickstream data to analyze engagement. Learning Management System (LMS) data offers temporal insights into engagement dynamics, complementing traditional metrics [10]. Although requiring sophisticated preprocessing, these sources offer granular insights into student engagement and potential.\n\nHybrid datasets, integrating multiple modalities, address single-source limitations by creating multidimensional learner profiles. The Unified Prediction Model by [6] and the variational factor analysis framework by [12] exemplify enhanced predictive accuracy through combined datasets. Feature relevance methodologies like HARVEST provide transferable insights for identifying predictive features [47]. Hybrid approaches not only improve prediction accuracy but also enhance model interpretability by offering a richer context.\n\nRecognizing key characteristics of educational data is vital for predictive performance. Assessment methods like the coursework assessment ratio (CAR) and module assessment index (MAI) are crucial for understanding evaluation strategies’ impact on outcomes. Research indicates higher scores with coursework-based assessments compared to exams. Analyzing over 230,000 student records shows that integrating these methods into educational data mining frameworks enhances prediction accuracy, necessitating tailored data preparation [25, 26].\n\nTemporal granularity in longitudinal records allows detailed performance analysis over time, enhancing prediction accuracy by examining evaluation strategies’ impact [13, 2, 26, 18]. Behavioral density in digital interaction traces, analyzed through clickstream data, enhances personalized learning experiences [42, 64, 16]. Demographic diversity plays a crucial role, with research showing higher grades through coursework-based assessments, emphasizing tailored approaches in data analysis [24, 26].\n\nFeature interpretability in high-dimensional datasets enhances predictive analytics, particularly where assessment methods impact performance. Incorporating coursework assessment ratios clarifies factors contributing to outcomes [45, 26]. The evolution towards multimodal integration suggests future developments will emphasize standardized schemas, privacy-preserving data fusion, and automated feature engineering, facilitating nuanced learner modeling and overcoming challenges in data interoperability and scalability. Strategies like social recommender systems and advanced machine learning methods aim to optimize personalized educational experiences [23, 16, 63]."
    },
    {
      "heading": "3.2 Data Collection Methods and Challenges",
      "level": 1,
      "content": "Data collection for academic success prediction involves diverse methodologies, each presenting technical and ethical challenges. Institutional records, extracted from student information systems, often exhibit class imbalance, risking model misclassification [65]. Learning management systems (LMS) provide interaction logs, requiring specialized analysis techniques [9].\n\nUnstructured data collection, particularly from open-ended responses, introduces complexity due to high variability [24]. Simulation-based learning environments require specialized skills for data capture [66]. Relational databases demand substantial expertise for feature identification [67].\n\nTechnical challenges include integrating diverse data sources, sophisticated preprocessing for varying assessment methods, and frameworks accurately predicting performance and identifying at-risk students [68, 69, 26]. Class imbalance necessitates advanced techniques like the HARVEST algorithm for effective feature selection [47, 51, 12, 45, 26].\n\nTemporal inconsistencies in longitudinal data can mislead performance and engagement trend analysis [54, 70, 2, 26, 71]. Cross-institutional data heterogeneity limits model generalization due to varying assessment methods [6].\n\nEthical considerations include privacy preservation, algorithmic fairness, and informed consent. Algorithmic bias detection is challenging with small or imbalanced samples, potentially exacerbating inequalities [50]. Data collection must balance granularity with privacy, complying with regulations like FERPA and GDPR.\n\nEmerging solutions include refining module assessment methods, leveraging educational data mining for study guidance, and integrating explainable AI with prescriptive analytics for tailored support [68, 14, 7, 26]. Adaptive sampling techniques address imbalanced datasets, optimizing sample distribution for reliable insights [10, 51, 26, 20].\n\nPrivacy-preserving data fusion methods like FedValue enhance predictive analytics in vertical federated learning (VFL) [72, 26]. Standardized metadata schemas ensure cross-institutional compatibility, enhancing predictive model accuracy [73, 26]. Comprehensive data governance frameworks incorporating diverse assessment methods and explainable AI techniques enhance educational data mining accuracy and provide tailored interventions [14, 26].\n\nThe field is evolving towards robust data collection paradigms addressing technical and ethical challenges. Future developments will prioritize automated quality assurance pipelines, federated learning architectures, and participatory design approaches. This shift aims to improve interventions for at-risk students and foster transparency and collaboration among stakeholders. Advancements in explainable AI and prescriptive analytics will generate actionable insights and tailored recommendations, enhancing retention and completion rates [14, 39].\n\nAs illustrated in Figure 3, the hierarchical structure of data collection methods and challenges in academic success prediction highlights the interplay between technical challenges, ethical considerations, and emerging solutions. These advancements aim to enhance data reliability while aligning with educational values and priorities.\n\n![](images/38f76a804e3c894aa40e56f52946cfb45126656b4b0a262f1059b816a675185b.jpg)  \nFigure 3: This figure illustrates the hierarchical structure of data collection methods and challenges in academic success prediction, highlighting technical challenges, ethical considerations, and emerging solutions."
    },
    {
      "heading": "3.3 Preprocessing Techniques",
      "level": 1,
      "content": "Preprocessing techniques for academic success prediction datasets address feature engineering, handling missing values, and normalization for algorithmic compatibility. Feature selection is crucial in high-dimensional datasets, where irrelevant features degrade performance. The HARVEST method systematically tests feature relevance, mitigating overfitting [47]. Optimal categorical attribute transformation enhances feature utility by converting nominal variables for machine learning [37].\n\nMissing data imputation requires specialized approaches due to non-random patterns. Multiple imputation techniques accounting for temporal dependencies are more effective than mean substitution, especially for longitudinal metrics [2]. Auditing imputation effects on fairness is crucial for protected attributes, requiring careful bias evaluation [46]. These methods must balance efficiency with statistical rigor, particularly for large datasets [7].\n\nNormalization and standardization techniques account for educational variables’ distinct characteristics, enhancing predictive accuracy by considering assessment methods and coursework ratios [25, 16, 26]. Min-max scaling for bounded metrics like grades and attendance enhances accuracy by accounting for diverse assessment methods [26, 57, 38, 25, 1]. Z-score standardization applies to normally distributed indicators, allowing accurate performance comparison across assessment methods [25, 26].\n\nLog transformations address skewed interaction frequency counts, enhancing accuracy in models assessing performance and outcomes [57, 14, 26, 12]. Feature hashing efficiently manages highcardinality variables, facilitating improved performance in extensive datasets [57, 51, 47, 26].\n\nAddressing concept drift in longitudinal datasets requires innovative strategies to adapt to nonstationary data, emphasizing tailored preparation for varying assessment methods [26, 74]. Protecting sensitive information while transforming features into quantifiable formats is essential for maintaining privacy and leveraging domain knowledge [47, 4, 26]. Ensuring interpretability of preprocessed features enhances model accuracy and transparency, particularly when considering assessment methods’ impact on performance [75, 26].\n\nManaging class imbalance is crucial in predictive tasks like fraud detection and educational analysis, where the minority class represents significant outcomes. Techniques for imbalanced distributions enhance accuracy by accounting for rare instances, improving model performance [51, 26, 20]. Future directions emphasize automated preprocessing pipelines adapting to educational contexts while maintaining transparency. Incorporating domain-specific knowledge ensures technical transformations resonate with pedagogical frameworks, accurately reflecting assessment nuances. This alignment is crucial for reliable predictions, leading to effective interventions and improved outcomes [23, 14, 26]. These advancements will enable robust and generalizable prediction systems while addressing persistent data quality and feature engineering challenges."
    },
    {
      "heading": "4 Machine Learning Models for Academic Success Prediction",
      "level": 1,
      "content": "<html><body><table><tr><td>Category</td><td>Feature</td><td>Method</td></tr><tr><td>Supervised Learning Models</td><td>Adaptive Techniques</td><td>SAP[8], AMMKNN[1]</td></tr><tr><td>Unsupervised Learning and Clustering Techniques</td><td> DimensinaGiroupdRepresentaion</td><td>KDMa41]</td></tr><tr><td>Ensemble and Hybrid Models</td><td></td><td>SEMS10].C2[2],UP[6</td></tr><tr><td>Comparative Analysis and Practical Applications</td><td>Efficient Processing Techniques</td><td>RNN-Attention-KD[76], QFM[77]</td></tr></table></body></html>\n\nTable 1: Table of machine learning methodologies applied in predicting academic success, categorized by learning models and techniques. This comprehensive overview includes adaptive techniques for supervised learning, dimensionality representation for unsupervised approaches, model integration methods in ensemble models, and efficient processing techniques in practical applications.\n\nPredicting academic success through machine learning requires a nuanced understanding of various methodologies. Supervised learning models, pivotal in this domain, use labeled data to identify patterns linked to student performance, aiding informed educational decisions. Table 1 summarizes the diverse machine learning methodologies utilized in the domain of academic success prediction, offering insights into their categorization by learning models and specific techniques. Additionally, Table 4 offers a comparative overview of key machine learning methodologies employed in the prediction of academic success, delineating their algorithmic characteristics, advantages, and application contexts. The following subsection delves into key supervised learning models, detailing their characteristics, advantages, and applications in predicting academic success."
    },
    {
      "heading": "4.1 Supervised Learning Models",
      "level": 1,
      "content": "<html><body><table><tr><td>Method Name</td><td>Algorithmic Families</td><td>Application Context</td><td>Performance Considerations</td></tr><tr><td>UPM[6]</td><td>Ensemble Classification Techniques</td><td>Diverse Educational Contexts</td><td>Prediction Accuracy And Universality</td></tr><tr><td>AMMKNN[1]</td><td>K-nearest Neighbors</td><td>At-risk Students</td><td>Execution Efficiency</td></tr><tr><td>SAP[8]</td><td>ML Algorithms</td><td>Distributed ML Systems</td><td>Execution Efficiency</td></tr><tr><td>C2S[2]</td><td>Recurrent Neural Network</td><td>At-risk Students</td><td>Predictive Accuracy</td></tr><tr><td>VarFA[12]</td><td>Bayesian Inference Methods</td><td>Skill Level Estimations</td><td>Computational Efficiency</td></tr><tr><td>SEMS[10]</td><td>Machine Learning Algorithms</td><td>E-learning Environments</td><td>Prediction Accuracy</td></tr></table></body></html>\n\nTable 2: Summary of supervised learning methods applied in educational contexts, highlighting algorithmic families, application domains, and performance considerations. This table provides a comparative overview of various models, including UPM, AMMKNN, SAP, C2S, VarFA, and SEMS, emphasizing their efficiency and predictive accuracy in different educational settings.\n\nSupervised learning models are central to predicting academic success, with four main algorithmic families offering distinct benefits. Table 2 presents an overview of supervised learning models employed in educational settings, detailing their algorithmic families, application contexts, and performance considerations. Decision tree-based methods, such as CART and Random Forest, provide interpretability and robust predictive performance through hierarchical structures. The Unified Prediction Model (UPM) exemplifies this, using automated preprocessing and ensemble techniques for improved accuracy across various educational indicators [6]. These methods, particularly effective when paired with adaptive minimum match algorithms, achieve high accuracy in identifying at-risk students in health education [1].\n\nSupport Vector Machines (SVMs) excel in high-dimensional educational spaces by maximizing margins. Structure Aware Parallelization (SAP) enhances SVM execution efficiency through optimized parameter updates [8]. While SVMs adeptly handle imbalanced datasets, careful kernel selection and parameter tuning are essential for scalability and efficiency, making them suitable for diverse educational contexts.\n\nNeural networks have revolutionized temporal academic prediction by modeling complex sequential patterns. The Click2State model, using recurrent architectures, surpasses traditional methods in predicting pass/fail outcomes [2]. Variational Factor Analysis (VarFA) enhances neural models with Bayesian techniques, improving speed and accuracy in skill estimation [12]. These models excel in longitudinal engagement analysis but face interpretability challenges, limiting their use in highstakes decisions.\n\nHybrid supervised models combine paradigms to tackle specific educational prediction challenges. The Systematic Ensemble Model Selection (SEMS) framework integrates classifiers at various course stages, enhancing grade prediction accuracy while retaining interpretability [10]. Logistic regression and gradient boosted trees are effective in dropout prediction when finely tuned [41]. These methods balance predictive power with practical implementation needs.\n\nImplementation trade-offs include the impact of assessment methods on predictability and the integration of transparent predictive analytics for tailored interventions [14, 26]. Comprehensive strategies that incorporate both predictive modeling and educational context are vital for understanding academic success."
    },
    {
      "heading": "4.2 Unsupervised Learning and Clustering Techniques",
      "level": 1,
      "content": "Unsupervised learning in academic success prediction focuses on dimensionality reduction and clustering for student subgroup identification. Techniques like Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) effectively transform high-dimensional educational data into interpretable forms while preserving predictive relationships [34]. These methods aid in exploring complex educational variables by reducing multidimensional student profiles into lower-dimensional, visualizable spaces. Figure 4 illustrates the key techniques in unsupervised learning and clustering within educational data mining, highlighting dimensionality reduction methods, clustering algorithms, and temporal clustering approaches.\n\nClustering algorithms identify latent student subgroups based on behavior and performance, with K-Means and hierarchical clustering being prevalent. [9] uses K-Means to categorize online learning engagement, identifying clusters of active, passive, and disengaged students. Gaussian Mixture Models (GMMs) allow overlapping cluster memberships, useful for analyzing multifaceted behaviors [18]. These methods enable targeted interventions tailored to specific learner groups, enhancing educational effectiveness.\n\nDensity-based clustering methods like DBSCAN detect outliers in educational datasets, identifying students with atypical behaviors [21]. The HARVEST methodology enhances feature selection in clustering, evaluating attribute relevance through random subset testing [47]. These techniques are valuable for analyzing open-ended responses, capturing nuanced qualitative patterns [24].\n\nTemporal clustering models the evolution of student behaviors over time, addressing learning processes’ dynamic nature. The Click2State framework demonstrates how time-series clustering of interaction patterns predicts academic outcomes while maintaining interpretability [2]. Variational inference approaches like VarFA efficiently estimate latent skill trajectories, quantifying uncertainty in cluster assignments [12]. These methods help track student progression and intervene at critical points, supporting retention and success.\n\nImplementation considerations include assessment methods and data preparation tailored to educational contexts, enhancing predictive accuracy [26, 3]. Aligning data preparation with educational frameworks maximizes predictive models’ effectiveness.\n\nEmerging applications integrate unsupervised and supervised techniques through semi-supervised architectures. The Unified Prediction Model shows how clustering informs feature engineering for classification tasks, enhancing prediction accuracy and interpretability [6]. Future research should focus on dynamic clustering for evolving student populations, multimodal integration, and explainable AI for cluster interpretation, bridging discovery and actionable insights while addressing data heterogeneity and temporal dynamics."
    },
    {
      "heading": "4.3 Ensemble and Hybrid Models",
      "level": 1,
      "content": "Ensemble and hybrid models in academic success prediction combine machine learning techniques to enhance accuracy, robustness, and generalization. These approaches use parallel model combination, sequential model stacking, and hybrid architectures merging distinct paradigms. The Systematic Ensemble Model Selection (SEMS) framework exemplifies parallel ensembles, combining classifiers at different stages for superior grade prediction accuracy while maintaining interpretability [10]. This approach addresses variability in performance patterns across terms and domains.\n\n![](images/9295d0a62a9c40f53b42ec36f4804f21a97a5e24953df66782321a53067f5cfb.jpg)  \nFigure 4: This figure illustrates the key techniques in unsupervised learning and clustering within educational data mining, highlighting dimensionality reduction methods, clustering algorithms, and temporal clustering approaches.\n\nSequential stacking leverages complementary model strengths through hierarchical pipelines. The Unified Prediction Model (UPM) integrates feature selection, preprocessing, and ensemble classification for predicting performance and employability across indicators [6]. The Click2State model illustrates sequential processing benefits, combining time-series clickstream analysis with mentor notes [2]. These hybrid approaches handle heterogeneous data modalities in modern learning environments, improving predictive capabilities.\n\nAdvanced hybrid architectures incorporate domain knowledge through innovative feature engineering. Translating expert intuition into quantifiable features bridges pedagogical knowledge and computational methods, as seen in MOOC environments where qualitative ’red flags’ become predictive metrics [4]. Variational Factor Analysis (VarFA) combines deep learning’s power with probabilistic models’ uncertainty quantification for skill estimation [12]. These architectures address interpretability challenges while maintaining performance, ensuring stakeholder trust in predictions.\n\nEnsemble and hybrid approaches optimize accuracy, enhance model selection through feature analysis, and integrate diverse algorithms to accommodate student performance data complexities [10, 57, 51, 62, 26]. Ongoing refinement is crucial for advancing educational data mining.\n\nEmerging directions emphasize dynamic weighting schemes, automated model selection pipelines optimizing accuracy and fairness, and multimodal architectures integrating behavioral, cognitive, and institutional data. These advancements address model generalization challenges while aligning with pedagogical and institutional objectives. Ensemble techniques in educational data mining are set to enhance computational methods’ integration with practical applications, improving academic success prediction through systematic model selection and diverse assessment methods [51, 10, 26]."
    },
    {
      "heading": "4.4 Comparative Analysis and Practical Applications",
      "level": 1,
      "content": "<html><body><table><tr><td>Benchmark</td><td>Size</td><td>Domain</td><td>Task Format</td><td>Metric</td></tr><tr><td>PEEKC[78]</td><td>290,535</td><td>Artificial Intelligence</td><td>Engagement Prediction</td><td>Accuracy,F1</td></tr><tr><td>AGKA[23]</td><td>20,724</td><td>Educational Text Classification</td><td>Behavior Classification</td><td>Accuracy,F1</td></tr><tr><td>EDM[36]</td><td>90</td><td>Engineering</td><td>Classification</td><td>Accuracy,TP Rate</td></tr><tr><td>DL-OPC[79]</td><td>10.610</td><td>Course Feedback Analysis</td><td>Sentiment Analysis</td><td>Accuracy,F1-macro</td></tr><tr><td>DialogID[53]</td><td>30,431</td><td>Education</td><td>Instruction Detection</td><td>F1</td></tr><tr><td>EDM[80]</td><td>1,000</td><td>Educational Data Mining</td><td>Comparative Analysis</td><td>Pass Percentage</td></tr><tr><td>MORF[73]</td><td>270</td><td>Educational Data Mining</td><td>Dropout Prediction</td><td>Accuracy,F1-score</td></tr><tr><td>FGM-SPP[59]</td><td>20,798</td><td>Educational Data Mining</td><td>Student Performance Predic- tion</td><td>Statistical parity,Equal opportunity</td></tr></table></body></html>\n\nTable 3: Table illustrating various benchmarks used in educational data mining and related domains, detailing the dataset size, domain, task format, and evaluation metrics. This comprehensive overview highlights the diversity of datasets and tasks, facilitating comparative analysis of machine learning models for academic success prediction.\n\nComparative evaluation of machine learning models for academic success prediction reveals contextdependent performance across educational settings and tasks. Decision tree-based approaches are effective in structured prediction scenarios, as [18] shows their superiority in grade forecasting. These models offer interpretability through hierarchical structures, suitable for institutional decisionmaking requiring transparency. However, they struggle with high-dimensional data or complex temporal patterns in engagement metrics.\n\nRecurrent neural networks with attention mechanisms advance temporal academic prediction, with the RNN-Attention-KD framework achieving superior recall and F1-measure in early risk identification [76]. These architectures process sequential interaction data but require substantial resources and training data. Quaternion factorization machines (QFM) offer lightweight, competitive performance with reduced parameters, practical for resource-constrained institutions [77].\n\nPractical applications highlight diverse implementation patterns across model families, emphasizing integrating domain knowledge, predictive analytics, and tailored feedback to enhance decisionmaking and outcomes [14, 4, 54, 63, 26]. Adapting models to specific environments and populations maximizes impact. Table 3 provides a comprehensive overview of representative benchmarks utilized in educational data mining, detailing their characteristics to facilitate comparative analysis and practical applications in predictive modeling.\n\nDecision trees and random forests are preferred in early warning systems for their interpretability, enabling stakeholders to understand predictions and make informed decisions on at-risk students. This transparency facilitates timely interventions to improve retention and completion rates [4, 14, 75, 26].\n\nEnsemble methods enhance predictive accuracy and reduce false positives in MOOC environments with diverse data streams, as systematic analyses highlight the importance of selecting suitable algorithms and parameters tailored to educational data [5, 51, 10, 26]. Their adaptability to various contexts enhances utility and effectiveness.\n\nHybrid architectures integrating neural and symbolic approaches are effective for predicting longitudinal outcomes, leveraging machine learning’s pattern identification and symbolic reasoning’s interpretability. Incorporating diverse assessment methods in data preparation significantly influences predictive performance. Explainable AI techniques improve model interpretation, facilitating tailored interventions and improving retention and completion rates [14, 26].\n\nLightweight factorization models, like Neural Factorization Machines (NFM) and VarFA, enable real-time analytics in resource-limited environments by efficiently handling sparse data and providing uncertainty estimations. NFM’s combination of linear and non-linear feature interactions makes it more expressive, while VarFA’s variational inference supports scalable Bayesian learning, effective even with large datasets. These advancements support adaptive testing and decision-making in predictive analytics [81, 82, 12].\n\nMethodological choices must align with specific educational contexts and objectives, as documented by [27]. Traditional data mining suffices for structured record analysis, while complex behavioral tasks require advanced neural or ensemble methods. Implementations must balance predictive accuracy, computational efficiency, and interpretability for stakeholder acceptance and ethical compliance.\n\nEmerging best practices emphasize context-aware model selection frameworks evaluating technical performance and educational utility. Future research should develop standardized benchmarking protocols accounting for academic success prediction’s multidimensional nature, including fairness considerations and robustness to evolving contexts. Educational technology is advancing towards hybrid intelligent systems integrating data mining, machine learning, and knowledge tracing to enhance applications, enabling personalized learning, improving predictions, and optimizing engagement through sophisticated student data analyses [23, 51, 16, 83, 62]."
    },
    {
      "heading": "5 Predictive Analytics in Higher Education Outcomes",
      "level": 1,
      "content": "Predictive analytics has become crucial in enhancing higher education outcomes, providing mechanisms for identifying and addressing academic challenges. The focus begins with early warning systems aimed at detecting at-risk students through sophisticated analytical techniques, enabling\n\n<html><body><table><tr><td>Feature</td><td>Decision Tree-Based Methods</td><td>Support Vector Machines</td><td>Neural Networks</td></tr><tr><td>Algorithmic Family</td><td>Hierarchical Structures</td><td>Margin Maximization</td><td>Sequential Patterns</td></tr><tr><td> Key Advantage</td><td>Interpretability</td><td>High Dimensional Handling</td><td>Complex Modeling</td></tr><tr><td>Suitability</td><td>Structured Prediction</td><td>Diverse Contexts</td><td>Temporal Prediction</td></tr></table></body></html>\n\nTable 4: This table provides a comparative analysis of three prominent machine learning methodologiesDecision Tree-Based Methods, Support Vector Machines, and Neural Networkshighlighting their algorithmic families, key advantages, and suitability for different predictive tasks in academic success prediction. It underscores the distinct benefits and application contexts of each method, offering a framework for selecting appropriate models based on specific educational objectives.\n\nproactive interventions that foster supportive learning environments. As institutions increasingly adopt these data-driven methodologies, predictive analytics not only improves student retention rates but also enhances overall institutional effectiveness by optimizing learning pathways and outcomes."
    },
    {
      "heading": "5.1 Early Warning Systems for At-Risk Students",
      "level": 1,
      "content": "Early warning systems utilize predictive analytics to identify students at risk by analyzing behavioral, cognitive, and performance patterns, thus facilitating timely interventions. These systems employ behavioral pattern recognition, cognitive process modeling, and statistical dimension identification. The Student Progression System uses statistical approaches with validated KPIs to identify at-risk students [38]. Behavioral analysis, particularly in online settings, identifies passive learners through interaction patterns, enabling motivational interventions [9]. Ensemble approaches enhance early identification by combining classifiers at different stages, improving prediction during critical phases [10]. The AMMKNN algorithm achieves high accuracy in health education [1], while the Click2State model refines predictions through time-series analysis [2].\n\nEffective implementation requires examining assessment methods, integrating educational data mining tailored to academic data, and developing structured approaches to leverage predictive and prescriptive analytics [68, 14, 3, 25, 26]. Aligning risk indicators with intervention windows enhances effectiveness, integrating prescriptive analytics for tailored feedback [14, 26]. Emerging directions emphasize multimodal integration, dynamic risk modeling, and explainable AI to build educator trust. These systems aim for proactive, data-driven student support, focusing on algorithmic fairness and scalability across diverse contexts [54, 56, 26, 14].\n\nFigure 5 illustrates the hierarchical structure of early warning systems for at-risk students, categorizing predictive analytics, implementation strategies, and emerging directions, while highlighting key methods and approaches in each area. This visual representation complements the discussion by providing a clear framework that encapsulates the various components and strategies involved in effectively supporting at-risk students.\n\n![](images/b7003ecb051f1ac198de8019eb1e52c8c4d0a1b19ff5b5bbca9abf3e63a64c93.jpg)  \nFigure 5: This figure illustrates the hierarchical structure of early warning systems for at-risk students, categorizing predictive analytics, implementation strategies, and emerging directions, highlighting key methods and approaches in each area."
    },
    {
      "heading": "5.2 Personalized Learning Recommendations",
      "level": 1,
      "content": "Personalized learning systems use machine learning to tailor educational experiences based on learner characteristics, patterns, and metrics. They operate through learning style identification, adaptive content delivery, and dynamic pathway optimization. Machine learning algorithms detect learning styles for customized instructional materials [84]. The FXAM framework models complex interactions while maintaining efficiency and interpretability [81]. Personalized data mining optimizes content sequencing, proving valuable in science education [43].\n\nEffective systems integrate diverse assessment methods, advanced data mining, and specific attributes to enhance prediction accuracy [25, 16, 26]. Multidimensional profiling enhances personalization by leveraging data mining to analyze performance and assessment methods [25, 57, 16, 26]. Real-time adaptation algorithms adjust to performance fluctuations, enhancing prediction accuracy [57, 26, 12]. Transparent frameworks empower educators to monitor performance and implement interventions [23, 69, 16, 56, 26].\n\nFairness-aware personalization strategies mitigate algorithmic bias, promoting inclusivity in educational environments [49, 59, 16, 46, 26]. Balancing technical aspects with ethical implications ensures equitable educational experiences."
    },
    {
      "heading": "5.3 Curriculum Optimization and Institutional Decision-Making",
      "level": 1,
      "content": "Predictive analytics informs curriculum design and policy formulation through learning pathway optimization, resource allocation, and adaptive policy frameworks. Distributed Bayesian modeling informs curriculum decisions with interpretability, achieving superior prediction accuracy [85]. The MOM method optimizes predictions in linear programming, reducing dataset dependence [86]. Analysis of binary link properties challenges conventional modeling assumptions, enhancing curriculum insights [87]. Descriptive analytics drive systemic reforms, transitioning to data-informed designs [3].\n\nApplications include tailored assessment strategies, machine learning for at-risk student identification, and advanced frameworks combining predictive and prescriptive insights [23, 14, 1, 26]. Graphbased modeling enhances prerequisite structure analysis, improving performance prediction [26, 83]. Time-series analysis optimizes course sequencing, enhancing design effectiveness [2, 26]. Clustering techniques identify competency gaps, improving academic assessments [24, 57, 65, 25, 26].\n\nResource allocation efficiency modeling optimizes educational resources, aligning distribution with assessment impacts to enhance intervention effectiveness [14, 18, 51, 56]. Implementing predictive analytics requires alignment with pedagogical objectives, interpretability for stakeholder acceptance, and ethical constraints in automation. Integrating computational techniques with pedagogical integrity ensures insights enhance expert judgment in curriculum design [17, 16, 26].\n\nEmerging directions include dynamic curriculum adaptation frameworks, integrated policy simulation environments, and fairness-aware optimization techniques to ensure equitable educational experiences [54, 16, 14, 46]. These advancements promise to transform curriculum development into continuous improvement processes grounded in empirical evidence."
    },
    {
      "heading": "5.4 Case Studies and Real-World Implementations",
      "level": 1,
      "content": "Real-world implementations of predictive analytics in higher education showcase the transformative potential of data-driven approaches. The political domain case study exemplifies a comprehensive framework applied to social data, offering transferable insights for educational settings [39]. The Kankor examination system in Afghanistan uses descriptive analytics for systemic improvement, analyzing extensive records to inform curriculum reforms [3]. This large-scale implementation addresses challenges in developing contexts, improving examination fairness and validity.\n\nIn health professions education, the AMMKNN algorithm achieves high accuracy in identifying at-risk students, demonstrating practical benefits in specialized domains [1]. The Unified Prediction Model integrates academic and employability predictions across diverse contexts, illustrating ensemble techniques’ scalability [6].\n\nCritical success factors include diverse assessment methods, explainable AI for interventions, student engagement in predicting outcomes, and comprehensive descriptive analytics [14, 54, 26, 3].\n\nThese case studies highlight the transition from theoretical models to operational systems, enhancing educational quality and institutional effectiveness. Future implementations will benefit from standardized evaluation protocols assessing technical performance and educational impact, maintaining focus on equitable outcomes across diverse populations."
    },
    {
      "heading": "6 Challenges and Limitations",
      "level": 1,
      "content": "Addressing the multifaceted nature of academic success prediction systems involves understanding the challenges surrounding model interpretability, transparency, and fairness. This section examines these critical aspects, emphasizing the importance of clear model outputs for stakeholder decisionmaking."
    },
    {
      "heading": "6.1 Model Interpretability and Transparency",
      "level": 1,
      "content": "Model interpretability is challenged by the trade-off between accuracy and explainability, reliance on high-quality data, and the need for domain-specific explanation frameworks [75, 70]. Complex models often function as black-boxes, hindering transparency and adoption in educational settings where decision-making impacts student outcomes. Approaches like the Click2State model and VarFA framework balance accuracy with transparency, offering interpretable insights through timeseries analysis and uncertainty quantification [2, 12]. Data quality is crucial; MOOC environments and comprehensive data collection methods like the Kankor exam case study highlight the need for reliable data to ensure model transparency [5, 3].\n\nEmerging methods enhance interpretability by integrating expert intuition through LLMs, combining machine learning with prescriptive analytics, and refining data preparation [23, 14, 4]. These strategies aim to leverage human expertise and advanced techniques for actionable insights [26]."
    },
    {
      "heading": "6.2 Bias and Fairness in Predictive Models",
      "level": 1,
      "content": "Bias and fairness in prediction models arise from data quality, model architecture, and implementation constraints. The Unified Prediction Model shows how data quality affects both accuracy and fairness, with incomplete datasets leading to skewed outcomes [6]. MOOC environments reveal challenges in fairness due to unstandardized datasets [35]. Data quality issues like class imbalance and demographic representation gaps undermine fairness, necessitating standardized evaluation protocols [26, 46].\n\nModel architecture decisions impact fairness through feature selection and weighting, with complex methods often lacking transparency [10, 51]. Implementation constraints such as limited model deployment access, proprietary model opacity, and data integrity issues exacerbate fairness concerns [49, 54]. Addressing these challenges requires balanced approaches prioritizing both performance and transparency."
    },
    {
      "heading": "6.3 Scalability and Computational Limitations",
      "level": 1,
      "content": "Scalability in prediction systems is constrained by computational resources, real-time processing demands, and distributed execution barriers. Optimized parallel execution strategies in distributed machine learning frameworks address these challenges, improving convergence and handling large datasets [8]. Real-time analytics, like the Click2State model, require efficient processing for timely interventions [2]. Implementations must balance complexity with infrastructure limitations, especially in resource-constrained settings [6].\n\nAs illustrated in Figure 6, the key challenges and future directions in scalability and computational limitations of distributed machine learning systems are highlighted. This figure emphasizes the challenges faced by distributed ML, the requirements for real-time analytics, and the focus areas for future research. Distributed machine learning faces challenges in program distribution, machine communication integration, and data exchange optimization [54, 39]. Memory constraints in highdimensional datasets necessitate strategies like LSTM models for accurate analysis [13, 51]. Future research should focus on adaptive model compression, hybrid cloud-edge architectures, and standardized benchmarking to enhance scalability and effectiveness in educational contexts [14, 26, 8].\n\n![](images/8e1c5baea982757dcc456bc95e58316850e9bee585ed0993f062b171c5a61b16.jpg)  \nFigure 6: This figure illustrates the key challenges and future directions in scalability and computational limitations of distributed machine learning systems, highlighting distributed ML challenges, real-time analytics requirements, and future research focus areas."
    },
    {
      "heading": "7 Future Directions",
      "level": 1,
      "content": "Exploring future directions in academic success prediction necessitates consideration of evolving educational technologies and methodologies. This section examines advancements in machine learning techniques that enhance predictive analytics in educational contexts, contributing to the development of more effective and adaptive systems for academic success prediction."
    },
    {
      "heading": "7.1 Advancements in Machine Learning Techniques",
      "level": 1,
      "content": "Future advancements in machine learning for academic success prediction will focus on enhanced knowledge tracing models, interpretable architectures, and adaptive learning frameworks. As illustrated in Figure 7, these advancements are categorized into three main areas: knowledge tracing models, interpretable architectures, and adaptive learning frameworks. Each category highlights key methodologies and approaches, such as deep knowledge tracing, generalized calibration, and AI integration, demonstrating the diverse strategies employed to enhance educational data mining and predictive analytics. Deep knowledge tracing, exemplified by the VarFA model, extends Bayesian inference while maintaining computational efficiency [12]. The HARVEST methodology optimizes feature selection through random subset configurations [47]. These approaches transform knowledge tracing into dynamic learning models.\n\nInterpretable architectures address model transparency challenges. Generalized calibration frameworks enhance model interpretability across prediction tasks [11]. Translating expert intuition into features requires empirical testing of encoding techniques [4]. These approaches must navigate big data challenges, including data quality and scalability [7].\n\nReinforcement learning (RL) in education presents untapped potential, especially when combined with geometric and topological data analysis [31]. Offline RL methods leveraging historical data could enable robust policy learning without real-time interaction. Time-series analysis of behavioral trajectories suggests promising directions for topic modeling correlating with student outcomes [2].\n\nAdaptive learning systems benefit from integrating AI and data mining for personalized education, developing advanced learning management systems, and applying explainable AI for tailored interventions [14, 23, 16, 56, 26].\n\nEmerging technical directions include advanced methodologies for educational data mining, incorporating various assessment methods to enhance predictability. Innovative predictive models analyze learning histories to predict STEM versus non-STEM field entry, emphasizing tailored data preparation and feature integration [62, 26]."
    },
    {
      "heading": "7.2 Multimodal Data Integration",
      "level": 1,
      "content": "Multimodal data integration in academic success prediction combines heterogeneous data streams for enhanced predictive accuracy and comprehensive learner profiles. This approach leverages behavioral interaction logs, affective state indicators, and cognitive engagement metrics. The Click2State model exemplifies effective multimodal integration by combining time-series analysis of clickstream data with textual mentor notes [2].\n\n![](images/e8e2cb7b60de9355a5dd4f7b89609c0cb87474958305d37761bb777d02c6fb92.jpg)  \nFigure 7: This figure illustrates the advancements in machine learning techniques for predicting academic success, categorizing them into knowledge tracing models, interpretable architectures, and adaptive learning frameworks. Each category highlights key methodologies and approaches, such as deep knowledge tracing, generalized calibration, and AI integration, demonstrating the diverse strategies employed to enhance educational data mining and predictive analytics.\n\nTextual data analysis is crucial in MOOC environments, where forum posts and assignments provide qualitative insights. The DialogID dataset establishes benchmarks for analyzing dialogic instruction patterns [53]. Translating expert intuition into quantifiable features enhances text analysis [4], navigating challenges of unstructured text processing.\n\nPhysiological and affective indicators enhance multimodal prediction systems by incorporating dimensions reflecting students’ emotional and physical states [14, 23, 21, 2, 26]. Eye-tracking data, galvanic skin response, and facial expression recognition contribute to understanding engagement and well-being [16, 26, 23, 54].\n\nThe Unified Prediction Model synthesizes attributes across behavioral, cognitive, and institutional data streams, capturing the multidimensional nature of learning processes [6]. MOOC communication pattern analysis reveals engagement dynamics through interaction logs and textual content analysis [5].\n\nTechnical challenges in multimodal integration include effective data preparation, large language model enhancement, explainable AI integration, and machine learning algorithm optimization [23, 14, 51, 26].\n\nFuture research emphasizes standardized multimodal datasets, adaptive fusion architectures, and explainable integration frameworks. These advancements promise to transform academic success prediction into holistic learning process modeling, addressing challenges in data interoperability and computational complexity. Multimodal integration techniques, combining behavioral data and content analysis, optimize personalized learning experiences [64, 16]."
    },
    {
      "heading": "7.3 Interdisciplinary Collaboration and Standardization",
      "level": 1,
      "content": "Advancing academic success prediction requires interdisciplinary collaboration and standardized frameworks across education, data science, and cognitive research. This involves methodological integration, shared frameworks, and standardized evaluation protocols. Interdisciplinary nature is exemplified by connecting physics methodologies with machine learning education [58].\n\nEffective collaboration reconciles qualitative pedagogical insights with quantitative analytical approaches. Mixed-methods research designs combining qualitative content analysis with quantitative metrics yield deeper understanding of learning processes [5]. Translating educational knowledge into computational features requires continuous dialogue between educators and data scientists.\n\nStandardized benchmarking addresses challenges in educational data mining predictions, improving student performance assessment and informed decision-making [68, 26, 3, 25, 1].\n\nMethodological inconsistencies arise from neglecting assessment methods, imbalanced features, and missing data, impacting prediction accuracy and fairness [26, 70, 46]. Data heterogeneity affects outcomes, necessitating tailored data preparation processes [54, 26, 57].\n\nAbsence of standardized metrics complicates comparison of algorithmic approaches, influencing evaluation of efficacy [57, 26].\n\nDeveloping standardized protocols enhances educational data preparation, integrating descriptive and prescriptive analytics for tailored support [68, 14, 23, 3, 26].\n\nKey domains for collaboration include educational data mining, expert insight conversion, exam analysis, large language model enhancement, and student feedback analysis [4, 79, 23, 3, 26].\n\nFuture trajectory emphasizes domain expertise integration throughout the analytics lifecycle, leveraging LLMs for feature conversion and prescriptive analytics for tailored recommendations [14, 75, 4]. Collaboration mechanisms, standardization efforts, and alignment with educational values enhance academic success prediction systems."
    },
    {
      "heading": "7.4 Emerging Technologies and Applications",
      "level": 1,
      "content": "Emerging technologies in academic success prediction include large language models (LLMs), virtual reality (VR) enhanced learning assessment, and blockchain-secured credential verification. LLMs transform qualitative data into predictive features, addressing challenges in MOOC environments and enhancing efficiency [4, 5, 12].\n\nVirtual learning environments capture nuanced processes, providing richer datasets for modeling [21]. Reinforcement learning develops adaptive policies responding to real-time interactions [22].\n\nBlockchain technologies enable secure credential verification, enhancing data credibility [62, 55, 26].   \nImmutable record-keeping ensures reliable documentation of performance [56, 26].\n\nHybrid architectures integrate emerging technologies with predictive analytics. The Unified Prediction Model combines educational data mining with employability forecasting [6], while distributed Bayesian methods enable scalable inference [85].\n\nKey considerations include assessment methods, data mining integration, descriptive analytics, and explainable AI for interventions [14, 26, 3].\n\nFuture research emphasizes neurosymbolic architectures, multimodal VR analytics, and decentralized identity frameworks. These advancements aim to revolutionize academic success prediction by creating interconnected learning ecosystems, addressing data sovereignty, transparency, and equitable access challenges [14, 54, 16, 56, 26]."
    },
    {
      "heading": "7.5 Future Research Priorities",
      "level": 1,
      "content": "Future research in academic success prediction should prioritize algorithmic fairness, scalable federated learning, transfer learning, model interpretability, and institutional implementation strategies. Multilayer federated learning requires optimal subgroup definitions and performance optimization [88].\n\nScalability research focuses on feature engineering, distributed learning, and knowledge distillation validation. Adaptive minimum match algorithms integrate with institutional systems, examining student perceptions of risk identification [1]. Guidelines for combined metric usage enhance interpretability [71].\n\nTransfer learning addresses data scarcity in specialized contexts, exploring proxy variable extensions and demographic data expansion [45, 21].\n\nInterpretability frameworks integrate assessment methodologies, transparent models, and prescriptive analytics for interventions [14, 75, 26].\n\nInstitutional implementation prioritizes tailored data preparation, predictive model accuracy, and module-level insights [14, 54, 3, 25, 26].\n\nPolicy frameworks ensure transparency, fairness, and diverse assessment methods for equitable outcomes [49, 14, 41, 26].\n\nThese research priorities address fundamental challenges by integrating innovative assessment methods and personalized strategies, aligning with core educational values such as engagement and tailored experiences [16, 26]."
    },
    {
      "heading": "8 Conclusion",
      "level": 1,
      "content": "This survey has delved into the intricate domain of academic success prediction, underscoring the pivotal role of educational data mining (EDM) and machine learning (ML) in transforming educational practices. The methodologies explored offer profound capabilities in identifying students at risk, refining learning paths through tailored recommendations, and guiding institutional strategies with data-informed insights. These advancements not only boost institutional efficiency but also cultivate environments conducive to student achievement. Recognizing these implications is vital for educators and policymakers aiming to harness these technologies effectively.\n\nThe survey highlights the nuanced efficacy of ML techniques across different educational contexts, with ensemble and hybrid models demonstrating significant potential in managing diverse academic datasets. The challenge of interpretability remains central, as clarity in model operations is crucial for fostering stakeholder trust and deriving actionable insights. This mirrors findings in clinical analytics, where understanding model limitations is essential for dependable application. Variational inference and generalized calibration methods have been identified as promising solutions to these interpretability challenges, ensuring both transparency and performance. Ethical considerations further demand that predictive models are comprehensible to all stakeholders, including students and educators, whose academic experiences are shaped by these technologies.\n\nSignificant barriers to implementation include addressing algorithmic bias, ensuring computational scalability, and navigating ethical complexities in data practices. The interdisciplinary nature of academic success prediction calls for ongoing collaboration among educators, data scientists, and policymakers to establish standardized evaluation criteria and fairness-aware models. Emerging technologies like large language models and multimodal data integration offer new avenues for enhancing accuracy but also pose challenges related to privacy and model validation. Balancing innovation with ethical responsibility is crucial to prevent privacy breaches and avoid reinforcing educational inequalities.\n\nFuture research should focus on three main areas: developing dynamic fairness assessment frameworks responsive to changing educational landscapes, advancing explainable AI tailored to educational decision-making, and creating robust validation protocols for new ML architectures in education. These efforts will drive the evolution of academic success prediction systems towards proactive educational paradigms, improving learning outcomes while aligning with essential educational values and institutional goals. As these systems advance, researchers must remain vigilant in evaluating their societal impacts, ensuring that predictive analytics in education are equitable and beneficial for all involved stakeholders."
    }
  ],
  "references": [
    "[1] Anshul Kumar, Taylor DiJohnson, Roger Edwards, and Lisa Walker. The application of adaptive minimum match k-nearest neighbors to identify at-risk students in health professions education, 2022.",
    "[2] Byungsoo Jeon, Eyal Shafran, Luke Breitfeller, Jason Levin, and Carolyn P. Rose. Time-series insights into the process of passing or failing online university courses using neural-induced interpretable student states, 2019.",
    "[3] Abdul Rahman Sherzad. Using descriptive analytics for the improvement of national university entrance exam: A case study in the context of kankor in afghanistan, 2016. [4] Phoebe Jing, Yijing Gao, Yuanhang Zhang, and Xianlong Zeng. Translating expert intuition into quantifiable features: Encode investigator domain knowledge via llm for enhanced predictive analytics, 2024.",
    "[5] Rebecca Eynon, Isis Hjorth, Taha Yasseri, and Nabeel Gillani. Understanding communication patterns in moocs: Combining data mining and qualitative methods, 2016.",
    "[6] Pooja Thakar, Anil Mehta, and Manisha. Unified prediction model for employability in indian higher education system, 2024.",
    "[7] Fatima El Jamiy, Abderrahmane Daif, Mohamed Azouazi, and Abdelaziz Marzak. The potential and challenges of big data - recommendation systems next level application, 2015.",
    "[8] Eric P. Xing, Qirong Ho, Pengtao Xie, and Wei Dai. Strategies and principles of distributed machine learning on big data, 2015.",
    "[9] I. P. Ratnapala, R. G. Ragel, and S. Deegalla. Students behavioural analysis in an online learning environment using data mining (iciafs), 2014.",
    "[10] MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, and Abdallah Shami. Systematic ensemble model selection approach for educational data mining, 2020.",
    "[11] Bavo De Cock Campo. Towards reliable predictive analytics: a generalized calibration framework, 2023.",
    "[12] Zichao Wang, Yi Gu, Andrew Lan, and Richard Baraniuk. Varfa: A variational factor analysis framework for efficient bayesian learning analytics, 2020.",
    "[13] Chun Wang, Jiexiao Chen, Ziyang Xie, and Jianke Zou. Research on education big data for students academic performance analysis based on machine learning, 2024.",
    "[14] Teo Susnjak. A prescriptive learning analytics framework: Beyond predictive modelling and onto explainable ai with prescriptive analytics and chatgpt, 2023.",
    "[15] Vahid Ashrafimoghari. Big data and education: using big data analytics in language learning, 2022.",
    "[16] Zhang Xiong, Haoxuan Li, Zhuang Liu, Zhuofan Chen, Hao Zhou, Wenge Rong, and Yuanxin Ouyang. A review of data mining in personalized education: Current trends and future prospects, 2024.",
    "[17] C. Romero and S. Ventura. Educational data mining and learning analytics: An updated survey, 2024.",
    "[18] Pooja Thakar, Anil Mehta, and Manisha. Performance analysis and prediction in educational data mining: A research travelogue, 2021.",
    "[19] Vitor Cerqueira, Luis Torgo, and Carlos Soares. Model selection for time series forecasting: Empirical analysis of different estimators, 2022.",
    "[20] Paula Branco, Luis Torgo, and Rita Ribeiro. A survey of predictive modelling under imbalanced distributions, 2015.",
    "[21] Eid Aldikanji and Khalil Ajami. Studying academic indicators within virtual learning environment using educational data mining, 2016.",
    "[22] Adish Singla, Anna N. Rafferty, Goran Radanovic, and Neil T. Heffernan. Reinforcement learning for education: Opportunities and challenges, 2021.",
    "[23] Shiqi Liu, Sannyuya Liu, Lele Sha, Zijie Zeng, Dragan Gasevic, and Zhi Liu. Annotation guidelines-based knowledge augmentation: Towards enhancing large language models for educational text classification, 2024.",
    "[24] Wilhelmiina Hämäläinen, Mike Joy, Florian Berger, and Sami Huttunen. Clustering students’ open-ended questionnaire answers, 2018.",
    "[25] Mohammed A. Alsuwaiket, Anas H. Blasi, and Khawla Altarawneh. Refining student marks based on enrolled modules assessment methods using data mining techniques, 2020.",
    "[26] Mohammed Alsuwaiket, Anas H. Blasi, and Ra’Fat Al-Msie’deen. Formulating module assessment for improved academic performance predictability in higher education, 2020.",
    "[27] Umesh Kumar Pandey, Brijesh Kumar Bhardwaj, and Saurabh pal. Data mining as a torch bearer in education sector, 2012.",
    "[28] Charlotte Van Petegem, Rien Maertens, Niko Strijbol, Jorg Van Renterghem, Felix Van der Jeugt, Bram De Wever, Peter Dawyndt, and Bart Mesuere. Dodona: learn to code with a virtual co-teacher that supports active learning, 2022.",
    "[29] Ramineh Lopez-Yazdani and Roberto Rivera. Improving on-time undergraduate graduation rate for undergraduate students using predictive analytics, 2024.",
    "[30] Thomas Hartmann, Francois Fouquet, Assaad Moawad, Romain Rouvoy, and Yves Le Traon. Greycat: Efficient what-if analytics for data in motion at scale, 2018.",
    "[31] Fionn Murtagh. The geometry and topology of data and information for analytics of processes and behaviours: Building on bourdieu and addressing new societal challenges, 2017.",
    "[32] Yuanguo Lin, Hong Chen, Wei Xia, Fan Lin, Zongyue Wang, and Yong Liu. A comprehensive survey on deep learning techniques in educational data mining, 2024.",
    "[33] Brijesh Kumar Bhardwaj and Saurabh Pal. Data mining: A prediction for performance improvement using classification, 2012.",
    "[34] Prof Rudresh Shirwaikar and Nikhil Rajadhyax. Data mining on educational domain, 2012.",
    "[35] Manikandan Ravikiran. What’s happened in mooc posts analysis, knowledge tracing and peer feedbacks? a review, 2020.",
    "[36] Surjeet Kumar Yadav and Saurabh Pal. Data mining: A prediction for performance improvement of engineering students using classification, 2012.",
    "[37] Paulo J. L. Adeodato, Fábio C. Pereira, and Rosalvo F. Oliveira Neto. Optimal categorical attribute transformation for granularity change in relational databases for binary decision problems in educational data mining, 2017.",
    "[38] Harkiran Kaur and Aanchal Phutela. Statistical dimension identification and implementation for student progression system, 2018.",
    "[39] Bilal Abu-Salih, Pornpit Wongthongtham, Dengya Zhu, Kit Yan Chan, and Amit Rudra. Predictive analytics using social big data and machine learning, 2021.",
    "[40] Linqing Li and Zhifeng Wang. Knowledge relation rank enhanced heterogeneous learning interaction modeling for neural graph forgetting knowledge tracing, 2023.",
    "[41] Renzhe Yu, Hansol Lee, and René F. Kizilcec. Should college dropout prediction models include protected attributes?, 2021.",
    "[42] Mohammad Khajah, Robert V. Lindsey, and Michael C. Mozer. How deep is knowledge tracing?, 2016.",
    "[43] Renato P. dos Santos. Big data as a mediator in science teaching: A proposal, 2014.",
    "[44] Weijian Chen, Fuli Feng, Qifan Wang, Xiangnan He, Chonggang Song, Guohui Ling, and Yongdong Zhang. Catgcn: Graph convolutional networks with categorical node features, 2022.",
    "[45] Hamsa Bastani. Predicting with proxies: Transfer learning in high dimension, 2020.",
    "[46] Hadis Anahideh, Parian Haghighat, Nazanin Nezami, and Denisa G‘andara. Auditing the imputation effect on fairness of predictive analytics in higher education, 2022.",
    "[47] Herbert Weisberg, Victor Pontes, and Mathis Thoma. Testing for feature relevance: The harvest algorithm, 2018.",
    "[48] Ali Jaber Almalki. Accuracy analysis of educational data mining using feature selection algorithm, 2021.",
    "[49] Parian Haghighat, Denisa G’andara, Lulu Kang, and Hadis Anahideh. Fair multivariate adaptive regression splines for ensuring equity and transparency, 2024.",
    "[50] Conrad Borchers. Toward sufficient statistical power in algorithmic bias assessment: A test for abroca, 2025.",
    "[51] MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, and Abdallah Shami. Multisplit optimized bagging ensemble model selection for multi-class educational data mining, 2020.",
    "[52] Yawen Chen, Jiande Sun, Jinhui Wang, Liang Zhao, Xinmin Song, and Linbo Zhai. Machine learning-driven student performance prediction for enhancing tiered instruction, 2025.",
    "[53] Jiahao Chen, Shuyan Huang, Zitao Liu, and Weiqi Luo. Dialogid: A dialogic instruction dataset for improving teaching effectiveness in online environments, 2022.",
    "[54] Robert D. Macredie, Martin Shepperd, Tommaso Turchi, and Terry Young. Exploring student engagement and outcomes: Experiences from three cycles of an undergraduate module, 2022.",
    "[55] Mohammed Alsuwaiket, Christian Dawson, and Firat Batmaz. Measuring the credibility of student attendance data in higher education for data mining, 2020.",
    "[56] Xinyu Zhang, Vincent CS Lee, Duo Xu, Jun Chen, and Mohammad S. Obaidat. An effective learning management system for revealing student performance attributes, 2024.",
    "[57] Tanya Nazaretsky, Sara Hershkovitz, and Giora Alexandron. Kappa learning: A new method for measuring similarity between educational items using performance data, 2018.",
    "[58] Gabriele Benelli, Thomas Y. Chen, Javier Duarte, Matthew Feickert, Matthew Graham, Lindsey Gray, Dan Hackett, Phil Harris, Shih-Chieh Hsu, Gregor Kasieczka, Elham E. Khoda, Matthias Komm, Mia Liu, Mark S. Neubauer, Scarlet Norberg, Alexx Perloff, Marcel Rieger, Claire Savard, Kazuhiro Terao, Savannah Thais, Avik Roy, Jean-Roch Vlimant, and Grigorios Chachamis. Data science and machine learning in education, 2022.",
    "[59] Tai Le Quy, Thi Huyen Nguyen, Gunnar Friege, and Eirini Ntoutsi. Evaluation of group fairness measures in student performance prediction problems, 2022.",
    "[60] Wei Qian, Aobo Chen, Chenxu Zhao, Yangyi Li, and Mengdi Huai. Exploring fairness in educational data mining in the context of the right to be forgotten, 2024.",
    "[61] Ren Chao and Yang Menghui. Information flow simulation community detection of weighteddirected campus friendship network in continuous time, 2023.",
    "[62] Chun kit Yeung, Zizheng Lin, Kai Yang, and Dit yan Yeung. Incorporating features learned by an enhanced deep knowledge tracing model for stem/non-stem job prediction, 2018.",
    "[63] Yohan Jo, Gaurav Tomar, Oliver Ferschke, Carolyn P. Rose, and Dragan Gasevic. Expediting support for social learning with behavior modeling, 2016.",
    "[64] Yuwei Tu, Weiyu Chen, and Christopher G. Brinton. A deep learning approach to behaviorbased learner modeling, 2020.",
    "[65] Pooja Thakar, Anil Mehta, and Manisha. Cluster model for parsimonious selection of variables and enhancing students employability prediction, 2024.",
    "[66] Francisco Esquembre, Félix J. García Clemente, Rafael Chicón, Lawrence Wee, Leong Tze Kwang, and Darren Tan. Easy java/javascript simulations as a tool for learning analytics, 2019.",
    "[67] Hoang Thanh Lam, Johann-Michael Thiebaut, Mathieu Sinn, Bei Chen, Tiep Mai, and Oznur Alkan. One button machine for automating feature engineering in relational databases, 2017.",
    "[68] Abdul Rahman Sherzad. Applicability of educational data mining in afghanistan: Opportunities and challenges, 2017.",
    "[69] Ms. Ganesan Kavitha and Dr. Lawrance Raj. Educational data mining and learning analytics - educational assistance for teaching and learning, 2017.",
    "[70] Nicholas T. Young and Marcos D. Caballero. Predictive and explanatory models might miss informative features in educational data, 2021.",
    "[71] Ryan S. Baker, Nigel Bosch, Stephen Hutt, Andres F. Zambrano, and Alex J. Bowers. On fixing the right problems in predictive analytics: Auc is not the problem, 2024.",
    "[72] Xiao Han, Leye Wang, Junjie Wu, and Xiao Fang. Data valuation for vertical federated learning: A model-free and privacy-preserving method, 2024.",
    "[73] Josh Gardner, Yuming Yang, Ryan Baker, and Christopher Brooks. Enabling end-to-end machine learning replicability: A case study in educational data mining, 2018.",
    "[74] Yunwen Xu, Rui Xu, Weizhong Yan, and Paul Ardis. Concept drift learning with alternating learners, 2017.",
    "[75] Renuka Sindhgatta, Chun Ouyang, and Catarina Moreira. Exploring interpretability for predictive process analytics, 2020.",
    "[76] Sukrit Leelaluk, Cheng Tang, Valdemar vábenský, and Atsushi Shimada. Knowledge distillation in rnn-attention models for early prediction of student performance, 2024.",
    "[77] Tong Chen, Hongzhi Yin, Xiangliang Zhang, Zi Huang, Yang Wang, and Meng Wang. Quaternion factorization machines: A lightweight solution to intricate feature interaction modelling, 2021.",
    "[78] Yuxiang Qiu, Karim Djemili, Denis Elezi, Aaneel Shalman, María Pérez-Ortiz, Emine Yilmaz, John Shawe-Taylor, and Sahan Bulathwela. A toolbox for modelling engagement with educational videos, 2023.",
    "[79] Anna Koufakou. Deep learning for opinion mining and topic classification of course reviews, 2023.",
    "[80] Sadiq Hussain and G. C. Hazarika. Educational data mining using jmp, 2014.",
    "[81] Yuanyuan Jiang, Rui Ding, Tianchi Qiao, Yunan Zhu, Shi Han, and Dongmei Zhang. A unified and fast interpretable model for predictive analytics, 2023.",
    "[82] Xiangnan He and Tat-Seng Chua. Neural factorization machines for sparse predictive analytics, 2017.",
    "[83] Haotian Zhang, Chenyang Bu, Fei Liu, Shuochen Liu, Yuhong Zhang, and Xuegang Hu. Apgkt: Exploiting associative path on skills graph for knowledge tracing, 2022.",
    "[84] Hani Y. Ayyoub and Omar S. Al-Kadi. Learning style identification using semi-supervised self-taught labeling, 2024.",
    "[85] Masato Asahara and Ryohei Fujimaki. Distributed bayesian piecewise sparse linear models, 2017.",
    "[86] Chunlin Sun, Shang Liu, and Xiaocheng Li. Maximum optimality margin: A unified approach for contextual linear programming and inverse linear programming, 2023.",
    "[87] Necla Gunduz and Ernest Fokoue. On the predictive properties of binary link functions, 2015.",
    "[88] Yun-Wei Chu, Seyyedali Hosseinalipour, Elizabeth Tenorio, Laura Cruz, Kerrie Douglas, Andrew Lan, and Christopher Brinton. Multi-layer personalized federated learning for mitigating biases in student predictive analytics, 2024."
  ]
}