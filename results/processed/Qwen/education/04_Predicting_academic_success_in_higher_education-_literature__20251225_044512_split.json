{
  "outline": [
    [
      1,
      "Literature Review: Predicting academic success in higher education- literature review and best practices."
    ],
    [
      2,
      "The Evolving Concept of Academic Success and the Imperative for Equity"
    ],
    [
      2,
      "Historical Trajectories and Foundational Theories of Student Success Prediction"
    ],
    [
      2,
      "State-of-the-Art Methodologies and Models in Predictive Analytics"
    ],
    [
      2,
      "Key Determinants of Academic Success: A Multi-Dimensional Analysis"
    ],
    [
      2,
      "Applications, Case Studies, and Practical Implications"
    ],
    [
      2,
      "Critical Challenges, Ethical Concerns, and Future Directions"
    ],
    [
      1,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "Literature Review: Predicting academic success in higher education- literature review and best practices.",
      "level": 1,
      "content": "*Generated on: 2025-12-25 04:45:12*\n*Topic Index: 4/10*\n\n---\n\nThis research aims to systematically review the literature on predicting academic success in higher education, covering key concepts, historical developments, current methods, applications, challenges, and future directions. The review will synthesize best practices from existing studies, critically analyze methodological strengths and weaknesses, and identify gaps in the field. It focuses broadly on higher education contexts without restriction to specific student populations or institutional types, incorporating both quantitative and qualitative approaches as reported in the literature.# Predicting Academic Success in Higher Education: A Systematic Literature Review",
      "stats": {
        "char_count": 738,
        "word_count": 93,
        "sentence_count": 4,
        "line_count": 6
      }
    },
    {
      "heading": "The Evolving Concept of Academic Success and the Imperative for Equity",
      "level": 2,
      "content": "The pursuit of academic success in higher education has historically been anchored in a narrow set of metrics, primarily reflecting institutional priorities and resource allocation. For decades, this concept was dominated by measures such as grade point average (GPA), course completion rates, and graduation timelines [[9,16]]. While these indicators provide a quantitative snapshot of student performance within a specific academic context, they often fail to capture the full spectrum of learning, development, and long-term achievement that institutions aim to foster. This traditional view is increasingly being challenged as researchers and policymakers recognize its limitations in promoting holistic student development and addressing systemic inequities. The contemporary understanding of academic success is therefore undergoing a profound transformation, shifting from a singular focus on retention and grades to a more comprehensive framework that incorporates equity, belonging, and multidimensional well-being.\n\nA critical driver of this evolution is the growing awareness that traditional test-based accountability policies have reached a plateau, with national assessments showing minimal improvement or even decline over the past decade [[1]]. The COVID-19 pandemic exacerbated these challenges, leading to significant disruptions in student learning that further highlighted the inadequacy of relying solely on standardized metrics [[1]]. In response, there is a concerted push towards developing more holistic student success indicators that can provide a richer, more equitable picture of educational outcomes [[1]]. This movement is not merely about expanding the list of metrics but fundamentally redefining what it means to succeed in higher education. It acknowledges that true success encompasses not only cognitive achievement but also non-cognitive skills, personal growth, and a sense of belonging within the academic community. Frameworks like the Holistic Student Development Measurement Scale (HSDMS) reflect this shift, incorporating dimensions such as Physical Quotient, Emotional Intelligence Quotient, Social Intelligence Quotient, and Spiritual Intelligence Quotient alongside traditional IQ and academic performance [[11]].\n\nAt the forefront of this paradigm shift is the imperative to embed equity at the core of all definitions of academic success. The National Academies of Sciences, Engineering, and Medicine (NASEM) has been instrumental in shaping this discourse through reports like *Indicators for Monitoring Undergraduate STEM Education* [[13]]. This work proposes eight measurable indicators designed to assess equity in STEM programs, moving beyond aggregate statistics to disaggregate data by race, ethnicity, gender, socioeconomic status, and other identities [[6,13]]. These indicators include tracking the diversity of enrollees compared to non-STEM fields, analyzing the persistence and credential completion rates of underrepresented groups, and evaluating students' sense of belonging and access to high-impact educational experiences [[6]]. By mandating intersectional analysis, these frameworks ensure that progress is measured for all students, not just the majority. This approach directly confronts the reality that student outcomes are becoming less equitable, a trend that traditional accountability systems have failed to reverse [[1]].\n\nThis emphasis on equity manifests in various ways across different disciplines and institutional contexts. For instance, studies show that faculty teaching practices differ significantly between STEM and non-STEM fields, which can impact student success differently [[5]]. Research at a public comprehensive university found that while both STEM and non-STEM instructors were guided by mastery goals, non-STEM instructors reported a stronger belief in their students' efficacy and used evidence-based teaching practices more frequently [[12]]. Such differences suggest that discipline-specific cultures and pedagogical approaches must be considered when designing interventions to support student success. Similarly, in the context of international higher education, foundation year programs in the UAE were found to produce business students whose academic performance was comparable to their peers without such preparation, demonstrating that targeted preparatory initiatives can successfully level the playing field [[27]]. The ultimate goal of this evolved definition is to create an educational system where success is not determined by a student's background but by their potential, supported by an environment that fosters diversity, inclusion, and a sense of belonging for all [[6]].",
      "stats": {
        "char_count": 4692,
        "word_count": 634,
        "sentence_count": 23,
        "line_count": 7
      }
    },
    {
      "heading": "Historical Trajectories and Foundational Theories of Student Success Prediction",
      "level": 2,
      "content": "The history of predicting academic success in higher education is a narrative of increasing complexity and sophistication, mirroring broader shifts in technology, data availability, and theoretical understanding. The journey began with simple, univariate analyses that sought to link a single predictor variable to an outcome. Early research focused on identifying straightforward correlations, such as the relationship between high school GPA and one-year retention rates [[3]]. These initial efforts laid the groundwork for a more systematic approach to understanding student attrition and success. As computing power became more accessible, the field advanced to multiple regression models. Institutions began using logistic regression to build \"student profiles\" or \"personas,\" integrating numerous independent variables—ranging from demographic information to prior academic records—to identify students at risk of not persisting [[3]]. This marked a significant step forward, acknowledging that student success is rarely attributable to a single factor but rather emerges from the interplay of many.\n\nThis period was heavily influenced by foundational theories of student departure and persistence. Scholars like Tinto, Bean, and Astin developed influential models that conceptualized student success as a process of social and academic integration [[22,27]]. Tinto’s Institutional Departure Theory, for example, posits that student attrition is a function of the degree of integration into the academic and social communities of the institution [[27]]. Similarly, Bean’s model of student attrition highlights internal student characteristics and external environmental factors that lead to withdrawal [[22]]. These theories provided a robust conceptual foundation for the early statistical models, guiding researchers to include variables related to student involvement, campus climate, and academic engagement. However, a systematic review revealed a growing disconnect between these established theories and modern empirical research; recent studies often employ context-specific frameworks centered on technology and digital tools, rarely referencing the rich theoretical heritage that preceded them [[22]]. This suggests a field that has become more applied and technology-driven, sometimes at the expense of deep theoretical grounding.\n\nThe most transformative period in the history of prediction has been the last two decades, driven by two parallel revolutions: advancements in machine learning and exponential increases in computational power and data connectivity [[3]]. This convergence has enabled a paradigm shift from correlational modeling to predictive analytics capable of uncovering complex, non-linear relationships. Neural networks and other machine learning algorithms can autonomously detect intricate patterns in vast datasets, revealing insights that would be impossible to discern through traditional statistical methods [[3]]. For instance, these advanced models have uncovered paradoxical findings, such as how student loans can positively affect retention for certain subgroups of students while negatively impacting others—a nuance lost in simpler models [[3]]. This new era prioritizes real-time, individualized predictions by leveraging data from diverse sources, including Student Information Systems (SIS), Learning Management Systems (LMS), marketing platforms, and event logs [[3]]. Consequently, the focus has shifted from lagging indicators like past GPA to leading indicators derived from co-curricular engagement and real-time behavioral data, allowing for the implementation of timely and targeted interventions [[3]]. This historical progression illustrates a clear trajectory from simple correlations to sophisticated, multi-faceted predictive systems that form the backbone of modern student success initiatives.",
      "stats": {
        "char_count": 3861,
        "word_count": 513,
        "sentence_count": 21,
        "line_count": 5
      }
    },
    {
      "heading": "State-of-the-Art Methodologies and Models in Predictive Analytics",
      "level": 2,
      "content": "The current state-of-the-art in predicting academic success is characterized by a dynamic and rapidly evolving landscape of methodologies, with a clear consensus emerging around the superiority of ensemble and hybrid machine learning models over single, standalone algorithms. While foundational models like Logistic Regression (LR) and Support Vector Machines (SVM) still find use, particularly in smaller-scale or exploratory studies, they consistently underperform when compared to more advanced techniques [[16,18]]. The literature points to Random Forest (RF), XGBoost, and various forms of neural networks as the dominant architectures driving predictive accuracy today. A study at Complutense University of Madrid, for instance, found that RF achieved an R² value of 0.22 for predicting first-year grades, outperforming SVR and LR, with XGBoost providing competitive results [[16]]. This pattern holds across multiple domains; in one study, RF correctly classified 99.26% of student outcomes, far surpassing Naive Bayes (95.68%) [[18]], while another study on a medical dataset found that an RF-based interval belief rule base (IBRB-C) model demonstrated superior performance over RF, BPNN, KNN, and LSTM [[20]].\n\nThe primary reason for the dominance of ensemble methods lies in their ability to mitigate the weaknesses of individual models and leverage their collective strengths. Ensemble models like Bagging and Boosting combine the predictions of multiple \"weak learners\" to produce a single, more robust and accurate output. A study at Damietta University exemplified this, where a Bagging ensemble model achieved 100% accuracy in predicting student grades, an unprecedented result that underscores the power of this approach [[18]]. Another study proposed a multi-model fusion framework for classifying student performance in Data Structures, suggesting a voting system to select the optimal model for a given task, thereby enhancing generalization [[19]]. The effectiveness of ensembling is also evident in the realm of deep learning, where combining Convolutional Neural Networks (CNNs) with meta-learners like XGBoost has proven highly successful. A hybrid model at Wollo University, for example, combined CNNs with RF and XGBoost to predict academic success with 88% accuracy, outperforming any of its constituent parts [[15]]. This demonstrates a clear trend towards creating sophisticated hybrid architectures that can capture complex feature interactions that simpler models cannot.\n\nDeep learning, particularly the use of image-based transformations of tabular data, represents one of the most innovative frontiers in the field. The EnCF model, introduced by Zhao et al. (2025), exemplifies this cutting-edge approach. By transforming numerical features from a transformed data matrix into high-dimensional image formats like Recurrence Plots (RP), Gramian Angular Fields (GAF), and Markov Transition Fields (MTF), the model enables the use of powerful 2D CNNs to analyze the resulting images [[4]]. This technique allows the model to learn spatial hierarchies and complex patterns within the data. The EnCF model, when trained on the Open University Learning Analytics Dataset (OULAD), achieved a remarkable accuracy of 0.9528, precision of 0.9529, recall of 0.9528, and F1-score of 0.9528, highlighting the immense potential of this novel methodology [[4]]. Furthermore, the importance of feature selection cannot be overstated. Advanced techniques like DE-FS integrate multiple feature selection methods with adaptive thresholding to enhance model performance, achieving 95.8% accuracy on a math dataset by selecting just 12 features [[17]]. This focus on refining the input data is proving to be as crucial as the choice of the prediction algorithm itself.\n\n| Model Type | Representative Example(s) | Reported Performance Metric | Source |\n| :--- | :--- | :--- | :--- |\n| **Ensemble Methods** | Bagging (Damietta University) | 100% Accuracy | `[[18]]` |\n| | Random Forest (Complutense U.) | R² = 0.22 (First-Year Grade) | `[[16]]` |\n| | Hybrid CNN + RF + XGBoost (Wollo University) | 88% Accuracy | `[[15]]` |\n| **Neural Networks / Deep Learning** | IBRB-C (Zhou et al., 2025) | MSE = 0.1014 (GPA Prediction) | `[[20]]` |\n| | Image-based CNN (Zhao et al., 2025) | Accuracy = 0.9528 | `[[4]]` |\n| **Traditional Machine Learning** | Support Vector Machine (Damietta University) | 79.3% Accuracy | `[[18]]` |\n| | Lasso Regression (Data Structures Course) | Lower error than Linear/Ridge/Decision Tree | `[[19]]` |",
      "stats": {
        "char_count": 4535,
        "word_count": 675,
        "sentence_count": 37,
        "line_count": 15
      }
    },
    {
      "heading": "Key Determinants of Academic Success: A Multi-Dimensional Analysis",
      "level": 2,
      "content": "Predicting academic success requires a nuanced understanding of the multifaceted determinants that influence a student's journey. Research consistently demonstrates that success is not dictated by a single factor but emerges from a complex interplay of cognitive abilities, non-cognitive skills, motivational drivers, and socio-environmental conditions. A comprehensive analysis reveals that the most powerful predictors span these diverse domains, necessitating a holistic approach to assessment and intervention. The strongest predictors identified in recent longitudinal studies are domain-specific knowledge from prior studies and learning motivation, with path coefficients of β = .293 and β = .337 respectively, explaining nearly a fifth of the variance in academic success over five years [[9]]. However, the most stable predictor across that same study was the use of effective learning strategies, underscoring the importance of metacognitive skills [[9]].\n\nNon-academic and non-cognitive factors play a surprisingly large role. A cross-sectional study at Mazandaran University of Medical Sciences identified several key non-academic factors influencing academic success, including motivation (r = 0.17), reading skills (r = 0.21), time management (r = 0.11), and financial management (r = 0.11) [[2]]. Meta-analytic evidence reinforces this, showing that promoting factors like positive emotion (R = 0.751), teacher-student relationship (R = 0.456), and positive teacher behavior (R = 0.419) have a strong, statistically significant correlation with student learning participation [[7]]. Conversely, hindering factors like negative teacher behavior (R = -0.064) and negative learning behaviors (R = -0.145) are also significant [[7]]. A study in Kazakhstan further refined this understanding by examining 26 non-cognitive skills, finding that eight had a direct positive impact on achievement in subjects like Math and Physics, while twelve had an indirect effect mediated through other skills [[14]]. This indicates that the influence of non-cognitive skills is not uniform but is subject-specific.\n\nMotivation and engagement are recurrent themes in the literature. A meta-analysis by Dicke and colleagues found that interest congruence—the alignment between a student's vocational interests and their chosen program—is a small but positive predictor of academic achievement, persistence, and satisfaction [[21]]. The effect is larger when measured with a full vocational profile rather than single dimensions, suggesting that a holistic understanding of student interests is key [[21]]. Beyond broad motivation, specific psychological constructs are crucial. For example, psychological ownership, which arises from student involvement, has been identified as a vital link between empowerment and both academic and experiential outcomes [[10]]. Cognitive styles also appear to be relevant, with a meta-analysis of 42 studies finding a significant positive correlation between field independence (the ability to separate a figure from its ground) and academic achievement, particularly in STEM-related subjects [[23]]. This suggests that inherent cognitive processing styles may predispose some students to excel in certain fields.\n\nFinally, contextual factors—including socio-economic background, institutional culture, and disciplinary norms—are inextricably linked to academic success. Socio-economic status, measured by parental education, was found to be a significant factor in one study [[16]], while another found it was not a significant predictor at the university level, potentially due to controlling for other variables [[9]]. This discrepancy highlights the importance of context. Institutional culture also plays a major role. Faculty teaching practices vary significantly between STEM and non-STEM fields, with non-STEM instructors reporting greater use of evidence-based practices and higher belief in student efficacy [[12]]. This disciplinary divide can shape the learning environment and, consequently, student outcomes. Furthermore, a student's geographic origin and family background can have a tangible impact, as seen in a Spanish university where a majority of students came from Madrid and had parents with higher education qualifications, factors that correlated with performance [[16]]. Collectively, these findings paint a picture of academic success as a product of a dynamic system where individual traits interact with the immediate learning environment and broader societal structures.",
      "stats": {
        "char_count": 4528,
        "word_count": 619,
        "sentence_count": 37,
        "line_count": 7
      }
    },
    {
      "heading": "Applications, Case Studies, and Practical Implications",
      "level": 2,
      "content": "The theoretical advancements in predicting academic success are being translated into practical applications that are reshaping student support services and institutional strategy. The primary application of these predictive models is the development of Early Warning Systems (EWS), which serve as proactive tools to identify at-risk students before they fall too far behind. By analyzing real-time data on student engagement and performance, EWS can trigger timely interventions, such as personalized coaching, tutoring referrals, or advising sessions. A longitudinal study at a Hungarian university found that early academic performance in the first semester and year was a strong predictor of long-term outcomes, providing a solid rationale for using early data to inform EWS [[16]]. Similarly, research has shown that specific instructional pillars, like Activating Student Teams, have a strong positive correlation with learning rates, offering actionable insights for faculty to improve classroom practices [[8]]. The goal is to move from a reactive model of remediation to a proactive, supportive ecosystem that fosters student persistence and achievement.\n\nSeveral case studies illustrate the successful deployment of these technologies in diverse institutional settings. At Complutense University of Madrid, a massive open-access university, machine learning models were used to predict first-year and first-semester grades based on administrative data [[16]]. The models, particularly Random Forest, identified key predictors like Access Grade and admission option preference, enabling the university to better understand factors influencing student success and allocate resources more effectively [[16]]. In a different context, a private higher education institution in the UAE conducted a study comparing Foundation Year (FY) and Non-Foundation Year (NFY) students. While no statistically significant difference in performance was found, the study highlighted the importance of English proficiency and LMS quality as key contextual factors, demonstrating how predictive modeling can uncover subtle but critical variables in specific institutional frameworks [[27]].\n\nThe table below presents a summary of key case studies, showcasing the variety of contexts, data types, and predictive models being employed.\n\n| Institution/Context | Data Source | Predictive Task | Key Findings & Models Used | Source |\n| :--- | :--- | :--- | :--- | :--- |\n| **Wollo University & Kombolcha Institute of Technology, Ethiopia** | 24,005 student records (2017–2022) | Predict academic success (Pass/Fail) | Hybrid model combining CNN, RF, and XGBoost achieved 88% accuracy. Studied credits and entrance exam results were key features. | `[[15]]` |\n| **Damietta University, Egypt** | 461 student records (2016–2021) | Predict final grade for a single medical course | Ensemble methods like Bagging (100% accuracy) and Random Forest (99.26%) outperformed individual classifiers. | `[[18]]` |\n| **Complutense University of Madrid, Spain** | 8,700 first-year student records (2022–2023) | Predict first-year/semester average grades | Random Forest (RF) performed best (R²=0.22). Key predictors included Access Grade, gender, and number of ECTS credits enrolled. | `[[16]]` |\n| **Mazandaran University of Medical Sciences, Iran** | 595 student survey responses | Identify factors influencing academic success index | Identified non-academic factors like motivation (r=0.17), reading skills (r=0.21), and time management (r=0.11) as significant predictors. | `[[2]]` |\n| **Kazakhstan STEM Secondary School** | 395 student and teacher survey responses | Predict academic achievement in Math, CS, Physics, Chemistry | Eight non-cognitive skills had direct positive impacts, and twelve had indirect impacts. Effectiveness was subject-specific. | `[[14]]` |\n| **Open University (UK)** | Open University Learning Analytics Dataset (OULAD) | Predict pass/fail outcomes | EnCF model (fusing CNNs and FCNs with image-transformed data) achieved 95.28% accuracy, setting a new benchmark for performance. | `[[4]]` |\n\nThese case studies reveal common threads. First, hybrid and ensemble models consistently demonstrate superior performance, confirming the trend observed in the broader methodological review [[15,18]]. Second, the most predictive features often relate to prior achievement (e.g., Access Grade, entrance exams) and basic demographics, though contextual factors like credit load are also important [[15,16]]. Third, the application of these models provides tangible benefits, such as enabling targeted educational interventions and supporting more strategic resource allocation [[15]]. However, the practical implications extend beyond mere prediction. The insights gained from these models can inform curriculum design, faculty training, and policy decisions aimed at improving the overall student experience. For example, if a model identifies a lack of collaboration as a hindering factor, the institution can invest in team-based learning activities. Ultimately, the successful application of predictive analytics hinges on the ability of an institution to translate data-driven insights into meaningful, actionable change for its students.",
      "stats": {
        "char_count": 5236,
        "word_count": 731,
        "sentence_count": 37,
        "line_count": 16
      }
    },
    {
      "heading": "Critical Challenges, Ethical Concerns, and Future Directions",
      "level": 2,
      "content": "Despite the rapid advancements and promising applications, the field of academic success prediction faces significant challenges and ethical hurdles that must be addressed to ensure its responsible and effective implementation. One of the most pressing concerns is the \"black box\" nature of many sophisticated machine learning models, particularly deep neural networks [[3]]. When a model makes a prediction, it is often difficult or impossible to understand the specific reasons behind it. This lack of interpretability creates a critical trust deficit among educators, administrators, and students. To mitigate this, experts strongly advocate for human oversight and the establishment of institutional review groups tasked with auditing model inputs, architecture, and outputs to detect and correct for biases [[3]]. Without such safeguards, there is a real risk that predictive systems could perpetuate or even amplify existing inequalities, for instance, by disproportionately flagging students from certain demographic groups as \"at risk.\"\n\nAnother fundamental challenge lies in the issue of data. The performance of any predictive model is contingent on the quality, completeness, and representativeness of the data used to train it [[17]]. Many studies rely on archival data from a single institution, which limits the generalizability of their findings [[14,18]]. Furthermore, self-report data, a common source for non-academic variables, is susceptible to bias [[14]]. The collection and use of student data also raise serious privacy concerns, making compliance with regulations like GDPR essential [[16]]. Beyond data quality, the field suffers from a lack of standardization. There is no universally accepted protocol for measuring constructs like \"non-cognitive skills\" or \"sense of belonging,\" leading to inconsistent operationalizations across studies and making it difficult to compare results or conduct meta-analyses [[21,22]]. This methodological heterogeneity hinders the accumulation of cumulative knowledge.\n\nLooking to the future, several key research directions emerge from the current landscape. A primary need is for longitudinal studies that track student cohorts over extended periods. Such research is essential for understanding not only what predicts short-term success (e.g., first-year grades) but also what leads to long-term outcomes like career readiness and lifelong learning [[9,16]]. Another critical area is the validation of predictive models across diverse institutional types and cultural contexts. Most of the available research originates from Australia and the USA, with a particular focus on STEM education at the secondary and undergraduate levels [[24]]. More research is needed in non-STEM fields, at the graduate level, and in non-Western higher education systems to build a more globally representative body of evidence. The question of whether a student's choice of study truly aligns with their vocational interests remains an open one, requiring further investigation to determine its causal impact on academic and career trajectories [[21]].\n\nTo conclude, the future of academic success prediction will likely be defined by a move towards greater transparency, fairness, and contextual awareness. Developing inherently interpretable models or post-hoc explanation techniques will be crucial for building trust. There is also a need to explicitly incorporate principles of equity into model design, ensuring that predictions do not disadvantage marginalized students. Finally, bridging the gap between technological innovation and established educational theory is paramount [[22]]. Integrating the rich insights from theories of motivation, identity, and social integration into next-generation predictive frameworks will yield more holistic and ethically sound tools. By pursuing these avenues, the field can move beyond simply predicting outcomes to actively fostering a more equitable and supportive educational environment for all students.\n\n---",
      "stats": {
        "char_count": 4005,
        "word_count": 561,
        "sentence_count": 30,
        "line_count": 9
      }
    }
  ],
  "references": [
    {
      "text": "1. What are student success indicators? - Education First",
      "number": null,
      "title": "what are student success indicators? - education first"
    },
    {
      "text": "2. Study of Student Success Indicators based on the ...",
      "number": null,
      "title": "study of student success indicators based on the"
    },
    {
      "text": "3. From Evolution to Revolution: Predictive Analytics in ...",
      "number": null,
      "title": "from evolution to revolution: predictive analytics in"
    },
    {
      "text": "4. Enhancing Student Academic Success Prediction Through ...",
      "number": null,
      "title": "enhancing student academic success prediction through"
    },
    {
      "text": "5. (PDF) STEM vs non-STEM differences in university ...",
      "number": null,
      "title": "(pdf) stem vs non-stem differences in university"
    },
    {
      "text": "6. Eight Indicators for Measuring Equitable Student Success in ...",
      "number": null,
      "title": "eight indicators for measuring equitable student success in"
    },
    {
      "text": "7. Meta-Analysis of Student Engagement and Its Influencing ...",
      "number": null,
      "title": "meta-analysis of student engagement and its influencing"
    },
    {
      "text": "8. Leading Indicators of Academic Achievement",
      "number": null,
      "title": "leading indicators of academic achievement"
    },
    {
      "text": "9. Cognitive and non-cognitive predictors of academic ...",
      "number": null,
      "title": "cognitive and non-cognitive predictors of academic"
    },
    {
      "text": "10. A holistic approach to student empowerment and ...",
      "number": null,
      "title": "a holistic approach to student empowerment and"
    },
    {
      "text": "11. Holistic Student Development in Higher Education Institutions",
      "number": null,
      "title": "holistic student development in higher education institutions"
    },
    {
      "text": "12. Comparing STEM and Non-STEM Instructor Motivation ...",
      "number": null,
      "title": "comparing stem and non-stem instructor motivation"
    },
    {
      "text": "13. Eight Indicators for Measuring Equitable Student Success ...",
      "number": null,
      "title": "eight indicators for measuring equitable student success"
    },
    {
      "text": "14. Exploring the influence of non-cognitive skills on academic ...",
      "number": null,
      "title": "exploring the influence of non-cognitive skills on academic"
    },
    {
      "text": "15. enhancing student achievement through machine learning",
      "number": null,
      "title": "enhancing student achievement through machine learning"
    },
    {
      "text": "16. Identifying the Determinants of Academic Success",
      "number": null,
      "title": "identifying the determinants of academic success"
    },
    {
      "text": "17. Advancing educational data mining for enhanced student ...",
      "number": null,
      "title": "advancing educational data mining for enhanced student"
    },
    {
      "text": "18. Predicting student performance academic using Automated ...",
      "number": null,
      "title": "predicting student performance academic using automated"
    },
    {
      "text": "19. Prediction of Student Academic Performance Utilizing a ...",
      "number": null,
      "title": "prediction of student academic performance utilizing a"
    },
    {
      "text": "20. A student academic performance prediction model based ...",
      "number": null,
      "title": "a student academic performance prediction model based"
    },
    {
      "text": "21. Does interest fit between student and study program lead ...",
      "number": null,
      "title": "does interest fit between student and study program lead"
    },
    {
      "text": "22. Bridging theoretical gaps to improve students' academic ...",
      "number": null,
      "title": "bridging theoretical gaps to improve students' academic"
    },
    {
      "text": "23. Cognitive style and Students' academic achievement",
      "number": null,
      "title": "cognitive style and students' academic achievement"
    },
    {
      "text": "24. Understanding STEM beyond the cities: A comprehensive ...",
      "number": null,
      "title": "understanding stem beyond the cities: a comprehensive"
    },
    {
      "text": "25. Systematic review and meta-analysis of the impact ...",
      "number": null,
      "title": "systematic review and meta-analysis of the impact"
    },
    {
      "text": "26. assessing a decade of progress in undergraduate STEM ...",
      "number": null,
      "title": "assessing a decade of progress in undergraduate stem"
    },
    {
      "text": "27. Full article: Comparative analysis of academic performance ...",
      "number": null,
      "title": "full article: comparative analysis of academic performance"
    }
  ],
  "metadata": {
    "source_file": "results\\original\\Qwen\\education\\04_Predicting_academic_success_in_higher_education-_literature__20251225_044512_split.json",
    "processed_date": "2025-12-30T20:33:44.399252",
    "config": {
      "normalize_outline": true,
      "normalize_content": true,
      "normalize_references": true
    }
  }
}