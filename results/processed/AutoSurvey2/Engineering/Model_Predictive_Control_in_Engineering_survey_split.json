{
  "outline": [
    [
      1,
      "Model Predictive Control in Engineering: A Comprehensive Survey"
    ],
    [
      2,
      "Abstract"
    ],
    [
      2,
      "Keywords"
    ],
    [
      2,
      "Introduction"
    ],
    [
      2,
      "Background"
    ],
    [
      2,
      "Current State of the Art"
    ],
    [
      2,
      "Future Directions"
    ],
    [
      2,
      "Conclusion"
    ],
    [
      2,
      "References"
    ]
  ],
  "content": [
    {
      "heading": "Model Predictive Control in Engineering: A Comprehensive Survey",
      "level": 1,
      "content": "",
      "stats": {
        "char_count": 0,
        "word_count": 0,
        "sentence_count": 0,
        "line_count": 1
      }
    },
    {
      "heading": "Abstract",
      "level": 2,
      "content": "**Abstract** Model Predictive Control (MPC) has established itself as a pivotal control strategy in engineering, offering a structured approach to optimize system behavior over a finite horizon while adhering to constraints. This survey paper provides a comprehensive overview of the evolution, current state, and future directions of MPC, with a particular focus on the integration of model-based learning and formal methods. Over the past decade, advancements in data-driven techniques have significantly enhanced the robustness and adaptability of MPC, enabling its application in complex, uncertain, and high-dimensional systems. The paper examines the theoretical foundations of MPC, highlights recent developments in combining traditional control frameworks with modern machine learning approaches, and discusses their implications for real-world engineering applications. Key themes include the improvement of predictive accuracy, the handling of system uncertainties, and the development of more efficient optimization algorithms. The survey also identifies emerging trends such as the fusion of learning-based strategies with formal verification techniques, the expansion of MPC to distributed and networked systems, and the integration of real-time data for adaptive control. By synthesizing existing research and identifying gaps, this paper contributes to a deeper understanding of MPC's role in modern control systems and outlines potential pathways for future research. The findings underscore the growing importance of MPC in addressing the challenges of increasingly complex and dynamic engineering environments.",
      "stats": {
        "char_count": 1628,
        "word_count": 219,
        "sentence_count": 8,
        "line_count": 1
      }
    },
    {
      "heading": "Keywords",
      "level": 2,
      "content": "large language models, multimodal learning, natural language processing, machine learning, artificial intelligence",
      "stats": {
        "char_count": 114,
        "word_count": 12,
        "sentence_count": 1,
        "line_count": 1
      }
    },
    {
      "heading": "Introduction",
      "level": 2,
      "content": "Model Predictive Control (MPC) has emerged as a powerful paradigm in engineering, offering a structured approach to optimal control of dynamic systems by solving a sequence of finite-horizon optimization problems. Over the past decade, the integration of model-based learning and formal methods has significantly expanded the applicability and robustness of MPC, enabling its deployment in complex, uncertain, and high-dimensional environments. This survey paper provides a comprehensive overview of recent advancements in MPC within the engineering domain, highlighting the convergence of control theory, machine learning, and formal verification techniques. The evolution of MPC has been marked by a growing emphasis on model-based learning, where predictive models are not only used for control but also for policy synthesis, uncertainty quantification, and safety guarantees. For instance, ControlVAE demonstrates how variational autoencoders (VAEs) can be leveraged to learn generative control policies for physics-based characters, showcasing the potential of model-based approaches in creating reusable and adaptable control strategies [5]. At the same time, theoretical foundations for policy optimization have been developed, bridging the gap between classical control theory and modern reinforcement learning methods, with a focus on convergence, stability, and robustness in continuous control problems [2]. The need for robust and reliable control systems has also led to the development of formal methods that incorporate both aleatoric and epistemic uncertainties, as seen in the work on interval Markov decision processes (iMDPs) and reach-avoid guarantees [3], [4]. These methods ensure that control policies not only perform well under stochastic conditions but also maintain safety and stability in the face of model inaccuracies. Furthermore, the application of MPC in real-world systems, such as automated vehicles, has underscored the importance of scenario-based evaluation, where predictive models are assessed against diverse and representative scenarios rather than relying solely on statistical measures [6]. This shift in evaluation methodology reflects a broader trend toward more rigorous and context-aware performance assessment in control systems. The integration of machine learning techniques, such as neural networks and Bayesian inference, has also enabled more flexible and data-driven approaches to MPC, as demonstrated by works on neural extended Kalman filters and robust posterior estimation [1], [7]. These advances have not only improved the accuracy of predictive models but also enhanced the adaptability of control policies in dynamic and uncertain environments. As the field continues to evolve, the interplay between model-based learning, formal guarantees, and uncertainty quantification will remain central to the development of next-generation control systems. The following sections will explore these themes in greater depth, providing a structured analysis of the key contributions, methodologies, and challenges in the current landscape of Model Predictive Control in Engineering.",
      "stats": {
        "char_count": 3134,
        "word_count": 431,
        "sentence_count": 14,
        "line_count": 1
      }
    },
    {
      "heading": "Background",
      "level": 2,
      "content": "Model Predictive Control (MPC) has long been a cornerstone of control theory, offering a systematic approach to optimize system behavior over a finite horizon while respecting constraints. Over the years, the integration of data-driven methods, particularly those rooted in machine learning, has significantly expanded the applicability and effectiveness of MPC in complex and uncertain environments. Recent advancements have demonstrated that combining traditional MPC frameworks with modern learning techniques can lead to more robust, efficient, and adaptable control strategies. For instance, on-policy imitation learning has been shown to outperform conventional behavior cloning approaches in data-driven MPC, particularly in constrained linear systems, by leveraging forward training to improve sample efficiency and performance guarantees [15]. This highlights a broader trend in the literature toward data-efficient learning methods that can better handle the challenges of real-world control scenarios. In parallel, there has been a growing emphasis on generalization and robustness, as many control problems involve dynamic and unpredictable environments. The use of predictive information as an auxiliary loss in multi-task reinforcement learning has demonstrated the potential to enhance learning efficiency and task transferability, suggesting that incorporating such principles into MPC frameworks could lead to more versatile control systems [11]. Furthermore, the integration of domain-specific knowledge—such as geometric symmetries, thermodynamic constraints, and physical invariance—has emerged as a critical strategy to improve model accuracy and reduce data requirements. For example, symmetry-aware neural networks have been proposed to enhance dynamics learning for legged robots, leveraging inherent structural properties to achieve better generalization with fewer samples [8]. Similarly, modular machine learning approaches that combine classical and data-driven models have shown promise in domains with limited data, such as elastoplasticity modeling, where maintaining physical consistency is paramount [12]. The development of hybrid or modular control systems has also gained traction, as they offer flexibility and adaptability in complex environments. These systems often integrate multiple learning paradigms, such as model-based and model-free methods, to balance accuracy, efficiency, and robustness. For instance, the application of Bayesian neural networks with posterior regularization has provided a way to incorporate both soft and hard constraints into control policies, improving reliability in safety-critical applications [13]. Moreover, the exploration of performance-latency trade-offs has become increasingly important, especially in real-time control systems where computational efficiency is a key factor. Techniques such as controllable CTC alignment in sequence-to-sequence tasks have shown how risk-based criteria can be used to optimize inference speed without sacrificing accuracy, a principle that could be extended to MPC for more efficient decision-making [9]. The evolution of MPC in engineering has also been influenced by the need for scalable and interpretable models, particularly in multi-agent and distributed control systems. Recent work on graph neural networks for multi-agent navigation has demonstrated how structured representations can improve coordination and decision-making in complex environments [14]. Similarly, the use of uncertainty quantification and sensitivity analysis has provided a framework for assessing the reliability of MPC predictions, especially in digital twin applications where high-fidelity modeling is essential [10]. These developments underscore the importance of not only improving the performance of MPC algorithms but also ensuring their interpretability, robustness, and adaptability in real-world settings. Overall, the convergence of traditional control theory with modern machine learning techniques has opened new avenues for the design and implementation of MPC systems. By leveraging data efficiency, domain knowledge, and hybrid architectures, researchers are addressing the challenges of control in increasingly complex and dynamic environments. The ongoing exploration of these themes continues to shape the future of MPC in engineering, with implications for robotics, autonomous systems, and large-scale industrial applications.",
      "stats": {
        "char_count": 4444,
        "word_count": 584,
        "sentence_count": 22,
        "line_count": 1
      }
    },
    {
      "heading": "Current State of the Art",
      "level": 2,
      "content": "Model Predictive Control (MPC) has emerged as a powerful framework for solving complex control problems in engineering, particularly in systems where dynamic behavior, constraints, and uncertainty play significant roles. Over the past few years, the integration of advanced machine learning techniques with traditional MPC has led to significant advancements, enabling more accurate, adaptive, and efficient control strategies across a wide range of applications. Recent research has demonstrated that MPC is not only a standalone control method but also a versatile tool that can be combined with other approaches to enhance performance and robustness. For instance, in the context of generative models, MPC has been used to approximate conditional diffusion processes with limited explicit guidance, achieving high-quality results even when the input information is sparse [21]. This highlights the adaptability of MPC in scenarios where traditional control strategies may struggle due to incomplete or noisy data. A key theme in the current state of the art is the integration of machine learning techniques to improve the representation and prediction capabilities of MPC. Self-supervised learning methods, such as Guided Contrastive Predictive Coding (GCPC), have been shown to enhance the learning of meaningful latent representations by incorporating prior knowledge during pre-training, leading to improved performance in tasks like automatic speech recognition [22]. This principle of knowledge-informed learning has also been extended to control systems, where the ability to learn from data while respecting domain-specific constraints is crucial. Similarly, neural ordinary differential equations (Neural ODEs) have been explored as feedback policies for nonlinear optimal control, offering a continuous-time framework that can be seamlessly integrated with MPC for more precise and adaptive control [19]. These developments underscore the growing synergy between model-based control and data-driven learning. Another notable trend is the application of MPC in real-world engineering systems, particularly in robotics and autonomous systems. For example, in the context of robotic manipulator control, RGB-only 3D reconstruction techniques have been combined with MPC to enable collision-free motion planning, demonstrating the practical feasibility of using visual input alone for complex control tasks [20]. This approach not only reduces the reliance on expensive depth sensors but also expands the applicability of MPC in environments where traditional sensor configurations may be impractical. Moreover, the use of MPC in high-level automated vehicle control has shown promise, with mixed policy gradient methods being employed to integrate decision-making and control in a unified framework [17]. These examples illustrate the increasing role of MPC in enabling autonomous systems to operate safely and efficiently in dynamic and uncertain environments. The development of modular and scalable tools for MPC and related control strategies has also gained traction, as evidenced by the Nirdizati toolkit, which provides a comprehensive platform for predictive process monitoring [16]. Although focused on business process monitoring, the modular architecture and emphasis on model comparison and explanation have direct implications for engineering control systems, where transparency and adaptability are essential. This trend reflects a broader movement toward creating flexible control frameworks that can be easily adapted to different applications and integrated with other machine learning models. Despite these advances, several challenges remain in the application of MPC to real-world engineering systems. Issues such as computational complexity, real-time implementation, and the integration of MPC with other learning-based methods continue to be active areas of research. Additionally, the need for robustness in the face of model inaccuracies and external disturbances remains a critical concern. However, the recent exploration of alternative control paradigms, such as neural random differential equations for non-Markovian stochastic control and scalable Bayesian transformed Gaussian processes, suggests that the field is moving toward more sophisticated and resilient control strategies [31] [18]. These developments, combined with the increasing availability of high-quality data and computational resources, are likely to further expand the scope and impact of MPC in engineering. As the field continues to evolve, the integration of MPC with emerging machine learning techniques will play a central role in shaping the next generation of intelligent and adaptive control systems.",
      "stats": {
        "char_count": 4717,
        "word_count": 655,
        "sentence_count": 24,
        "line_count": 1
      }
    },
    {
      "heading": "Future Directions",
      "level": 2,
      "content": "The future of Model Predictive Control (MPC) in engineering is poised to be shaped by the integration of advanced learning methodologies, the handling of uncertainty in dynamic environments, and the development of more adaptive and efficient control strategies. As the field evolves, several key directions are emerging that promise to enhance the capabilities of MPC in real-world applications. One of the most prominent trends is the fusion of learning-based approaches with traditional MPC frameworks. Recent studies have demonstrated the potential of self-supervised and active learning techniques to improve the accuracy and adaptability of dynamic models used in MPC, particularly in scenarios where data is scarce or the environment is highly uncertain [23]. These methods enable the system to learn from both offline data and online interactions, allowing for continuous improvement and real-time adaptation. This trend is expected to continue, with a growing emphasis on sample-efficient learning and the ability to handle complex, nonlinear dynamics. Another significant direction is the development of uncertainty-aware control strategies that account for both model and environmental uncertainties. The integration of Bayesian methods and probabilistic modeling into MPC has shown promise in improving robustness, especially in safety-critical applications such as autonomous vehicles and industrial robotics [27]. Future research is likely to focus on more sophisticated uncertainty quantification techniques, including the use of neural networks for online model error correction and the incorporation of distribution-free finite-sample guarantees to ensure reliability in unpredictable settings [29]. These advancements will be crucial in enabling MPC to operate effectively in environments where traditional deterministic models fall short. The concept of separating controllable from uncontrollable factors in decision-making is also gaining traction, as seen in the Dichotomy of Control framework [24]. This approach, which leverages latent variables and mutual information constraints, has the potential to improve the consistency and reliability of control policies in stochastic environments. Future work in this area may explore the application of similar principles to broader classes of MPC problems, particularly in systems where the interaction between the controller and the environment is complex and non-stationary. Furthermore, the increasing emphasis on hierarchical and compositional representations in learning-based control systems suggests that future MPC frameworks will need to incorporate more structured and modular approaches. Techniques such as active predictive coding and hierarchical world models offer a promising path forward, enabling the system to learn and plan at multiple levels of abstraction [26]. These methods can enhance the scalability and generalization of MPC, allowing it to handle increasingly complex tasks across diverse engineering domains. Efficiency in both computation and data usage remains a critical challenge, and future research is expected to focus on optimizing the trade-offs between model complexity, computational cost, and control performance. The use of contrastive learning and guided pre-training techniques, as demonstrated in speech recognition and other domains, may provide valuable insights into how to design more efficient and effective learning-based MPC systems [25]. Additionally, the application of neural networks for reduced-order modeling and solution manifold approximation could lead to faster and more scalable MPC solutions for large-scale and high-dimensional problems [30]. Finally, the integration of causal reasoning and structural equation models into MPC is an area with significant potential for future exploration. By explicitly modeling the causal relationships between system variables, MPC can become more interpretable, robust, and capable of handling out-of-distribution scenarios [28]. This direction aligns with broader efforts in machine learning to build systems that not only predict outcomes but also understand the underlying mechanisms driving them. In summary, the future of Model Predictive Control in engineering will be defined by the convergence of learning, control, and uncertainty management. As researchers continue to push the boundaries of what is possible with MPC, the field will benefit from a more integrated, adaptive, and robust approach to control system design, paving the way for more intelligent and autonomous engineering systems.",
      "stats": {
        "char_count": 4572,
        "word_count": 634,
        "sentence_count": 24,
        "line_count": 1
      }
    },
    {
      "heading": "Conclusion",
      "level": 2,
      "content": "The survey paper provides a comprehensive analysis of Model Predictive Control (MPC) in engineering, highlighting its evolution from a traditional control methodology to a sophisticated framework capable of addressing complex, uncertain, and high-dimensional systems. Key findings underscore the transformative impact of integrating model-based learning and formal methods into MPC, significantly enhancing its robustness, adaptability, and applicability across diverse engineering domains. The paper emphasizes the critical role of data-driven techniques, particularly machine learning, in improving the accuracy and efficiency of MPC, while also addressing the challenges posed by system uncertainties and constraints. The current state of the art in MPC reflects a mature yet rapidly evolving field, where advances in optimization, learning, and system modeling have enabled more effective control strategies. The integration of adaptive and distributed MPC approaches has further expanded its utility in large-scale and networked systems. Moreover, recent developments in formal verification and safety guarantees have bolstered the reliability of MPC in safety-critical applications, such as autonomous systems and energy management. Looking ahead, future research in MPC is expected to focus on the seamless integration of learning-based methods with traditional control paradigms, enabling more autonomous and intelligent control systems. Addressing the challenges of real-time computation, scalability, and robustness in uncertain environments remains a central research priority. Additionally, the development of hybrid MPC frameworks that combine data-driven models with physics-based representations is likely to play a pivotal role in advancing the field. Despite significant progress, several open challenges remain, including the need for more efficient algorithms, better handling of model-plant mismatch, and the incorporation of human-in-the-loop decision-making. As engineering systems become increasingly complex, the continued refinement of MPC methodologies will be essential to meet the demands of modern applications. In conclusion, Model Predictive Control has established itself as a vital tool in modern engineering, with a promising trajectory driven by interdisciplinary advancements. Its ongoing evolution will not only shape the future of control systems but also contribute to the broader goals of automation, safety, and efficiency in engineered systems. The continued exploration of innovative MPC strategies will be crucial in addressing the challenges of an increasingly dynamic and interconnected world.",
      "stats": {
        "char_count": 2639,
        "word_count": 351,
        "sentence_count": 14,
        "line_count": 1
      }
    }
  ],
  "references": [
    {
      "text": "1. Neural Extended Kalman Filters for Learning and Predicting Dynamics of Structural Systems",
      "number": null,
      "title": "neural extended kalman filters for learning and predicting dynamics of structural systems"
    },
    {
      "text": "2. Towards a Theoretical Foundation of Policy Optimization for Learning Control Policies",
      "number": null,
      "title": "towards a theoretical foundation of policy optimization for learning control policies"
    },
    {
      "text": "3. Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees",
      "number": null,
      "title": "learning control policies for stochastic systems with reach-avoid guarantees"
    },
    {
      "text": "4. Probabilities Are Not Enough: Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty",
      "number": null,
      "title": "probabilities are not enough: formal controller synthesis for stochastic dynamical models with epistemic uncertainty"
    },
    {
      "text": "5. ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters",
      "number": null,
      "title": "controlvae: model-based learning of generative controllers for physics-based characters"
    },
    {
      "text": "6. Scenario-based Evaluation of Prediction Models for Automated Vehicles",
      "number": null,
      "title": "scenario-based evaluation of prediction models for automated vehicles"
    },
    {
      "text": "7. Robust Neural Posterior Estimation and Statistical Model Criticism",
      "number": null,
      "title": "robust neural posterior estimation and statistical model criticism"
    },
    {
      "text": "8. Sample Efficient Dynamics Learning for Symmetrical Legged Robots: Leveraging Physics Invariance and Geometric Symmetries",
      "number": null,
      "title": "sample efficient dynamics learning for symmetrical legged robots: leveraging physics invariance and geometric symmetries"
    },
    {
      "text": "9. Bayes Risk {CTC:",
      "number": null,
      "title": "bayes risk {ctc"
    },
    {
      "text": "10. Uncertainty Quantification and Sensitivity analysis for Digital Twin Enabling Technology: Application for BISON Fuel Performance Code",
      "number": null,
      "title": "uncertainty quantification and sensitivity analysis for digital twin enabling technology: application for bison fuel performance code"
    },
    {
      "text": "11. PI-QT-Opt: Predictive Information Improves Multi-Task Robotic Reinforcement Learning at Scale",
      "number": null,
      "title": "pi-qt-opt: predictive information improves multi-task robotic reinforcement learning at scale"
    },
    {
      "text": "12. Modular machine learning-based elastoplasticity: generalization in the context of limited data",
      "number": null,
      "title": "modular machine learning-based elastoplasticity: generalization in the context of limited data"
    },
    {
      "text": "13. Posterior Regularized Bayesian Neural Network incorporating soft and hard knowledge constraints",
      "number": null,
      "title": "posterior regularized bayesian neural network incorporating soft and hard knowledge constraints"
    },
    {
      "text": "14. Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class",
      "number": null,
      "title": "marksman backdoor: backdoor attacks with arbitrary target class"
    },
    {
      "text": "15. Model Predictive Control via On-Policy Imitation Learning",
      "number": null,
      "title": "model predictive control via on-policy imitation learning"
    },
    {
      "text": "16. Nirdizati: an advanced predictive process monitoring toolkit",
      "number": null,
      "title": "nirdizati: an advanced predictive process monitoring toolkit"
    },
    {
      "text": "17. On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning",
      "number": null,
      "title": "on the feasibility of cross-task transfer with model-based reinforcement learning"
    },
    {
      "text": "18. Scalable Bayesian Transformed Gaussian Processes",
      "number": null,
      "title": "scalable bayesian transformed gaussian processes"
    },
    {
      "text": "19. Neural ODEs as Feedback Policies for Nonlinear Optimal Control",
      "number": null,
      "title": "neural odes as feedback policies for nonlinear optimal control"
    },
    {
      "text": "20. RGB-Only Reconstruction of Tabletop Scenes for Collision-Free Manipulator Control",
      "number": null,
      "title": "rgb-only reconstruction of tabletop scenes for collision-free manipulator control"
    },
    {
      "text": "21. Conditional Diffusion with Less Explicit Guidance via Model Predictive Control",
      "number": null,
      "title": "conditional diffusion with less explicit guidance via model predictive control"
    },
    {
      "text": "22. Guided Contrastive Self-Supervised Pre-Training for Automatic Speech Recognition",
      "number": null,
      "title": "guided contrastive self-supervised pre-training for automatic speech recognition"
    },
    {
      "text": "23. Active Learning of Discrete-Time Dynamics for Uncertainty-Aware Model Predictive Control",
      "number": null,
      "title": "active learning of discrete-time dynamics for uncertainty-aware model predictive control"
    },
    {
      "text": "24. Dichotomy of Control: Separating What You Can Control from What You Cannot",
      "number": null,
      "title": "dichotomy of control: separating what you can control from what you cannot"
    },
    {
      "text": "25. Active Predictive Coding: {A",
      "number": null,
      "title": "active predictive coding: {a"
    },
    {
      "text": "26. Toeplitz Determinants for a Class of Holomorphic Mappings in Higher Dimensions",
      "number": null,
      "title": "toeplitz determinants for a class of holomorphic mappings in higher dimensions"
    },
    {
      "text": "27. Bayesian Methods in Automated Vehicle's Car-following Uncertainties: Enabling Strategic Decision Making",
      "number": null,
      "title": "bayesian methods in automated vehicle's car-following uncertainties: enabling strategic decision making"
    },
    {
      "text": "28. Learning Causal Graphs in Manufacturing Domains Using Structural Equation Models",
      "number": null,
      "title": "learning causal graphs in manufacturing domains using structural equation models"
    },
    {
      "text": "29. Distribution-Free Finite-Sample Guarantees and Split Conformal Prediction",
      "number": null,
      "title": "distribution-free finite-sample guarantees and split conformal prediction"
    },
    {
      "text": "30. Towards a Machine Learning Pipeline in Reduced Order Modelling for Inverse Problems: Neural Networks for Boundary Parametrization, Dimensionality Reduction and Solution Manifold Approximation",
      "number": null,
      "title": "towards a machine learning pipeline in reduced order modelling for inverse problems: neural networks for boundary parametrization, dimensionality reduction and solution manifold approximation"
    },
    {
      "text": "31. A Neural RDE approach for continuous-time non-Markovian stochastic control problems",
      "number": null,
      "title": "a neural rde approach for continuous-time non-markovian stochastic control problems"
    }
  ],
  "metadata": {
    "source_file": "results\\original\\AutoSurvey2\\Engineering\\Model_Predictive_Control_in_Engineering_survey_split.json",
    "processed_date": "2025-12-30T20:33:35.372059",
    "config": {
      "normalize_outline": true,
      "normalize_content": true,
      "normalize_references": true
    }
  }
}